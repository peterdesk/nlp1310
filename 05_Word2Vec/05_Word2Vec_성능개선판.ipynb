{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능 개선판 word2vec 학습모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_layers import Embedding, NegativeSamplingLoss, Adam, Trainer\n",
    "from mynlp import preprocess, most_similar, create_contexts_target\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW :\n",
    "    def __init__(self, vocab_size, hidden_size, window_size, corpus):\n",
    "        V,H = vocab_size, hidden_size\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        W_in = 0.01*np.random.randn(V,H).astype('f') \n",
    "        W_out = 0.01*np.random.randn(V,H).astype('f')  # (H,V) 가 아님에 주의\n",
    "        \n",
    "        # 계층 생성\n",
    "        self.in_layers = []\n",
    "        for i in range(2*window_size):   # window_size = 5일 경우 , i : 0~9 (10회 반복)    \n",
    "            layer = Embedding(W_in)      # Embedding 계층 사용\n",
    "            self.in_layers.append(layer)\n",
    "        \n",
    "        self.ns_loss_layer = NegativeSamplingLoss(W_out,corpus,power=0.75,sample_size=5)\n",
    "\n",
    "        # 모든 가중치와 기울기를 배열에 모은다.\n",
    "        layers = self.in_layers + [self.ns_loss_layer]\n",
    "        self.params ,self.grads = [],[]\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "        # 인스턴스 변수 단어의 분산 표현을 저장한다.    \n",
    "        self.word_vecs = W_in  \n",
    "        \n",
    "    def forward(self,contexts,target):  # contexts : (100,10)\n",
    "        h = 0\n",
    "        for i,layer in enumerate(self.in_layers): # 10회\n",
    "            h += layer.forward(contexts[:,i])     # contexts의 1개 컬럼만 추출하여 Embedding층에 idx로 전달\n",
    "            \n",
    "        h *= 1/len(self.in_layers)  # h*(1/10) : 10으로 나눔\n",
    "        loss = self.ns_loss_layer.forward(h,target)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.ns_loss_layer.backward(dout)\n",
    "        dout *= 1/len(self.in_layers)\n",
    "        for layer in self.in_layers:\n",
    "            layer.backward(dout)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW 모델 학습 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "929589\n"
     ]
    }
   ],
   "source": [
    "from dataset import ptb\n",
    "import pickle\n",
    "\n",
    "# 하이퍼 파라미터 설정\n",
    "window_size = 5\n",
    "# window_size = 2\n",
    "\n",
    "hidden_size = 100\n",
    "batch_size = 100\n",
    "max_epoch = 10  # 10회 이상\n",
    "\n",
    "# 데이터 읽기\n",
    "# 전체 데이터 모두 사용시  # 전체 데이터로 epoch 10회 학습 ==> '약 10시간 소요'\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "print(vocab_size)  # 10000\n",
    "print(len(corpus)) # 929589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "5276\n",
      "5276\n",
      "5276\n"
     ]
    }
   ],
   "source": [
    "# PTB 데이터 중 일부만 사용시 :  50000 corpus\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "\n",
    "corpus_size = 50000\n",
    "corpus = corpus[:corpus_size]\n",
    "\n",
    "vocab_size = int(max(corpus) + 1)  # 5276\n",
    "\n",
    "temp1,temp2 = {},{}\n",
    "for k in range(vocab_size):\n",
    "    word1= list(word_to_id.keys())[k]    \n",
    "    id1 = list(word_to_id.values())[k] \n",
    "    temp1[word1] = id1\n",
    "    \n",
    "    word2= list(id_to_word.keys())[k]    \n",
    "    id2 = list(id_to_word.values())[k] \n",
    "    temp2[word2] = id2\n",
    "    \n",
    "word_to_id = temp1\n",
    "id_to_word =temp2\n",
    "\n",
    "print(len(corpus))\n",
    "print(vocab_size)      # 5276 \n",
    "print(len(word_to_id))\n",
    "print(len(id_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49990, 10) (49990,)\n",
      "[[ 0  1  2  3  4  6  7  8  9 10]\n",
      " [ 1  2  3  4  5  7  8  9 10 11]\n",
      " [ 2  3  4  5  6  8  9 10 11 12]\n",
      " [ 3  4  5  6  7  9 10 11 12 13]\n",
      " [ 4  5  6  7  8 10 11 12 13 14]\n",
      " [ 5  6  7  8  9 11 12 13 14 15]\n",
      " [ 6  7  8  9 10 12 13 14 15 16]\n",
      " [ 7  8  9 10 11 13 14 15 16 17]\n",
      " [ 8  9 10 11 12 14 15 16 17 18]\n",
      " [ 9 10 11 12 13 15 16 17 18 19]\n",
      " [10 11 12 13 14 16 17 18 19 20]\n",
      " [11 12 13 14 15 17 18 19 20 21]\n",
      " [12 13 14 15 16 18 19 20 21 22]\n",
      " [13 14 15 16 17 19 20 21 22 23]\n",
      " [14 15 16 17 18 20 21 22 23 24]\n",
      " [15 16 17 18 19 21 22 23 24 25]\n",
      " [16 17 18 19 20 22 23 24 25 26]\n",
      " [17 18 19 20 21 23 24 25 26 27]\n",
      " [18 19 20 21 22 24 25 26 27 28]\n",
      " [19 20 21 22 23 25 26 27 28 29]\n",
      " [20 21 22 23 24 26 27 28 29 30]\n",
      " [21 22 23 24 25 27 28 29 30 31]\n",
      " [22 23 24 25 26 28 29 30 31 32]\n",
      " [23 24 25 26 27 29 30 31 32 33]\n",
      " [24 25 26 27 28 30 31 32 33 34]\n",
      " [25 26 27 28 29 31 32 33 34 35]\n",
      " [26 27 28 29 30 32 33 34 35 36]\n",
      " [27 28 29 30 31 33 34 35 36 37]\n",
      " [28 29 30 31 32 34 35 36 37 38]\n",
      " [29 30 31 32 33 35 36 37 38 27]\n",
      " [30 31 32 33 34 36 37 38 27 24]\n",
      " [31 32 33 34 35 37 38 27 24 39]\n",
      " [32 33 34 35 36 38 27 24 39 26]\n",
      " [33 34 35 36 37 27 24 39 26 40]\n",
      " [34 35 36 37 38 24 39 26 40 41]\n",
      " [35 36 37 38 27 39 26 40 41 42]\n",
      " [36 37 38 27 24 26 40 41 42 26]\n",
      " [37 38 27 24 39 40 41 42 26 43]\n",
      " [38 27 24 39 26 41 42 26 43 32]\n",
      " [27 24 39 26 40 42 26 43 32 44]\n",
      " [24 39 26 40 41 26 43 32 44 45]\n",
      " [39 26 40 41 42 43 32 44 45 46]\n",
      " [26 40 41 42 26 32 44 45 46 24]\n",
      " [40 41 42 26 43 44 45 46 24 47]\n",
      " [41 42 26 43 32 45 46 24 47 26]\n",
      " [42 26 43 32 44 46 24 47 26 27]\n",
      " [26 43 32 44 45 24 47 26 27 28]\n",
      " [43 32 44 45 46 47 26 27 28 29]\n",
      " [32 44 45 46 24 26 27 28 29 48]\n",
      " [44 45 46 24 47 27 28 29 48 49]\n",
      " [45 46 24 47 26 28 29 48 49 41]\n",
      " [46 24 47 26 27 29 48 49 41 42]\n",
      " [24 47 26 27 28 48 49 41 42 50]\n",
      " [47 26 27 28 29 49 41 42 50 51]\n",
      " [26 27 28 29 48 41 42 50 51 52]\n",
      " [27 28 29 48 49 42 50 51 52 53]\n",
      " [28 29 48 49 41 50 51 52 53 54]\n",
      " [29 48 49 41 42 51 52 53 54 55]\n",
      " [48 49 41 42 50 52 53 54 55 35]\n",
      " [49 41 42 50 51 53 54 55 35 36]\n",
      " [41 42 50 51 52 54 55 35 36 37]\n",
      " [42 50 51 52 53 55 35 36 37 42]\n",
      " [50 51 52 53 54 35 36 37 42 56]\n",
      " [51 52 53 54 55 36 37 42 56 57]\n",
      " [52 53 54 55 35 37 42 56 57 58]\n",
      " [53 54 55 35 36 42 56 57 58 59]\n",
      " [54 55 35 36 37 56 57 58 59 24]\n",
      " [55 35 36 37 42 57 58 59 24 35]\n",
      " [35 36 37 42 56 58 59 24 35 60]\n",
      " [36 37 42 56 57 59 24 35 60 42]\n",
      " [37 42 56 57 58 24 35 60 42 61]\n",
      " [42 56 57 58 59 35 60 42 61 62]\n",
      " [56 57 58 59 24 60 42 61 62 63]\n",
      " [57 58 59 24 35 42 61 62 63 64]\n",
      " [58 59 24 35 60 61 62 63 64 65]\n",
      " [59 24 35 60 42 62 63 64 65 66]\n",
      " [24 35 60 42 61 63 64 65 66 67]\n",
      " [35 60 42 61 62 64 65 66 67 68]\n",
      " [60 42 61 62 63 65 66 67 68 69]\n",
      " [42 61 62 63 64 66 67 68 69 70]\n",
      " [61 62 63 64 65 67 68 69 70 35]\n",
      " [62 63 64 65 66 68 69 70 35 71]\n",
      " [63 64 65 66 67 69 70 35 71 72]\n",
      " [64 65 66 67 68 70 35 71 72 42]\n",
      " [65 66 67 68 69 35 71 72 42 73]\n",
      " [66 67 68 69 70 71 72 42 73 74]\n",
      " [67 68 69 70 35 72 42 73 74 75]\n",
      " [68 69 70 35 71 42 73 74 75 35]\n",
      " [69 70 35 71 72 73 74 75 35 46]\n",
      " [70 35 71 72 42 74 75 35 46 42]\n",
      " [35 71 72 42 73 75 35 46 42 76]\n",
      " [71 72 42 73 74 35 46 42 76 77]\n",
      " [72 42 73 74 75 46 42 76 77 64]\n",
      " [42 73 74 75 35 42 76 77 64 78]\n",
      " [73 74 75 35 46 76 77 64 78 79]\n",
      " [74 75 35 46 42 77 64 78 79 80]\n",
      " [75 35 46 42 76 64 78 79 80 27]\n",
      " [35 46 42 76 77 78 79 80 27 28]\n",
      " [46 42 76 77 64 79 80 27 28 81]\n",
      " [42 76 77 64 78 80 27 28 81 82]]\n"
     ]
    }
   ],
   "source": [
    "contexts,target = create_contexts_target(corpus,window_size)\n",
    "# print(corpus[:100])\n",
    "print(contexts.shape,target.shape) #(49990, 10), (49990,)\n",
    "print(contexts[:100])             \n",
    "# print(target[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 499 | 시간 0[s] | 손실 4.16\n",
      "| 에폭 1 |  반복 21 / 499 | 시간 1[s] | 손실 4.16\n",
      "| 에폭 1 |  반복 41 / 499 | 시간 2[s] | 손실 4.15\n",
      "| 에폭 1 |  반복 61 / 499 | 시간 4[s] | 손실 4.11\n",
      "| 에폭 1 |  반복 81 / 499 | 시간 6[s] | 손실 4.02\n",
      "| 에폭 1 |  반복 101 / 499 | 시간 7[s] | 손실 3.86\n",
      "| 에폭 1 |  반복 121 / 499 | 시간 9[s] | 손실 3.67\n",
      "| 에폭 1 |  반복 141 / 499 | 시간 10[s] | 손실 3.48\n",
      "| 에폭 1 |  반복 161 / 499 | 시간 12[s] | 손실 3.34\n",
      "| 에폭 1 |  반복 181 / 499 | 시간 13[s] | 손실 3.19\n",
      "| 에폭 1 |  반복 201 / 499 | 시간 15[s] | 손실 3.09\n",
      "| 에폭 1 |  반복 221 / 499 | 시간 16[s] | 손실 3.00\n",
      "| 에폭 1 |  반복 241 / 499 | 시간 17[s] | 손실 2.93\n",
      "| 에폭 1 |  반복 261 / 499 | 시간 19[s] | 손실 2.88\n",
      "| 에폭 1 |  반복 281 / 499 | 시간 20[s] | 손실 2.85\n",
      "| 에폭 1 |  반복 301 / 499 | 시간 22[s] | 손실 2.80\n",
      "| 에폭 1 |  반복 321 / 499 | 시간 24[s] | 손실 2.75\n",
      "| 에폭 1 |  반복 341 / 499 | 시간 25[s] | 손실 2.75\n",
      "| 에폭 1 |  반복 361 / 499 | 시간 28[s] | 손실 2.73\n",
      "| 에폭 1 |  반복 381 / 499 | 시간 30[s] | 손실 2.72\n",
      "| 에폭 1 |  반복 401 / 499 | 시간 32[s] | 손실 2.71\n",
      "| 에폭 1 |  반복 421 / 499 | 시간 34[s] | 손실 2.69\n",
      "| 에폭 1 |  반복 441 / 499 | 시간 37[s] | 손실 2.69\n",
      "| 에폭 1 |  반복 461 / 499 | 시간 38[s] | 손실 2.70\n",
      "| 에폭 1 |  반복 481 / 499 | 시간 39[s] | 손실 2.70\n",
      "| 에폭 2 |  반복 1 / 499 | 시간 40[s] | 손실 2.67\n",
      "| 에폭 2 |  반복 21 / 499 | 시간 42[s] | 손실 2.60\n",
      "| 에폭 2 |  반복 41 / 499 | 시간 43[s] | 손실 2.61\n",
      "| 에폭 2 |  반복 61 / 499 | 시간 44[s] | 손실 2.58\n",
      "| 에폭 2 |  반복 81 / 499 | 시간 46[s] | 손실 2.62\n",
      "| 에폭 2 |  반복 101 / 499 | 시간 47[s] | 손실 2.63\n",
      "| 에폭 2 |  반복 121 / 499 | 시간 48[s] | 손실 2.64\n",
      "| 에폭 2 |  반복 141 / 499 | 시간 49[s] | 손실 2.60\n",
      "| 에폭 2 |  반복 161 / 499 | 시간 51[s] | 손실 2.64\n",
      "| 에폭 2 |  반복 181 / 499 | 시간 53[s] | 손실 2.62\n",
      "| 에폭 2 |  반복 201 / 499 | 시간 55[s] | 손실 2.62\n",
      "| 에폭 2 |  반복 221 / 499 | 시간 56[s] | 손실 2.64\n",
      "| 에폭 2 |  반복 241 / 499 | 시간 58[s] | 손실 2.63\n",
      "| 에폭 2 |  반복 261 / 499 | 시간 63[s] | 손실 2.59\n",
      "| 에폭 2 |  반복 281 / 499 | 시간 67[s] | 손실 2.63\n",
      "| 에폭 2 |  반복 301 / 499 | 시간 70[s] | 손실 2.61\n",
      "| 에폭 2 |  반복 321 / 499 | 시간 72[s] | 손실 2.61\n",
      "| 에폭 2 |  반복 341 / 499 | 시간 74[s] | 손실 2.62\n",
      "| 에폭 2 |  반복 361 / 499 | 시간 76[s] | 손실 2.61\n",
      "| 에폭 2 |  반복 381 / 499 | 시간 78[s] | 손실 2.62\n",
      "| 에폭 2 |  반복 401 / 499 | 시간 79[s] | 손실 2.61\n",
      "| 에폭 2 |  반복 421 / 499 | 시간 81[s] | 손실 2.60\n",
      "| 에폭 2 |  반복 441 / 499 | 시간 84[s] | 손실 2.61\n",
      "| 에폭 2 |  반복 461 / 499 | 시간 86[s] | 손실 2.61\n",
      "| 에폭 2 |  반복 481 / 499 | 시간 88[s] | 손실 2.59\n",
      "| 에폭 3 |  반복 1 / 499 | 시간 90[s] | 손실 2.62\n",
      "| 에폭 3 |  반복 21 / 499 | 시간 93[s] | 손실 2.52\n",
      "| 에폭 3 |  반복 41 / 499 | 시간 96[s] | 손실 2.55\n",
      "| 에폭 3 |  반복 61 / 499 | 시간 97[s] | 손실 2.57\n",
      "| 에폭 3 |  반복 81 / 499 | 시간 99[s] | 손실 2.52\n",
      "| 에폭 3 |  반복 101 / 499 | 시간 101[s] | 손실 2.55\n",
      "| 에폭 3 |  반복 121 / 499 | 시간 104[s] | 손실 2.57\n",
      "| 에폭 3 |  반복 141 / 499 | 시간 105[s] | 손실 2.56\n",
      "| 에폭 3 |  반복 161 / 499 | 시간 107[s] | 손실 2.57\n",
      "| 에폭 3 |  반복 181 / 499 | 시간 109[s] | 손실 2.57\n",
      "| 에폭 3 |  반복 201 / 499 | 시간 111[s] | 손실 2.58\n",
      "| 에폭 3 |  반복 221 / 499 | 시간 113[s] | 손실 2.57\n",
      "| 에폭 3 |  반복 241 / 499 | 시간 115[s] | 손실 2.57\n",
      "| 에폭 3 |  반복 261 / 499 | 시간 116[s] | 손실 2.55\n",
      "| 에폭 3 |  반복 281 / 499 | 시간 119[s] | 손실 2.58\n",
      "| 에폭 3 |  반복 301 / 499 | 시간 120[s] | 손실 2.56\n",
      "| 에폭 3 |  반복 321 / 499 | 시간 121[s] | 손실 2.57\n",
      "| 에폭 3 |  반복 341 / 499 | 시간 123[s] | 손실 2.57\n",
      "| 에폭 3 |  반복 361 / 499 | 시간 124[s] | 손실 2.55\n",
      "| 에폭 3 |  반복 381 / 499 | 시간 126[s] | 손실 2.58\n",
      "| 에폭 3 |  반복 401 / 499 | 시간 128[s] | 손실 2.53\n",
      "| 에폭 3 |  반복 421 / 499 | 시간 130[s] | 손실 2.58\n",
      "| 에폭 3 |  반복 441 / 499 | 시간 132[s] | 손실 2.56\n",
      "| 에폭 3 |  반복 461 / 499 | 시간 134[s] | 손실 2.56\n",
      "| 에폭 3 |  반복 481 / 499 | 시간 136[s] | 손실 2.57\n",
      "| 에폭 4 |  반복 1 / 499 | 시간 138[s] | 손실 2.58\n",
      "| 에폭 4 |  반복 21 / 499 | 시간 139[s] | 손실 2.50\n",
      "| 에폭 4 |  반복 41 / 499 | 시간 141[s] | 손실 2.51\n",
      "| 에폭 4 |  반복 61 / 499 | 시간 142[s] | 손실 2.52\n",
      "| 에폭 4 |  반복 81 / 499 | 시간 143[s] | 손실 2.49\n",
      "| 에폭 4 |  반복 101 / 499 | 시간 145[s] | 손실 2.54\n",
      "| 에폭 4 |  반복 121 / 499 | 시간 146[s] | 손실 2.51\n",
      "| 에폭 4 |  반복 141 / 499 | 시간 147[s] | 손실 2.53\n",
      "| 에폭 4 |  반복 161 / 499 | 시간 149[s] | 손실 2.54\n",
      "| 에폭 4 |  반복 181 / 499 | 시간 150[s] | 손실 2.54\n",
      "| 에폭 4 |  반복 201 / 499 | 시간 152[s] | 손실 2.52\n",
      "| 에폭 4 |  반복 221 / 499 | 시간 153[s] | 손실 2.52\n",
      "| 에폭 4 |  반복 241 / 499 | 시간 155[s] | 손실 2.54\n",
      "| 에폭 4 |  반복 261 / 499 | 시간 157[s] | 손실 2.51\n",
      "| 에폭 4 |  반복 281 / 499 | 시간 158[s] | 손실 2.55\n",
      "| 에폭 4 |  반복 301 / 499 | 시간 160[s] | 손실 2.55\n",
      "| 에폭 4 |  반복 321 / 499 | 시간 161[s] | 손실 2.57\n",
      "| 에폭 4 |  반복 341 / 499 | 시간 162[s] | 손실 2.52\n",
      "| 에폭 4 |  반복 361 / 499 | 시간 164[s] | 손실 2.55\n",
      "| 에폭 4 |  반복 381 / 499 | 시간 166[s] | 손실 2.51\n",
      "| 에폭 4 |  반복 401 / 499 | 시간 168[s] | 손실 2.56\n",
      "| 에폭 4 |  반복 421 / 499 | 시간 169[s] | 손실 2.55\n",
      "| 에폭 4 |  반복 441 / 499 | 시간 171[s] | 손실 2.52\n",
      "| 에폭 4 |  반복 461 / 499 | 시간 174[s] | 손실 2.52\n",
      "| 에폭 4 |  반복 481 / 499 | 시간 175[s] | 손실 2.52\n",
      "| 에폭 5 |  반복 1 / 499 | 시간 177[s] | 손실 2.54\n",
      "| 에폭 5 |  반복 21 / 499 | 시간 178[s] | 손실 2.47\n",
      "| 에폭 5 |  반복 41 / 499 | 시간 180[s] | 손실 2.49\n",
      "| 에폭 5 |  반복 61 / 499 | 시간 182[s] | 손실 2.47\n",
      "| 에폭 5 |  반복 81 / 499 | 시간 184[s] | 손실 2.47\n",
      "| 에폭 5 |  반복 101 / 499 | 시간 186[s] | 손실 2.49\n",
      "| 에폭 5 |  반복 121 / 499 | 시간 187[s] | 손실 2.50\n",
      "| 에폭 5 |  반복 141 / 499 | 시간 189[s] | 손실 2.50\n",
      "| 에폭 5 |  반복 161 / 499 | 시간 192[s] | 손실 2.48\n",
      "| 에폭 5 |  반복 181 / 499 | 시간 194[s] | 손실 2.51\n",
      "| 에폭 5 |  반복 201 / 499 | 시간 195[s] | 손실 2.49\n",
      "| 에폭 5 |  반복 221 / 499 | 시간 197[s] | 손실 2.52\n",
      "| 에폭 5 |  반복 241 / 499 | 시간 199[s] | 손실 2.50\n",
      "| 에폭 5 |  반복 261 / 499 | 시간 201[s] | 손실 2.50\n",
      "| 에폭 5 |  반복 281 / 499 | 시간 203[s] | 손실 2.50\n",
      "| 에폭 5 |  반복 301 / 499 | 시간 206[s] | 손실 2.50\n",
      "| 에폭 5 |  반복 321 / 499 | 시간 209[s] | 손실 2.50\n",
      "| 에폭 5 |  반복 341 / 499 | 시간 210[s] | 손실 2.52\n",
      "| 에폭 5 |  반복 361 / 499 | 시간 212[s] | 손실 2.50\n",
      "| 에폭 5 |  반복 381 / 499 | 시간 213[s] | 손실 2.51\n",
      "| 에폭 5 |  반복 401 / 499 | 시간 214[s] | 손실 2.52\n",
      "| 에폭 5 |  반복 421 / 499 | 시간 216[s] | 손실 2.50\n",
      "| 에폭 5 |  반복 441 / 499 | 시간 217[s] | 손실 2.49\n",
      "| 에폭 5 |  반복 461 / 499 | 시간 218[s] | 손실 2.49\n",
      "| 에폭 5 |  반복 481 / 499 | 시간 220[s] | 손실 2.51\n",
      "| 에폭 6 |  반복 1 / 499 | 시간 222[s] | 손실 2.51\n",
      "| 에폭 6 |  반복 21 / 499 | 시간 223[s] | 손실 2.46\n",
      "| 에폭 6 |  반복 41 / 499 | 시간 225[s] | 손실 2.44\n",
      "| 에폭 6 |  반복 61 / 499 | 시간 227[s] | 손실 2.47\n",
      "| 에폭 6 |  반복 81 / 499 | 시간 229[s] | 손실 2.46\n",
      "| 에폭 6 |  반복 101 / 499 | 시간 231[s] | 손실 2.45\n",
      "| 에폭 6 |  반복 121 / 499 | 시간 233[s] | 손실 2.46\n",
      "| 에폭 6 |  반복 141 / 499 | 시간 235[s] | 손실 2.47\n",
      "| 에폭 6 |  반복 161 / 499 | 시간 237[s] | 손실 2.47\n",
      "| 에폭 6 |  반복 181 / 499 | 시간 239[s] | 손실 2.47\n",
      "| 에폭 6 |  반복 201 / 499 | 시간 241[s] | 손실 2.47\n",
      "| 에폭 6 |  반복 221 / 499 | 시간 243[s] | 손실 2.47\n",
      "| 에폭 6 |  반복 241 / 499 | 시간 245[s] | 손실 2.47\n",
      "| 에폭 6 |  반복 261 / 499 | 시간 247[s] | 손실 2.48\n",
      "| 에폭 6 |  반복 281 / 499 | 시간 249[s] | 손실 2.43\n",
      "| 에폭 6 |  반복 301 / 499 | 시간 252[s] | 손실 2.44\n",
      "| 에폭 6 |  반복 321 / 499 | 시간 254[s] | 손실 2.45\n",
      "| 에폭 6 |  반복 341 / 499 | 시간 256[s] | 손실 2.45\n",
      "| 에폭 6 |  반복 361 / 499 | 시간 258[s] | 손실 2.45\n",
      "| 에폭 6 |  반복 381 / 499 | 시간 260[s] | 손실 2.45\n",
      "| 에폭 6 |  반복 401 / 499 | 시간 263[s] | 손실 2.47\n",
      "| 에폭 6 |  반복 421 / 499 | 시간 265[s] | 손실 2.47\n",
      "| 에폭 6 |  반복 441 / 499 | 시간 267[s] | 손실 2.47\n",
      "| 에폭 6 |  반복 461 / 499 | 시간 269[s] | 손실 2.45\n",
      "| 에폭 6 |  반복 481 / 499 | 시간 270[s] | 손실 2.44\n",
      "| 에폭 7 |  반복 1 / 499 | 시간 272[s] | 손실 2.41\n",
      "| 에폭 7 |  반복 21 / 499 | 시간 273[s] | 손실 2.39\n",
      "| 에폭 7 |  반복 41 / 499 | 시간 275[s] | 손실 2.44\n",
      "| 에폭 7 |  반복 61 / 499 | 시간 277[s] | 손실 2.40\n",
      "| 에폭 7 |  반복 81 / 499 | 시간 279[s] | 손실 2.41\n",
      "| 에폭 7 |  반복 101 / 499 | 시간 281[s] | 손실 2.42\n",
      "| 에폭 7 |  반복 121 / 499 | 시간 282[s] | 손실 2.43\n",
      "| 에폭 7 |  반복 141 / 499 | 시간 284[s] | 손실 2.41\n",
      "| 에폭 7 |  반복 161 / 499 | 시간 286[s] | 손실 2.42\n",
      "| 에폭 7 |  반복 181 / 499 | 시간 288[s] | 손실 2.43\n",
      "| 에폭 7 |  반복 201 / 499 | 시간 289[s] | 손실 2.41\n",
      "| 에폭 7 |  반복 221 / 499 | 시간 291[s] | 손실 2.37\n",
      "| 에폭 7 |  반복 241 / 499 | 시간 292[s] | 손실 2.40\n",
      "| 에폭 7 |  반복 261 / 499 | 시간 293[s] | 손실 2.40\n",
      "| 에폭 7 |  반복 281 / 499 | 시간 294[s] | 손실 2.38\n",
      "| 에폭 7 |  반복 301 / 499 | 시간 296[s] | 손실 2.44\n",
      "| 에폭 7 |  반복 321 / 499 | 시간 297[s] | 손실 2.40\n",
      "| 에폭 7 |  반복 341 / 499 | 시간 298[s] | 손실 2.41\n",
      "| 에폭 7 |  반복 361 / 499 | 시간 300[s] | 손실 2.43\n",
      "| 에폭 7 |  반복 381 / 499 | 시간 301[s] | 손실 2.40\n",
      "| 에폭 7 |  반복 401 / 499 | 시간 302[s] | 손실 2.40\n",
      "| 에폭 7 |  반복 421 / 499 | 시간 303[s] | 손실 2.41\n",
      "| 에폭 7 |  반복 441 / 499 | 시간 305[s] | 손실 2.38\n",
      "| 에폭 7 |  반복 461 / 499 | 시간 306[s] | 손실 2.38\n",
      "| 에폭 7 |  반복 481 / 499 | 시간 307[s] | 손실 2.40\n",
      "| 에폭 8 |  반복 1 / 499 | 시간 309[s] | 손실 2.41\n",
      "| 에폭 8 |  반복 21 / 499 | 시간 311[s] | 손실 2.35\n",
      "| 에폭 8 |  반복 41 / 499 | 시간 313[s] | 손실 2.33\n",
      "| 에폭 8 |  반복 61 / 499 | 시간 315[s] | 손실 2.33\n",
      "| 에폭 8 |  반복 81 / 499 | 시간 317[s] | 손실 2.33\n",
      "| 에폭 8 |  반복 101 / 499 | 시간 319[s] | 손실 2.38\n",
      "| 에폭 8 |  반복 121 / 499 | 시간 321[s] | 손실 2.36\n",
      "| 에폭 8 |  반복 141 / 499 | 시간 323[s] | 손실 2.34\n",
      "| 에폭 8 |  반복 161 / 499 | 시간 325[s] | 손실 2.36\n",
      "| 에폭 8 |  반복 181 / 499 | 시간 326[s] | 손실 2.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 8 |  반복 201 / 499 | 시간 328[s] | 손실 2.34\n",
      "| 에폭 8 |  반복 221 / 499 | 시간 330[s] | 손실 2.36\n",
      "| 에폭 8 |  반복 241 / 499 | 시간 331[s] | 손실 2.33\n",
      "| 에폭 8 |  반복 261 / 499 | 시간 334[s] | 손실 2.35\n",
      "| 에폭 8 |  반복 281 / 499 | 시간 336[s] | 손실 2.35\n",
      "| 에폭 8 |  반복 301 / 499 | 시간 338[s] | 손실 2.35\n",
      "| 에폭 8 |  반복 321 / 499 | 시간 340[s] | 손실 2.33\n",
      "| 에폭 8 |  반복 341 / 499 | 시간 341[s] | 손실 2.35\n",
      "| 에폭 8 |  반복 361 / 499 | 시간 343[s] | 손실 2.35\n",
      "| 에폭 8 |  반복 381 / 499 | 시간 345[s] | 손실 2.35\n",
      "| 에폭 8 |  반복 401 / 499 | 시간 346[s] | 손실 2.34\n",
      "| 에폭 8 |  반복 421 / 499 | 시간 348[s] | 손실 2.33\n",
      "| 에폭 8 |  반복 441 / 499 | 시간 350[s] | 손실 2.34\n",
      "| 에폭 8 |  반복 461 / 499 | 시간 351[s] | 손실 2.35\n",
      "| 에폭 8 |  반복 481 / 499 | 시간 353[s] | 손실 2.33\n",
      "| 에폭 9 |  반복 1 / 499 | 시간 354[s] | 손실 2.31\n",
      "| 에폭 9 |  반복 21 / 499 | 시간 356[s] | 손실 2.26\n",
      "| 에폭 9 |  반복 41 / 499 | 시간 357[s] | 손실 2.25\n",
      "| 에폭 9 |  반복 61 / 499 | 시간 359[s] | 손실 2.24\n",
      "| 에폭 9 |  반복 81 / 499 | 시간 361[s] | 손실 2.26\n",
      "| 에폭 9 |  반복 101 / 499 | 시간 363[s] | 손실 2.29\n",
      "| 에폭 9 |  반복 121 / 499 | 시간 365[s] | 손실 2.28\n",
      "| 에폭 9 |  반복 141 / 499 | 시간 366[s] | 손실 2.29\n",
      "| 에폭 9 |  반복 161 / 499 | 시간 368[s] | 손실 2.30\n",
      "| 에폭 9 |  반복 181 / 499 | 시간 369[s] | 손실 2.31\n",
      "| 에폭 9 |  반복 201 / 499 | 시간 370[s] | 손실 2.30\n",
      "| 에폭 9 |  반복 221 / 499 | 시간 372[s] | 손실 2.24\n",
      "| 에폭 9 |  반복 241 / 499 | 시간 373[s] | 손실 2.26\n",
      "| 에폭 9 |  반복 261 / 499 | 시간 375[s] | 손실 2.28\n",
      "| 에폭 9 |  반복 281 / 499 | 시간 376[s] | 손실 2.27\n",
      "| 에폭 9 |  반복 301 / 499 | 시간 377[s] | 손실 2.32\n",
      "| 에폭 9 |  반복 321 / 499 | 시간 379[s] | 손실 2.29\n",
      "| 에폭 9 |  반복 341 / 499 | 시간 380[s] | 손실 2.26\n",
      "| 에폭 9 |  반복 361 / 499 | 시간 381[s] | 손실 2.28\n",
      "| 에폭 9 |  반복 381 / 499 | 시간 382[s] | 손실 2.26\n",
      "| 에폭 9 |  반복 401 / 499 | 시간 384[s] | 손실 2.27\n",
      "| 에폭 9 |  반복 421 / 499 | 시간 385[s] | 손실 2.32\n",
      "| 에폭 9 |  반복 441 / 499 | 시간 386[s] | 손실 2.24\n",
      "| 에폭 9 |  반복 461 / 499 | 시간 388[s] | 손실 2.28\n",
      "| 에폭 9 |  반복 481 / 499 | 시간 389[s] | 손실 2.29\n",
      "| 에폭 10 |  반복 1 / 499 | 시간 390[s] | 손실 2.26\n",
      "| 에폭 10 |  반복 21 / 499 | 시간 391[s] | 손실 2.20\n",
      "| 에폭 10 |  반복 41 / 499 | 시간 393[s] | 손실 2.20\n",
      "| 에폭 10 |  반복 61 / 499 | 시간 395[s] | 손실 2.21\n",
      "| 에폭 10 |  반복 81 / 499 | 시간 397[s] | 손실 2.21\n",
      "| 에폭 10 |  반복 101 / 499 | 시간 398[s] | 손실 2.21\n",
      "| 에폭 10 |  반복 121 / 499 | 시간 399[s] | 손실 2.22\n",
      "| 에폭 10 |  반복 141 / 499 | 시간 401[s] | 손실 2.19\n",
      "| 에폭 10 |  반복 161 / 499 | 시간 402[s] | 손실 2.24\n",
      "| 에폭 10 |  반복 181 / 499 | 시간 404[s] | 손실 2.20\n",
      "| 에폭 10 |  반복 201 / 499 | 시간 405[s] | 손실 2.20\n",
      "| 에폭 10 |  반복 221 / 499 | 시간 407[s] | 손실 2.21\n",
      "| 에폭 10 |  반복 241 / 499 | 시간 408[s] | 손실 2.21\n",
      "| 에폭 10 |  반복 261 / 499 | 시간 410[s] | 손실 2.20\n",
      "| 에폭 10 |  반복 281 / 499 | 시간 411[s] | 손실 2.23\n",
      "| 에폭 10 |  반복 301 / 499 | 시간 414[s] | 손실 2.23\n",
      "| 에폭 10 |  반복 321 / 499 | 시간 418[s] | 손실 2.23\n",
      "| 에폭 10 |  반복 341 / 499 | 시간 420[s] | 손실 2.22\n",
      "| 에폭 10 |  반복 361 / 499 | 시간 422[s] | 손실 2.19\n",
      "| 에폭 10 |  반복 381 / 499 | 시간 424[s] | 손실 2.23\n",
      "| 에폭 10 |  반복 401 / 499 | 시간 426[s] | 손실 2.20\n",
      "| 에폭 10 |  반복 421 / 499 | 시간 428[s] | 손실 2.22\n",
      "| 에폭 10 |  반복 441 / 499 | 시간 430[s] | 손실 2.21\n",
      "| 에폭 10 |  반복 461 / 499 | 시간 432[s] | 손실 2.19\n",
      "| 에폭 10 |  반복 481 / 499 | 시간 433[s] | 손실 2.20\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = CBOW(vocab_size, hidden_size, window_size, corpus)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model,optimizer)\n",
    "\n",
    "# 학습 : 50000개 일때 약 7분 소요\n",
    "trainer.fit(contexts, target, max_epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나중에 사용할 수 있도록 필요한 데이터 저장\n",
    "word_vecs = model.word_vecs\n",
    "\n",
    "params = {}\n",
    "params['word_vecs'] = word_vecs.astype(np.float16)\n",
    "params['word_to_id'] = word_to_id\n",
    "params['id_to_word'] = id_to_word\n",
    "pkl_file = 'cbow_params.pkl'  # 저장할 파일\n",
    "with open(pkl_file, 'wb') as f:\n",
    "    pickle.dump(params, f, -1) # 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5276, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.04960905,  0.02695149,  0.00817851, ...,  0.04403228,\n",
       "        -0.03093504,  0.10660045],\n",
       "       [-0.00108058,  0.0557363 ,  0.14048922, ...,  0.04365902,\n",
       "        -0.07825884,  0.20460749],\n",
       "       [-0.04039905,  0.01439103,  0.19065669, ..., -0.01758152,\n",
       "        -0.06686762,  0.21547836],\n",
       "       ...,\n",
       "       [ 0.30001032,  0.2045574 ,  0.35228336, ...,  0.01926974,\n",
       "        -0.02192492,  0.3850582 ],\n",
       "       [ 0.23011799,  0.2963479 ,  0.24182451, ...,  0.12436571,\n",
       "        -0.19134884,  0.2318561 ],\n",
       "       [-0.08581711, -0.13982452, -0.06632292, ...,  0.13611177,\n",
       "        -0.02076899,  0.04800173]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# W_in :단어의 분산 표현\n",
    "print(model.word_vecs.shape)\n",
    "model.word_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " we: 0.6103515625\n",
      " someone: 0.59130859375\n",
      " i: 0.55419921875\n",
      " something: 0.48974609375\n",
      " anyone: 0.47314453125\n",
      "\n",
      "[query] year\n",
      " month: 0.71875\n",
      " week: 0.65234375\n",
      " spring: 0.62744140625\n",
      " summer: 0.6259765625\n",
      " decade: 0.603515625\n",
      "\n",
      "[query] car\n",
      " luxury: 0.497314453125\n",
      " arabia: 0.47802734375\n",
      " auto: 0.47119140625\n",
      " disk-drive: 0.450927734375\n",
      " travel: 0.4091796875\n",
      "\n",
      "[query] toyota\n",
      " ford: 0.55078125\n",
      " instrumentation: 0.509765625\n",
      " mazda: 0.49365234375\n",
      " bethlehem: 0.47509765625\n",
      " nissan: 0.474853515625\n"
     ]
    }
   ],
   "source": [
    "pkl_file = 'cbow_params_epoch10.pkl'\n",
    "\n",
    "with open(pkl_file, 'rb') as f :\n",
    "    params = pickle.load(f)  # 읽어오기\n",
    "    word_vecs = params['word_vecs']\n",
    "    word_to_id = params['word_to_id']\n",
    "    id_to_word = params['id_to_word']\n",
    "    \n",
    "# 가장 비슷한(most simialr) 단어 뽑기\n",
    "querys = ['you','year','car','toyota']\n",
    "for query in querys:\n",
    "    most_similar(query,word_to_id,id_to_word,word_vecs,top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    if x.ndim == 2:\n",
    "        s = np.sqrt((x * x).sum(1))\n",
    "        x /= s.reshape((s.shape[0], 1))\n",
    "    elif x.ndim == 1:\n",
    "        s = np.sqrt((x * x).sum())\n",
    "        x /= s\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(a, b, c, word_to_id, id_to_word, word_matrix, top=5, answer=None):\n",
    "    for word in (a, b, c):\n",
    "        if word not in word_to_id:\n",
    "            print('%s(을)를 찾을 수 없습니다.' % word)\n",
    "            return\n",
    "\n",
    "    print('\\n[analogy] ' + a + ':' + b + ' = ' + c + ':?')\n",
    "    a_vec, b_vec, c_vec = word_matrix[word_to_id[a]], word_matrix[word_to_id[b]], word_matrix[word_to_id[c]]\n",
    "    query_vec = b_vec - a_vec + c_vec\n",
    "    query_vec = normalize(query_vec)\n",
    "\n",
    "    similarity = np.dot(word_matrix, query_vec)\n",
    "\n",
    "    if answer is not None:\n",
    "        print(\"==>\" + answer + \":\" + str(np.dot(word_matrix[word_to_id[answer]], query_vec)))\n",
    "\n",
    "    count = 0\n",
    "    for i in (-1 * similarity).argsort():\n",
    "        if np.isnan(similarity[i]):\n",
    "            continue\n",
    "        if id_to_word[i] in (a, b, c):\n",
    "            continue\n",
    "        print(' {0}: {1}'.format(id_to_word[i], similarity[i]))\n",
    "\n",
    "        count += 1\n",
    "        if count >= top:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[analogy] king:man = queen:?\n",
      " woman: 5.16015625\n",
      " veto: 4.9296875\n",
      " ounce: 4.69140625\n",
      " earthquake: 4.6328125\n",
      " successor: 4.609375\n",
      "\n",
      "[analogy] take:took = go:?\n",
      " went: 4.55078125\n",
      " points: 4.25\n",
      " began: 4.09375\n",
      " comes: 3.98046875\n",
      " oct.: 3.90625\n",
      "\n",
      "[analogy] car:cars = child:?\n",
      " children: 5.21875\n",
      " average: 4.7265625\n",
      " yield: 4.20703125\n",
      " cattle: 4.1875\n",
      " priced: 4.1796875\n",
      "\n",
      "[analogy] good:better = bad:?\n",
      " more: 6.6484375\n",
      " less: 6.0625\n",
      " rather: 5.21875\n",
      " slower: 4.734375\n",
      " greater: 4.671875\n"
     ]
    }
   ],
   "source": [
    "# 유추(analogy) 작업\n",
    "analogy('king', 'man', 'queen',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('take', 'took', 'go',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('car', 'cars', 'child',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('good', 'better', 'bad',  word_to_id, id_to_word, word_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SkipGram 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGram:\n",
    "    def __init__(self, vocab_size, hidden_size, window_size, corpus):\n",
    "        V, H = vocab_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 가중치 초기화\n",
    "        W_in = 0.01 * rn(V, H).astype('f')\n",
    "        W_out = 0.01 * rn(V, H).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.in_layer = Embedding(W_in)\n",
    "        self.loss_layers = []\n",
    "        for i in range(2 * window_size):\n",
    "            layer = NegativeSamplingLoss(W_out, corpus, power=0.75, sample_size=5)\n",
    "            self.loss_layers.append(layer)\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        layers = [self.in_layer] + self.loss_layers\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "        # 인스턴스 변수에 단어의 분산 표현을 저장한다.\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "    def forward(self, contexts, target):\n",
    "        h = self.in_layer.forward(target)\n",
    "\n",
    "        loss = 0\n",
    "        for i, layer in enumerate(self.loss_layers):\n",
    "            loss += layer.forward(h, contexts[:, i])\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dh = 0\n",
    "        for i, layer in enumerate(self.loss_layers):\n",
    "            dh += layer.backward(dout)\n",
    "        self.in_layer.backward(dh)\n",
    "        return None      \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SkipGram 모델 학습 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "929589\n"
     ]
    }
   ],
   "source": [
    "from dataset import ptb\n",
    "import pickle\n",
    "\n",
    "# 하이퍼 파라미터 설정\n",
    "window_size = 5\n",
    "# window_size = 2\n",
    "\n",
    "hidden_size = 100\n",
    "batch_size = 100\n",
    "max_epoch = 10  # 10회 이상\n",
    "max_epoch = 2   # Test용\n",
    "\n",
    "# 데이터 읽기\n",
    "# 전체 데이터 모두 사용시  # 전체 데이터로 epoch 8회 학습 ==> '약 7시간 소요'\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "print(vocab_size)  # 10000\n",
    "print(len(corpus)) # 929589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "5276\n",
      "5276\n",
      "5276\n"
     ]
    }
   ],
   "source": [
    "# PTB 데이터 중 일부만 사용시 :  50000 corpus\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "\n",
    "corpus_size = 50000\n",
    "corpus = corpus[:corpus_size]\n",
    "\n",
    "vocab_size = int(max(corpus) + 1)  # 5276\n",
    "\n",
    "temp1,temp2 = {},{}\n",
    "for k in range(vocab_size):\n",
    "    word1= list(word_to_id.keys())[k]    \n",
    "    id1 = list(word_to_id.values())[k] \n",
    "    temp1[word1] = id1\n",
    "    \n",
    "    word2= list(id_to_word.keys())[k]    \n",
    "    id2 = list(id_to_word.values())[k] \n",
    "    temp2[word2] = id2\n",
    "    \n",
    "word_to_id = temp1\n",
    "id_to_word =temp2\n",
    "\n",
    "print(len(corpus))\n",
    "print(vocab_size)      # 5276 \n",
    "print(len(word_to_id))\n",
    "print(len(id_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49990, 10) (49990,)\n"
     ]
    }
   ],
   "source": [
    "contexts,target = create_contexts_target(corpus,window_size)\n",
    "# print(corpus[:100])\n",
    "print(contexts.shape,target.shape) #(49990, 10), (49990,)\n",
    "# print(contexts[:100])             \n",
    "# print(target[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 499 | 시간 0[s] | 손실 41.59\n",
      "| 에폭 1 |  반복 21 / 499 | 시간 7[s] | 손실 41.58\n",
      "| 에폭 1 |  반복 41 / 499 | 시간 18[s] | 손실 41.44\n",
      "| 에폭 1 |  반복 61 / 499 | 시간 26[s] | 손실 40.89\n",
      "| 에폭 1 |  반복 81 / 499 | 시간 34[s] | 손실 39.67\n",
      "| 에폭 1 |  반복 101 / 499 | 시간 44[s] | 손실 37.93\n",
      "| 에폭 1 |  반복 121 / 499 | 시간 52[s] | 손실 36.32\n",
      "| 에폭 1 |  반복 141 / 499 | 시간 58[s] | 손실 34.76\n",
      "| 에폭 1 |  반복 161 / 499 | 시간 64[s] | 손실 33.66\n",
      "| 에폭 1 |  반복 181 / 499 | 시간 72[s] | 손실 32.95\n",
      "| 에폭 1 |  반복 201 / 499 | 시간 80[s] | 손실 32.14\n",
      "| 에폭 1 |  반복 221 / 499 | 시간 87[s] | 손실 31.64\n",
      "| 에폭 1 |  반복 241 / 499 | 시간 98[s] | 손실 31.07\n",
      "| 에폭 1 |  반복 261 / 499 | 시간 106[s] | 손실 30.80\n",
      "| 에폭 1 |  반복 281 / 499 | 시간 114[s] | 손실 30.32\n",
      "| 에폭 1 |  반복 301 / 499 | 시간 120[s] | 손실 30.21\n",
      "| 에폭 1 |  반복 321 / 499 | 시간 126[s] | 손실 29.90\n",
      "| 에폭 1 |  반복 341 / 499 | 시간 132[s] | 손실 29.89\n",
      "| 에폭 1 |  반복 361 / 499 | 시간 141[s] | 손실 29.48\n",
      "| 에폭 1 |  반복 381 / 499 | 시간 150[s] | 손실 29.18\n",
      "| 에폭 1 |  반복 401 / 499 | 시간 160[s] | 손실 29.11\n",
      "| 에폭 1 |  반복 421 / 499 | 시간 166[s] | 손실 28.91\n",
      "| 에폭 1 |  반복 441 / 499 | 시간 175[s] | 손실 28.84\n",
      "| 에폭 1 |  반복 461 / 499 | 시간 181[s] | 손실 28.72\n",
      "| 에폭 1 |  반복 481 / 499 | 시간 187[s] | 손실 28.57\n",
      "| 에폭 2 |  반복 1 / 499 | 시간 193[s] | 손실 28.20\n",
      "| 에폭 2 |  반복 21 / 499 | 시간 199[s] | 손실 27.69\n",
      "| 에폭 2 |  반복 41 / 499 | 시간 207[s] | 손실 27.60\n",
      "| 에폭 2 |  반복 61 / 499 | 시간 213[s] | 손실 27.50\n",
      "| 에폭 2 |  반복 81 / 499 | 시간 220[s] | 손실 27.38\n",
      "| 에폭 2 |  반복 101 / 499 | 시간 228[s] | 손실 27.31\n",
      "| 에폭 2 |  반복 121 / 499 | 시간 236[s] | 손실 27.35\n",
      "| 에폭 2 |  반복 141 / 499 | 시간 245[s] | 손실 27.14\n",
      "| 에폭 2 |  반복 161 / 499 | 시간 256[s] | 손실 27.08\n",
      "| 에폭 2 |  반복 181 / 499 | 시간 265[s] | 손실 27.11\n",
      "| 에폭 2 |  반복 201 / 499 | 시간 273[s] | 손실 26.99\n",
      "| 에폭 2 |  반복 221 / 499 | 시간 281[s] | 손실 26.94\n",
      "| 에폭 2 |  반복 241 / 499 | 시간 289[s] | 손실 26.86\n",
      "| 에폭 2 |  반복 261 / 499 | 시간 297[s] | 손실 26.76\n",
      "| 에폭 2 |  반복 281 / 499 | 시간 307[s] | 손실 26.65\n",
      "| 에폭 2 |  반복 301 / 499 | 시간 317[s] | 손실 26.68\n",
      "| 에폭 2 |  반복 321 / 499 | 시간 326[s] | 손실 26.80\n",
      "| 에폭 2 |  반복 341 / 499 | 시간 333[s] | 손실 26.81\n",
      "| 에폭 2 |  반복 361 / 499 | 시간 340[s] | 손실 26.53\n",
      "| 에폭 2 |  반복 381 / 499 | 시간 346[s] | 손실 26.39\n",
      "| 에폭 2 |  반복 401 / 499 | 시간 352[s] | 손실 26.60\n",
      "| 에폭 2 |  반복 421 / 499 | 시간 358[s] | 손실 26.67\n",
      "| 에폭 2 |  반복 441 / 499 | 시간 364[s] | 손실 26.42\n",
      "| 에폭 2 |  반복 461 / 499 | 시간 370[s] | 손실 26.35\n",
      "| 에폭 2 |  반복 481 / 499 | 시간 375[s] | 손실 26.49\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = SkipGram(vocab_size, hidden_size, window_size, corpus)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model,optimizer)\n",
    "\n",
    "# 학습 : 50000개 일때 약  분 소요\n",
    "trainer.fit(contexts, target, max_epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나중에 사용할 수 있도록 필요한 데이터 저장\n",
    "word_vecs = model.word_vecs\n",
    "\n",
    "params = {}\n",
    "params['word_vecs'] = word_vecs.astype(np.float16)\n",
    "params['word_to_id'] = word_to_id\n",
    "params['id_to_word'] = id_to_word\n",
    "pkl_file = 'skigram_params.pkl'  # 저장할 파일\n",
    "with open(pkl_file, 'wb') as f:\n",
    "    pickle.dump(params, f, -1) # 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5276, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.01469743,  0.00927876, -0.01702363, ...,  0.01778063,\n",
       "        -0.01863942, -0.01310235],\n",
       "       [-0.00369291, -0.00021643, -0.00877899, ..., -0.00915353,\n",
       "         0.00029852, -0.0051466 ],\n",
       "       [ 0.00797196, -0.00773571, -0.00296781, ...,  0.00938755,\n",
       "        -0.00778373, -0.01221906],\n",
       "       ...,\n",
       "       [ 0.02982701,  0.02626465, -0.03041195, ...,  0.04058851,\n",
       "         0.02885516, -0.01740751],\n",
       "       [ 0.02953697,  0.02640967, -0.02040264, ...,  0.03913492,\n",
       "         0.01929725, -0.043809  ],\n",
       "       [ 0.04264574,  0.04548058, -0.03616559, ...,  0.05097941,\n",
       "         0.0479342 , -0.03317109]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# W_in :단어의 분산 표현\n",
    "print(model.word_vecs.shape)\n",
    "model.word_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip-Gram 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " yourself: 0.693359375\n",
      " anybody: 0.666015625\n",
      " i: 0.66015625\n",
      " somebody: 0.6328125\n",
      " your: 0.63134765625\n",
      "\n",
      "[query] year\n",
      " month: 0.60986328125\n",
      " earlier: 0.5537109375\n",
      " week: 0.5419921875\n",
      " quarter: 0.541015625\n",
      " fiscal: 0.53759765625\n",
      "\n",
      "[query] car\n",
      " cars: 0.65380859375\n",
      " luxury: 0.58203125\n",
      " mazda: 0.54638671875\n",
      " beretta: 0.52099609375\n",
      " truck: 0.51513671875\n",
      "\n",
      "[query] toyota\n",
      " lexus: 0.7197265625\n",
      " honda: 0.68359375\n",
      " motor: 0.68115234375\n",
      " infiniti: 0.6787109375\n",
      " mazda: 0.6318359375\n"
     ]
    }
   ],
   "source": [
    "pkl_file = 'skipgram_params_epoch08.pkl'\n",
    "\n",
    "with open(pkl_file, 'rb') as f :\n",
    "    params = pickle.load(f)  # 읽어오기\n",
    "    word_vecs = params['word_vecs']\n",
    "    word_to_id = params['word_to_id']\n",
    "    id_to_word = params['id_to_word']\n",
    "    \n",
    "# 가장 비슷한(most simialr) 단어 뽑기\n",
    "querys = ['you','year','car','toyota']\n",
    "for query in querys:\n",
    "    most_similar(query,word_to_id,id_to_word,word_vecs,top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    if x.ndim == 2:\n",
    "        s = np.sqrt((x * x).sum(1))\n",
    "        x /= s.reshape((s.shape[0], 1))\n",
    "    elif x.ndim == 1:\n",
    "        s = np.sqrt((x * x).sum())\n",
    "        x /= s\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(a, b, c, word_to_id, id_to_word, word_matrix, top=5, answer=None):\n",
    "    for word in (a, b, c):\n",
    "        if word not in word_to_id:\n",
    "            print('%s(을)를 찾을 수 없습니다.' % word)\n",
    "            return\n",
    "\n",
    "    print('\\n[analogy] ' + a + ':' + b + ' = ' + c + ':?')\n",
    "    a_vec, b_vec, c_vec = word_matrix[word_to_id[a]], word_matrix[word_to_id[b]], word_matrix[word_to_id[c]]\n",
    "    query_vec = b_vec - a_vec + c_vec\n",
    "    query_vec = normalize(query_vec)\n",
    "\n",
    "    similarity = np.dot(word_matrix, query_vec)\n",
    "\n",
    "    if answer is not None:\n",
    "        print(\"==>\" + answer + \":\" + str(np.dot(word_matrix[word_to_id[answer]], query_vec)))\n",
    "\n",
    "    count = 0\n",
    "    for i in (-1 * similarity).argsort():\n",
    "        if np.isnan(similarity[i]):\n",
    "            continue\n",
    "        if id_to_word[i] in (a, b, c):\n",
    "            continue\n",
    "        print(' {0}: {1}'.format(id_to_word[i], similarity[i]))\n",
    "\n",
    "        count += 1\n",
    "        if count >= top:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[analogy] king:man = queen:?\n",
      " teacher: 1.90234375\n",
      " incest: 1.8935546875\n",
      " hero: 1.736328125\n",
      " mystery: 1.736328125\n",
      " duck: 1.62109375\n",
      "\n",
      "[analogy] take:took = go:?\n",
      " ran: 1.66796875\n",
      " went: 1.5166015625\n",
      " walked: 1.4921875\n",
      " amsterdam: 1.4775390625\n",
      " pricings: 1.41015625\n",
      "\n",
      "[analogy] car:cars = child:?\n",
      " rape: 2.439453125\n",
      " adults: 2.2578125\n",
      " incest: 1.935546875\n",
      " districts: 1.818359375\n",
      " children: 1.806640625\n",
      "\n",
      "[analogy] good:better = bad:?\n",
      " ever: 1.5927734375\n",
      " vary: 1.4326171875\n",
      " comparable: 1.4189453125\n",
      " ca: 1.3212890625\n",
      " abbie: 1.306640625\n"
     ]
    }
   ],
   "source": [
    "# 유추(analogy) 작업\n",
    "analogy('king', 'man', 'queen',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('take', 'took', 'go',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('car', 'cars', 'child',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('good', 'better', 'bad',  word_to_id, id_to_word, word_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
