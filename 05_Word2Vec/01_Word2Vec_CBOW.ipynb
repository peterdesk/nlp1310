{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론(예측) 기반 기법과 신경망\n",
    "\n",
    "## word2vec : 워드투벡터\n",
    "2013년 구글의 토마스미콜로프(Tomas Mikolov)의 팀이 개발<br>\n",
    "<b>word2vec</b> 알고리즘은 <b>신경망 모델</b>을 사용 하여 큰 텍스트 코퍼스에서 단어 연관성을 학습. 학습이 끝나면 이러한 모델은 동의어 단어를 감지하거나 부분 문장에 대한 추가 단어를 제안 할 수 있다. word2vec는 <b>벡터</b> 라고하는 특정 숫자 목록을 사용하여 각각의 고유 한 단어를 나타낸다 . 벡터는 간단한 수학적 함수 ( 벡터 간의 코사인 유사성 ) 가 해당 벡터가 나타내는 단어 간의 의미 유사성 수준을 나타내 도록 신중하게 선택 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] 신경망에서의 단어 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\n",
      " [[1 0 0 0 0 0 0]]\n",
      "W:\n",
      " [[-1.28538961  0.64792478 -0.37034692]\n",
      " [-1.32314326  0.22349505 -3.10678191]\n",
      " [ 1.0895167   1.81182082  0.22445226]\n",
      " [ 1.25819541 -1.11850756  0.48816333]\n",
      " [ 0.28208495 -1.10086583  0.08395836]\n",
      " [-0.42763555  1.3866479  -0.12573135]\n",
      " [-0.15107386 -0.55324631 -0.0185085 ]]\n",
      "h:\n",
      " [[-1.28538961  0.64792478 -0.37034692]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "text = 'You say goodbye and I say hello.' \n",
    "# {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n",
    "\n",
    "# 여기서 'you'만  one-hot 인코딩으로 표현\n",
    "c = np.array([[1,0,0,0,0,0,0]])   # (1,7)\n",
    "print('c:\\n',c)\n",
    "\n",
    "W = np.random.randn(7,3)          # (7,3)\n",
    "print('W:\\n',W)\n",
    "\n",
    "h = np.matmul(c,W)    # (1,7) * (7,3) = (1,3)\n",
    "print('h:\\n',h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatMul:\n",
    "    def __init__(self,W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.x = None\n",
    "        \n",
    "    def forward(self,x):\n",
    "        W, = self.params\n",
    "        out = np.dot(x,W)\n",
    "        self.x = x\n",
    "        return out\n",
    "        \n",
    "    def backward(self,dout):\n",
    "        W = self.params\n",
    "        dx = np.dot(dout,W.T)\n",
    "        dw = np.dot(self.x.T,dout)\n",
    "        self.grads[0][...] = dw  # 깊은복사\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\n",
      " [[1 0 0 0 0 0 0]]\n",
      "W:\n",
      " [[-0.03242822  1.2190229   0.45928323]\n",
      " [-2.61749499  1.55165468  0.28560177]\n",
      " [ 0.74289918 -0.05973607  0.34769935]\n",
      " [-0.68861041  0.18058425 -0.28971501]\n",
      " [-1.04228678  0.93596162  0.10277779]\n",
      " [-0.43039547  0.50823827 -1.20898852]\n",
      " [-0.2251487   1.52103797 -0.52640616]]\n",
      "h:\n",
      " [[-0.03242822  1.2190229   0.45928323]]\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.' \n",
    "# {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n",
    "\n",
    "# 여기서 'you'만  one-hot 인코딩으로 표현\n",
    "c = np.array([[1,0,0,0,0,0,0]])   # (1,7)\n",
    "print('c:\\n',c)\n",
    "\n",
    "W = np.random.randn(7,3)          # (7,3)\n",
    "print('W:\\n',W)\n",
    "\n",
    "layer = MatMul(W)\n",
    "h = layer.forward(c)\n",
    "print('h:\\n',h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] 단순한 word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW (Continuous Bag of Words) 모델\n",
    "\n",
    "#### Word2Vec에는 CBOW(Continuous Bag of Words)와 Skip-Gram 두 가지 방식이 있다\n",
    "- $ CBOW $ 는 주변에 있는 단어들을 가지고, 중간에 있는 단어들을 예측하는 방법 <br>\n",
    "  타깃(target)은 중앙 단어 그 주변 단어들이 맥락(contexts)이다\n",
    "- $ Skip-Gram $ 은 중간에 있는 단어로 주변 단어들을 예측하는 방법\n",
    "\n",
    "#### BOW(Bag of Words) : 단어들의 순서는 전혀 고려하지 않고, 단어들의 출현 빈도(frequency)에만 집중하는 텍스트 데이터의 수치화 표현 방법\n",
    "\n",
    "BOW를 만드는 과정<br>\n",
    "(1) 우선, 각 단어의 고유한 인덱스(Index)를 부여한다.<br>\n",
    "(2) 각 인덱스의 위치에 단어 토큰의 등장 횟수를 기록한 벡터(Vector)를 만든다.<br>\n",
    "\n",
    "\"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\"<br>\n",
    "('정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9) <br>\n",
    "BOW: [1, 2, 1, 1, 2, 1, 1, 1, 1, 1]  ==> '가' 와 '물가상승률' 은 2회 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.07329764 0.54778421 0.69472239]] (1, 3)\n",
      "[[ 1.39817177  0.2844833  -0.64249062  0.76180552  0.51063952  1.21341815\n",
      "   1.32639781]] (1, 7)\n"
     ]
    }
   ],
   "source": [
    "# (CBOW 전체구조의 Preview)\n",
    "# 샘플 맥락 데이터 : 2개의 주변 단어를 맥락으로 중간 단어('say')를 예측\n",
    "\n",
    "text = 'You say goodbye and I say hello.' \n",
    "\n",
    "# 2개의 주변 단어를 one-hot 벡터 생성\n",
    "c0 = np.array([[1,0,0,0,0,0,0]])  # 'you' , (1,7)\n",
    "c1 = np.array([[0,0,1,0,0,0,0]])  # 'goodbye' , (1,7)\n",
    "\n",
    "# 가중치 초기화\n",
    "W_in = np.random.randn(7,3)\n",
    "W_out = np.random.randn(3,7)\n",
    "\n",
    "# 계층 생성\n",
    "in_layer0 = MatMul(W_in)\n",
    "in_layer1 = MatMul(W_in)\n",
    "out_layer = MatMul(W_out)\n",
    "\n",
    "# 순전파\n",
    "h0 = in_layer0.forward(c0) # (1,7) * (7,3) = (1,3)\n",
    "h1 = in_layer1.forward(c1) # (1,7) * (7,3) = (1,3)\n",
    "h = 0.5*(h0 + h1)\n",
    "print(h,h.shape)\n",
    "s = out_layer.forward(h)   # (1,3) * (3,7) = (1,7)\n",
    "print(s,s.shape)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] 학습 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mynlp import preprocess\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.' \n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "print(corpus)      # 8 개\n",
    "print(id_to_word)  # 7 개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: [1 2 3 4 1 5]\n",
      "contexts:\n",
      " [[0 2]\n",
      " [1 3]\n",
      " [2 4]\n",
      " [3 1]\n",
      " [4 5]\n",
      " [1 6]]\n"
     ]
    }
   ],
   "source": [
    "# target : (6,)\n",
    "target = corpus[1:-1]  # 타깃(중간단어) : [1 2 3 4 1 5], 첫번째와 마지막 단어 제외\n",
    "print('target:',target)\n",
    "\n",
    "contexts = []\n",
    "for idx in range(1,len(corpus) - 1 ): # 1 to 6,6회 반복 , 중간단어마다 앞뒤 주변단어 조합 6가지\n",
    "    cs = []\n",
    "    for t in range(-1,2): # 3회, -1,0,1\n",
    "        if t == 0:\n",
    "            continue\n",
    "        cs.append(corpus[idx + t]) \n",
    "    contexts.append(cs)  \n",
    "\n",
    "print('contexts:\\n',np.array(contexts))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contexts와 target을 구하는 함수\n",
    "def create_contexts_target(corpus,window_size=1):\n",
    "    target = corpus[window_size:-window_size]  \n",
    "\n",
    "    contexts = []\n",
    "    for idx in(range(window_size,len(corpus) -window_size)): \n",
    "        cs = []\n",
    "        for t in range(-window_size,window_size+1) : \n",
    "            if t == 0: \n",
    "                continue\n",
    "            cs.append(corpus[idx + t]) \n",
    "        contexts.append(cs)\n",
    "    return np.array(contexts),np.array(target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [1 3]\n",
      " [2 4]\n",
      " [3 1]\n",
      " [4 5]\n",
      " [1 6]]\n"
     ]
    }
   ],
   "source": [
    "contexts,target = create_contexts_target(corpus,window_size=1)\n",
    "print(contexts)  # (6,2)\n",
    "\n",
    "# 맥락(contexts) : 예측할 단어의 주변 단어\n",
    "# {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n",
    "# window_size=1 일 경우 : 주변 단어를 중간 단어에 앞,뒤로 1개만 사용\n",
    "# [[0 2]   : 'you', 'goodbye'\n",
    "#  [1 3]   : 'say', 'and'\n",
    "#  [2 4]   : 'goodbye', 'i'\n",
    "#  [3 1]   : 'and', 'say'\n",
    "#  [4 5]   : 'i', 'hello'\n",
    "#  [1 6]]  : 'say', '.'\n",
    "\n",
    "# window_size=2 일 경우 : : 주변 단어를 중간 단어에 앞,뒤로 2개 사용\n",
    "# [[0 1 3 4]\n",
    "#  [1 2 4 1]\n",
    "#  [2 3 1 5]\n",
    "#  [3 4 5 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 1 5]\n"
     ]
    }
   ],
   "source": [
    "print(target)   # (6,)\n",
    "# 타깃(target) : 예측할 단어, 중간단어, 6개\n",
    "# ['say','goodbye','and','i','say','hello']\n",
    "# [1 2 3 4 1 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 맥락과 타깃을 원핫 표현으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫 변환 함수\n",
    "\n",
    "# target [1 2 3 4 1 5]을 변환하는 경우를 주석으로 설명 \n",
    "def convert_one_hot(corpus, vocab_size):  # [1 2 3 4 1 5], 7\n",
    "    N = corpus.shape[0] # (6,) --> 6\n",
    "\n",
    "    if corpus.ndim == 1: # target [1 2 3 4 1 5], 1차원인경우 ==> 2차원으로 출력\n",
    "        one_hot = np.zeros((N, vocab_size), dtype=np.int32) # 0으로 초기화된 (6,7) 2차원 배열 생성 \n",
    "        for idx, word_id in enumerate(corpus): # 6회 반복\n",
    "            one_hot[idx, word_id] = 1  # one_hot[0,1] = 1, [1,2]=1, [2,3] = 1,...,  [3,4],[4,1],[5,5] = 1...\n",
    "\n",
    "    elif corpus.ndim == 2: # contexts 2차원 인경우 ==> 3차원으로 출력\n",
    "        C = corpus.shape[1] # (6,2) --> 2\n",
    "        one_hot = np.zeros((N, C, vocab_size), dtype=np.int32) # 0으로 초기화된 (6,2,7) 3차원 배열 생성 \n",
    "        for idx_0, word_ids in enumerate(corpus): # 6회\n",
    "            for idx_1, word_id in enumerate(word_ids): #  2회\n",
    "                one_hot[idx_0, idx_1, word_id] = 1  \n",
    "\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_id)\n",
    "print(vocab_size) # 7\n",
    "\n",
    "target = convert_one_hot(target, vocab_size)\n",
    "contexts = convert_one_hot(contexts, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0]]\n",
      "(6, 7)\n"
     ]
    }
   ],
   "source": [
    "print(target)\n",
    "print(target.shape)  # (6, 7)\n",
    "# [1 2 3 4 1 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2, 7)\n",
      "[[[1 0 0 0 0 0 0]\n",
      "  [0 0 1 0 0 0 0]]\n",
      "\n",
      " [[0 1 0 0 0 0 0]\n",
      "  [0 0 0 1 0 0 0]]\n",
      "\n",
      " [[0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 1 0 0]]\n",
      "\n",
      " [[0 0 0 1 0 0 0]\n",
      "  [0 1 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 1 0 0]\n",
      "  [0 0 0 0 0 1 0]]\n",
      "\n",
      " [[0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 1]]]\n"
     ]
    }
   ],
   "source": [
    "print(contexts.shape) # (6, 2, 7)\n",
    "print(contexts)\n",
    "# [[0 2]\n",
    "#  [1 3]\n",
    "#  [2 4]\n",
    "#  [3 1]\n",
    "#  [4 5]\n",
    "#  [1 6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4] CBOW 신경망 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_layers import MatMul, SoftmaxWithLoss, SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 분류 모델 : Softmax 사용\n",
    "class SimpleCBOW :\n",
    "    def __init__(self, vocab_size, hidden_size): # 단어의 갯수: 7, 은닉층의 뉴런: 5\n",
    "        V,H = vocab_size, hidden_size\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        W_in = 0.01*np.random.randn(V,H).astype('f') # (7,5)\n",
    "        W_out = 0.01*np.random.randn(H,V).astype('f') # (5,7)\n",
    "        \n",
    "        # 계층 생성\n",
    "        self.in_layer0 = MatMul(W_in)\n",
    "        self.in_layer1 = MatMul(W_in)\n",
    "        self.out_layer = MatMul(W_out)\n",
    "        self.loss_layer = SoftmaxWithLoss()\n",
    "        \n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        layers = [self.in_layer0, self.in_layer1, self.out_layer]\n",
    "        self.params, self.grads = [],[]\n",
    "        for layer in layers : # 3회\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "        # 인스턴스 변수 단어의 분산 표현을 저장한다.    \n",
    "        self.word_vec = W_in    \n",
    "        \n",
    "    def predict(self,contexts):  # contexts :  (6, 2, 7)\n",
    "        \n",
    "        # (6,7) * (7,5)  =  (6,5)\n",
    "        h0 = self.in_layer0.forward(contexts[:,0]) #  (6,7)으로 입력, 맥락의 첫번째 단어 \n",
    "        h1 = self.in_layer1.forward(contexts[:,1]) #  (6,7)으로 입력, 맥락의 두번째 단어\n",
    "        \n",
    "        h = (h0 + h1) * 0.5  # 평균\n",
    "        \n",
    "        # (6,5) * (5,7) = (6,7)\n",
    "        score = self.out_layer.forward(h)\n",
    "        return self.loss_layer.softmax(score) # softmax()함수로 확률값으로 출력\n",
    "    \n",
    "    def forward(self,contexts,target):  # contexts :  (6, 2, 7), target : (6,7)\n",
    "        \n",
    "        # (6,7) * (7,5)  =  (6,5)\n",
    "        h0 = self.in_layer0.forward(contexts[:,0]) #  (6,7)으로 입력, 맥락의 첫번째 단어 \n",
    "        h1 = self.in_layer1.forward(contexts[:,1]) #  (6,7)으로 입력, 맥락의 두번째 단어\n",
    "        \n",
    "        h = (h0 + h1) * 0.5  # 평균\n",
    "        \n",
    "        # (6,5) * (5,7) = (6,7)\n",
    "        score = self.out_layer.forward(h)\n",
    "        loss = self.loss_layer.forward(score,target)        \n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        ds = self.loss_layer.backward(dout)\n",
    "        da = self.out_layer.backward(ds)\n",
    "        da *= 0.5\n",
    "        \n",
    "        self.in_layer0.backward(da)\n",
    "        self.in_layer1.backward(da)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "\n",
    "def remove_duplicate(params, grads):\n",
    "    '''\n",
    "    매개변수의 중복 제거 함수\n",
    "    매개변수 배열 중 중복되는 가중치를 하나로 모아\n",
    "    그 가중치에 대응하는 기울기를 더한다.\n",
    "    '''\n",
    "    params, grads = params[:], grads[:]  # copy list\n",
    "\n",
    "    while True:\n",
    "        find_flg = False\n",
    "        L = len(params)\n",
    "\n",
    "        for i in range(0, L - 1):\n",
    "            for j in range(i + 1, L):\n",
    "                # 가중치 공유 시  : lSTM에서 사용\n",
    "                if params[i] is params[j]:\n",
    "                    grads[i] += grads[j]  # 경사를 더함\n",
    "                    find_flg = True\n",
    "                    params.pop(j)\n",
    "                    grads.pop(j)\n",
    "                # 가중치를 전치행렬로 공유하는 경우(weight tying)\n",
    "                elif params[i].ndim == 2 and params[j].ndim == 2 and \\\n",
    "                     params[i].T.shape == params[j].shape and np.all(params[i].T == params[j]):\n",
    "                    grads[i] += grads[j].T\n",
    "                    find_flg = True\n",
    "                    params.pop(j)\n",
    "                    grads.pop(j)\n",
    "\n",
    "                if find_flg: break\n",
    "            if find_flg: break\n",
    "\n",
    "        if not find_flg: break\n",
    "\n",
    "    return params, grads\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, optimizer):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_list = []\n",
    "        self.eval_interval = None\n",
    "        self.current_epoch = 0\n",
    "\n",
    "    def fit(self, x, t, max_epoch=10, batch_size=32, max_grad=None, eval_interval=20):\n",
    "        data_size = len(x)\n",
    "        max_iters = data_size // batch_size\n",
    "        self.eval_interval = eval_interval\n",
    "        model, optimizer = self.model, self.optimizer\n",
    "        total_loss = 0\n",
    "        loss_count = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        for epoch in range(max_epoch):\n",
    "            # 뒤섞기\n",
    "            idx = np.random.permutation(np.arange(data_size))\n",
    "            x = x[idx]\n",
    "            t = t[idx]\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "                batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
    "                batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
    "\n",
    "                # 기울기 구해 매개변수 갱신\n",
    "                loss = model.forward(batch_x, batch_t)\n",
    "                model.backward()\n",
    "                \n",
    "                params, grads = remove_duplicate(model.params, model.grads)  # 공유된 가중치를 하나로 모음\n",
    "                if max_grad is not None:\n",
    "                    clip_grads(grads, max_grad)\n",
    "                optimizer.update(params, grads)\n",
    "                total_loss += loss\n",
    "                loss_count += 1\n",
    "\n",
    "                # 평가\n",
    "                if (eval_interval is not None) and (iters % eval_interval) == 0:\n",
    "                    avg_loss = total_loss / loss_count\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    print('| 에폭 %d |  반복 %d / %d | 시간 %d[s] | 손실 %.2f'\n",
    "                          % (self.current_epoch + 1, iters + 1, max_iters, elapsed_time, avg_loss))\n",
    "                    self.loss_list.append(float(avg_loss))\n",
    "                    total_loss, loss_count = 0, 0\n",
    "\n",
    "            self.current_epoch += 1\n",
    "\n",
    "    def plot(self, ylim=None):\n",
    "        x = np.arange(len(self.loss_list))\n",
    "        if ylim is not None:\n",
    "            plt.ylim(*ylim)\n",
    "        plt.plot(x, self.loss_list, label='train')\n",
    "        plt.xlabel('반복 (x' + str(self.eval_interval) + ')')\n",
    "        plt.ylabel('손실')\n",
    "        plt.show()      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 0 0 0 0 0 0]\n",
      "  [0 0 1 0 0 0 0]]\n",
      "\n",
      " [[0 1 0 0 0 0 0]\n",
      "  [0 0 0 1 0 0 0]]\n",
      "\n",
      " [[0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 1 0 0]]\n",
      "\n",
      " [[0 0 0 1 0 0 0]\n",
      "  [0 1 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 1 0 0]\n",
      "  [0 0 0 0 0 1 0]]\n",
      "\n",
      " [[0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 1]]] (6, 2, 7)\n",
      "[[0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0]] (6, 7)\n"
     ]
    }
   ],
   "source": [
    "window_size = 1\n",
    "hidden_size = 5\n",
    "batch_size = 3\n",
    "max_epoch = 1000\n",
    "\n",
    "text = 'You say goodbye and I say hello.' \n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "contexts,target = create_contexts_target(corpus,window_size)\n",
    "\n",
    "target = convert_one_hot(target, vocab_size)\n",
    "contexts = convert_one_hot(contexts, vocab_size)\n",
    "\n",
    "print(contexts,contexts.shape)\n",
    "print(target,target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 2 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 3 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 4 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 5 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 6 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 7 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 8 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 9 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 10 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 11 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 12 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 13 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 14 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 15 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 16 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 17 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 18 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 19 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 20 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 21 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 22 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 23 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 24 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 25 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 26 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 27 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 28 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 29 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 30 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 31 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 32 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 33 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 34 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 35 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
      "| 에폭 36 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 37 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
      "| 에폭 38 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
      "| 에폭 39 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
      "| 에폭 40 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
      "| 에폭 41 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
      "| 에폭 42 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
      "| 에폭 43 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
      "| 에폭 44 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
      "| 에폭 45 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
      "| 에폭 46 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
      "| 에폭 47 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
      "| 에폭 48 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
      "| 에폭 49 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
      "| 에폭 50 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
      "| 에폭 51 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
      "| 에폭 52 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
      "| 에폭 53 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
      "| 에폭 54 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
      "| 에폭 55 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
      "| 에폭 56 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
      "| 에폭 57 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
      "| 에폭 58 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
      "| 에폭 59 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
      "| 에폭 60 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
      "| 에폭 61 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
      "| 에폭 62 |  반복 1 / 2 | 시간 0[s] | 손실 1.85\n",
      "| 에폭 63 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
      "| 에폭 64 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
      "| 에폭 65 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
      "| 에폭 66 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
      "| 에폭 67 |  반복 1 / 2 | 시간 0[s] | 손실 1.83\n",
      "| 에폭 68 |  반복 1 / 2 | 시간 0[s] | 손실 1.85\n",
      "| 에폭 69 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
      "| 에폭 70 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
      "| 에폭 71 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
      "| 에폭 72 |  반복 1 / 2 | 시간 0[s] | 손실 1.83\n",
      "| 에폭 73 |  반복 1 / 2 | 시간 0[s] | 손실 1.81\n",
      "| 에폭 74 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
      "| 에폭 75 |  반복 1 / 2 | 시간 0[s] | 손실 1.80\n",
      "| 에폭 76 |  반복 1 / 2 | 시간 0[s] | 손실 1.83\n",
      "| 에폭 77 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
      "| 에폭 78 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
      "| 에폭 79 |  반복 1 / 2 | 시간 0[s] | 손실 1.81\n",
      "| 에폭 80 |  반복 1 / 2 | 시간 0[s] | 손실 1.80\n",
      "| 에폭 81 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
      "| 에폭 82 |  반복 1 / 2 | 시간 0[s] | 손실 1.77\n",
      "| 에폭 83 |  반복 1 / 2 | 시간 0[s] | 손실 1.78\n",
      "| 에폭 84 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
      "| 에폭 85 |  반복 1 / 2 | 시간 0[s] | 손실 1.76\n",
      "| 에폭 86 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
      "| 에폭 87 |  반복 1 / 2 | 시간 0[s] | 손실 1.74\n",
      "| 에폭 88 |  반복 1 / 2 | 시간 0[s] | 손실 1.76\n",
      "| 에폭 89 |  반복 1 / 2 | 시간 0[s] | 손실 1.76\n",
      "| 에폭 90 |  반복 1 / 2 | 시간 0[s] | 손실 1.76\n",
      "| 에폭 91 |  반복 1 / 2 | 시간 0[s] | 손실 1.77\n",
      "| 에폭 92 |  반복 1 / 2 | 시간 0[s] | 손실 1.70\n",
      "| 에폭 93 |  반복 1 / 2 | 시간 0[s] | 손실 1.76\n",
      "| 에폭 94 |  반복 1 / 2 | 시간 0[s] | 손실 1.72\n",
      "| 에폭 95 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
      "| 에폭 96 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
      "| 에폭 97 |  반복 1 / 2 | 시간 0[s] | 손실 1.72\n",
      "| 에폭 98 |  반복 1 / 2 | 시간 0[s] | 손실 1.71\n",
      "| 에폭 99 |  반복 1 / 2 | 시간 0[s] | 손실 1.72\n",
      "| 에폭 100 |  반복 1 / 2 | 시간 0[s] | 손실 1.70\n",
      "| 에폭 101 |  반복 1 / 2 | 시간 0[s] | 손실 1.66\n",
      "| 에폭 102 |  반복 1 / 2 | 시간 0[s] | 손실 1.74\n",
      "| 에폭 103 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
      "| 에폭 104 |  반복 1 / 2 | 시간 0[s] | 손실 1.66\n",
      "| 에폭 105 |  반복 1 / 2 | 시간 0[s] | 손실 1.69\n",
      "| 에폭 106 |  반복 1 / 2 | 시간 0[s] | 손실 1.70\n",
      "| 에폭 107 |  반복 1 / 2 | 시간 0[s] | 손실 1.66\n",
      "| 에폭 108 |  반복 1 / 2 | 시간 0[s] | 손실 1.67\n",
      "| 에폭 109 |  반복 1 / 2 | 시간 0[s] | 손실 1.65\n",
      "| 에폭 110 |  반복 1 / 2 | 시간 0[s] | 손실 1.65\n",
      "| 에폭 111 |  반복 1 / 2 | 시간 0[s] | 손실 1.65\n",
      "| 에폭 112 |  반복 1 / 2 | 시간 0[s] | 손실 1.63\n",
      "| 에폭 113 |  반복 1 / 2 | 시간 0[s] | 손실 1.66\n",
      "| 에폭 114 |  반복 1 / 2 | 시간 0[s] | 손실 1.62\n",
      "| 에폭 115 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
      "| 에폭 116 |  반복 1 / 2 | 시간 0[s] | 손실 1.60\n",
      "| 에폭 117 |  반복 1 / 2 | 시간 0[s] | 손실 1.62\n",
      "| 에폭 118 |  반복 1 / 2 | 시간 0[s] | 손실 1.61\n",
      "| 에폭 119 |  반복 1 / 2 | 시간 0[s] | 손실 1.62\n",
      "| 에폭 120 |  반복 1 / 2 | 시간 0[s] | 손실 1.60\n",
      "| 에폭 121 |  반복 1 / 2 | 시간 0[s] | 손실 1.62\n",
      "| 에폭 122 |  반복 1 / 2 | 시간 0[s] | 손실 1.59\n",
      "| 에폭 123 |  반복 1 / 2 | 시간 0[s] | 손실 1.60\n",
      "| 에폭 124 |  반복 1 / 2 | 시간 0[s] | 손실 1.57\n",
      "| 에폭 125 |  반복 1 / 2 | 시간 0[s] | 손실 1.61\n",
      "| 에폭 126 |  반복 1 / 2 | 시간 0[s] | 손실 1.56\n",
      "| 에폭 127 |  반복 1 / 2 | 시간 0[s] | 손실 1.57\n",
      "| 에폭 128 |  반복 1 / 2 | 시간 0[s] | 손실 1.56\n",
      "| 에폭 129 |  반복 1 / 2 | 시간 0[s] | 손실 1.58\n",
      "| 에폭 130 |  반복 1 / 2 | 시간 0[s] | 손실 1.55\n",
      "| 에폭 131 |  반복 1 / 2 | 시간 0[s] | 손실 1.61\n",
      "| 에폭 132 |  반복 1 / 2 | 시간 0[s] | 손실 1.46\n",
      "| 에폭 133 |  반복 1 / 2 | 시간 0[s] | 손실 1.61\n",
      "| 에폭 134 |  반복 1 / 2 | 시간 0[s] | 손실 1.51\n",
      "| 에폭 135 |  반복 1 / 2 | 시간 0[s] | 손실 1.55\n",
      "| 에폭 136 |  반복 1 / 2 | 시간 0[s] | 손실 1.51\n",
      "| 에폭 137 |  반복 1 / 2 | 시간 0[s] | 손실 1.56\n",
      "| 에폭 138 |  반복 1 / 2 | 시간 0[s] | 손실 1.51\n",
      "| 에폭 139 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
      "| 에폭 140 |  반복 1 / 2 | 시간 0[s] | 손실 1.50\n",
      "| 에폭 141 |  반복 1 / 2 | 시간 0[s] | 손실 1.52\n",
      "| 에폭 142 |  반복 1 / 2 | 시간 0[s] | 손실 1.47\n",
      "| 에폭 143 |  반복 1 / 2 | 시간 0[s] | 손실 1.50\n",
      "| 에폭 144 |  반복 1 / 2 | 시간 0[s] | 손실 1.52\n",
      "| 에폭 145 |  반복 1 / 2 | 시간 0[s] | 손실 1.51\n",
      "| 에폭 146 |  반복 1 / 2 | 시간 0[s] | 손실 1.43\n",
      "| 에폭 147 |  반복 1 / 2 | 시간 0[s] | 손실 1.51\n",
      "| 에폭 148 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
      "| 에폭 149 |  반복 1 / 2 | 시간 0[s] | 손실 1.41\n",
      "| 에폭 150 |  반복 1 / 2 | 시간 0[s] | 손실 1.50\n",
      "| 에폭 151 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
      "| 에폭 152 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
      "| 에폭 153 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
      "| 에폭 154 |  반복 1 / 2 | 시간 0[s] | 손실 1.42\n",
      "| 에폭 155 |  반복 1 / 2 | 시간 0[s] | 손실 1.45\n",
      "| 에폭 156 |  반복 1 / 2 | 시간 0[s] | 손실 1.44\n",
      "| 에폭 157 |  반복 1 / 2 | 시간 0[s] | 손실 1.44\n",
      "| 에폭 158 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
      "| 에폭 159 |  반복 1 / 2 | 시간 0[s] | 손실 1.51\n",
      "| 에폭 160 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
      "| 에폭 161 |  반복 1 / 2 | 시간 0[s] | 손실 1.45\n",
      "| 에폭 162 |  반복 1 / 2 | 시간 0[s] | 손실 1.44\n",
      "| 에폭 163 |  반복 1 / 2 | 시간 0[s] | 손실 1.34\n",
      "| 에폭 164 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
      "| 에폭 165 |  반복 1 / 2 | 시간 0[s] | 손실 1.43\n",
      "| 에폭 166 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
      "| 에폭 167 |  반복 1 / 2 | 시간 0[s] | 손실 1.42\n",
      "| 에폭 168 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
      "| 에폭 169 |  반복 1 / 2 | 시간 0[s] | 손실 1.40\n",
      "| 에폭 170 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
      "| 에폭 171 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
      "| 에폭 172 |  반복 1 / 2 | 시간 0[s] | 손실 1.32\n",
      "| 에폭 173 |  반복 1 / 2 | 시간 0[s] | 손실 1.42\n",
      "| 에폭 174 |  반복 1 / 2 | 시간 0[s] | 손실 1.33\n",
      "| 에폭 175 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
      "| 에폭 176 |  반복 1 / 2 | 시간 0[s] | 손실 1.38\n",
      "| 에폭 177 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
      "| 에폭 178 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
      "| 에폭 179 |  반복 1 / 2 | 시간 0[s] | 손실 1.27\n",
      "| 에폭 180 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
      "| 에폭 181 |  반복 1 / 2 | 시간 0[s] | 손실 1.33\n",
      "| 에폭 182 |  반복 1 / 2 | 시간 0[s] | 손실 1.29\n",
      "| 에폭 183 |  반복 1 / 2 | 시간 0[s] | 손실 1.32\n",
      "| 에폭 184 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
      "| 에폭 185 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
      "| 에폭 186 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
      "| 에폭 187 |  반복 1 / 2 | 시간 0[s] | 손실 1.27\n",
      "| 에폭 188 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
      "| 에폭 189 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
      "| 에폭 190 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
      "| 에폭 191 |  반복 1 / 2 | 시간 0[s] | 손실 1.41\n",
      "| 에폭 192 |  반복 1 / 2 | 시간 0[s] | 손실 1.29\n",
      "| 에폭 193 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
      "| 에폭 194 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
      "| 에폭 195 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
      "| 에폭 196 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 197 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
      "| 에폭 198 |  반복 1 / 2 | 시간 0[s] | 손실 1.31\n",
      "| 에폭 199 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
      "| 에폭 200 |  반복 1 / 2 | 시간 0[s] | 손실 1.34\n",
      "| 에폭 201 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
      "| 에폭 202 |  반복 1 / 2 | 시간 0[s] | 손실 1.31\n",
      "| 에폭 203 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
      "| 에폭 204 |  반복 1 / 2 | 시간 0[s] | 손실 1.27\n",
      "| 에폭 205 |  반복 1 / 2 | 시간 0[s] | 손실 1.24\n",
      "| 에폭 206 |  반복 1 / 2 | 시간 0[s] | 손실 1.24\n",
      "| 에폭 207 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
      "| 에폭 208 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
      "| 에폭 209 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
      "| 에폭 210 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
      "| 에폭 211 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
      "| 에폭 212 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
      "| 에폭 213 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 214 |  반복 1 / 2 | 시간 0[s] | 손실 1.24\n",
      "| 에폭 215 |  반복 1 / 2 | 시간 0[s] | 손실 1.24\n",
      "| 에폭 216 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
      "| 에폭 217 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
      "| 에폭 218 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
      "| 에폭 219 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
      "| 에폭 220 |  반복 1 / 2 | 시간 0[s] | 손실 1.27\n",
      "| 에폭 221 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
      "| 에폭 222 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
      "| 에폭 223 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
      "| 에폭 224 |  반복 1 / 2 | 시간 0[s] | 손실 1.27\n",
      "| 에폭 225 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
      "| 에폭 226 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 227 |  반복 1 / 2 | 시간 0[s] | 손실 1.32\n",
      "| 에폭 228 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 229 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 230 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 231 |  반복 1 / 2 | 시간 0[s] | 손실 1.24\n",
      "| 에폭 232 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 233 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
      "| 에폭 234 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 235 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
      "| 에폭 236 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
      "| 에폭 237 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 238 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
      "| 에폭 239 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 240 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
      "| 에폭 241 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
      "| 에폭 242 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 243 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
      "| 에폭 244 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 245 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
      "| 에폭 246 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 247 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
      "| 에폭 248 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 249 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 250 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
      "| 에폭 251 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 252 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 253 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 254 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 255 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 256 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 257 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 258 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 259 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 260 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 261 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 262 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 263 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 264 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 265 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 266 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 267 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 268 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 269 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 270 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 271 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
      "| 에폭 272 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 273 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 274 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 275 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 276 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 277 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 278 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 279 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 280 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 281 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 282 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 283 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 284 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 285 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
      "| 에폭 286 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 287 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 288 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 289 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 290 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
      "| 에폭 291 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 292 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 293 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 294 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 295 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 296 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 297 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 298 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 299 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 300 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 301 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 302 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 303 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 304 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 305 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 306 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 307 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 308 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 309 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 310 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 311 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 312 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 313 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 314 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 315 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 316 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 317 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 318 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 319 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 320 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 321 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 322 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 323 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
      "| 에폭 324 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 325 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 326 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 327 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 328 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 329 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 330 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 331 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 332 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 333 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 334 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 335 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 336 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 337 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 338 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 339 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 340 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 341 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 342 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 343 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 344 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 345 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 346 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 347 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 348 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 349 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 350 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 351 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 352 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 353 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
      "| 에폭 354 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 355 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 356 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 357 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 358 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 359 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 360 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 361 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 362 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 363 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 364 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 365 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 366 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 367 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 368 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 369 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 370 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 371 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 372 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 373 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 374 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 375 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 376 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 377 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 378 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 379 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 380 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 381 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 382 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 383 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 384 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 385 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 386 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 387 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 388 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 389 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 390 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 391 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 392 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 393 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 394 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 395 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 396 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 397 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 398 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 399 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 400 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 401 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 402 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 403 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 404 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 405 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 406 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 407 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 408 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
      "| 에폭 409 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 410 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 411 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 412 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 413 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 414 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 415 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 416 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 417 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 418 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 419 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 420 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 421 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 422 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 423 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
      "| 에폭 424 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 425 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 426 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 427 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 428 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 429 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 430 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 431 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 432 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 433 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 434 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 435 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 436 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 437 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 438 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 439 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 440 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 441 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 442 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 443 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 444 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 445 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 446 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 447 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 448 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 449 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 450 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
      "| 에폭 451 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 452 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 453 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 454 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 455 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 456 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 457 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 458 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 459 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 460 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
      "| 에폭 461 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 462 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 463 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
      "| 에폭 464 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
      "| 에폭 465 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 466 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
      "| 에폭 467 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
      "| 에폭 468 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
      "| 에폭 469 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 470 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
      "| 에폭 471 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 472 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
      "| 에폭 473 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
      "| 에폭 474 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 475 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 476 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
      "| 에폭 477 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
      "| 에폭 478 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
      "| 에폭 479 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 480 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
      "| 에폭 481 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
      "| 에폭 482 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
      "| 에폭 483 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 484 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 485 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
      "| 에폭 486 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
      "| 에폭 487 |  반복 1 / 2 | 시간 1[s] | 손실 0.81\n",
      "| 에폭 488 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
      "| 에폭 489 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
      "| 에폭 490 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 491 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
      "| 에폭 492 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
      "| 에폭 493 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 494 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
      "| 에폭 495 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 496 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
      "| 에폭 497 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 498 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
      "| 에폭 499 |  반복 1 / 2 | 시간 1[s] | 손실 0.87\n",
      "| 에폭 500 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 501 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 502 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 503 |  반복 1 / 2 | 시간 1[s] | 손실 0.97\n",
      "| 에폭 504 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 505 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 506 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 507 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
      "| 에폭 508 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 509 |  반복 1 / 2 | 시간 1[s] | 손실 0.81\n",
      "| 에폭 510 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 511 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 512 |  반복 1 / 2 | 시간 1[s] | 손실 0.97\n",
      "| 에폭 513 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 514 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
      "| 에폭 515 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 516 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
      "| 에폭 517 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
      "| 에폭 518 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 519 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
      "| 에폭 520 |  반복 1 / 2 | 시간 1[s] | 손실 0.81\n",
      "| 에폭 521 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 522 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 523 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 524 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 525 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
      "| 에폭 526 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 527 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
      "| 에폭 528 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 529 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
      "| 에폭 530 |  반복 1 / 2 | 시간 1[s] | 손실 0.54\n",
      "| 에폭 531 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
      "| 에폭 532 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
      "| 에폭 533 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 534 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 535 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
      "| 에폭 536 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 537 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
      "| 에폭 538 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 539 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 540 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
      "| 에폭 541 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 542 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 543 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
      "| 에폭 544 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 545 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 546 |  반복 1 / 2 | 시간 1[s] | 손실 0.95\n",
      "| 에폭 547 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 548 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
      "| 에폭 549 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 550 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 551 |  반복 1 / 2 | 시간 1[s] | 손실 0.86\n",
      "| 에폭 552 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 553 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 554 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 555 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
      "| 에폭 556 |  반복 1 / 2 | 시간 1[s] | 손실 0.57\n",
      "| 에폭 557 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 558 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 559 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
      "| 에폭 560 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 561 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 562 |  반복 1 / 2 | 시간 1[s] | 손실 0.86\n",
      "| 에폭 563 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 564 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
      "| 에폭 565 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 566 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
      "| 에폭 567 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 568 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 569 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 570 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 571 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
      "| 에폭 572 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 573 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
      "| 에폭 574 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
      "| 에폭 575 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 576 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 577 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 578 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 579 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 580 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
      "| 에폭 581 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
      "| 에폭 582 |  반복 1 / 2 | 시간 1[s] | 손실 0.50\n",
      "| 에폭 583 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
      "| 에폭 584 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 585 |  반복 1 / 2 | 시간 1[s] | 손실 0.57\n",
      "| 에폭 586 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
      "| 에폭 587 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 588 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 589 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 590 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 591 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 592 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
      "| 에폭 593 |  반복 1 / 2 | 시간 1[s] | 손실 0.57\n",
      "| 에폭 594 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
      "| 에폭 595 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 596 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 597 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 598 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
      "| 에폭 599 |  반복 1 / 2 | 시간 1[s] | 손실 0.54\n",
      "| 에폭 600 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
      "| 에폭 601 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
      "| 에폭 602 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 603 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 604 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 605 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
      "| 에폭 606 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 607 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 608 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 609 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
      "| 에폭 610 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 611 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
      "| 에폭 612 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
      "| 에폭 613 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
      "| 에폭 614 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
      "| 에폭 615 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 616 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 617 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
      "| 에폭 618 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 619 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 620 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
      "| 에폭 621 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 622 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 623 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
      "| 에폭 624 |  반복 1 / 2 | 시간 1[s] | 손실 0.48\n",
      "| 에폭 625 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
      "| 에폭 626 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 627 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
      "| 에폭 628 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 629 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 630 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 631 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 632 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 633 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 634 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 635 |  반복 1 / 2 | 시간 1[s] | 손실 0.81\n",
      "| 에폭 636 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
      "| 에폭 637 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 638 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 639 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 640 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
      "| 에폭 641 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 642 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 643 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 644 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
      "| 에폭 645 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 646 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 647 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 648 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 649 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 650 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 651 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 652 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 653 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 654 |  반복 1 / 2 | 시간 1[s] | 손실 0.54\n",
      "| 에폭 655 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 656 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
      "| 에폭 657 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
      "| 에폭 658 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 659 |  반복 1 / 2 | 시간 1[s] | 손실 0.44\n",
      "| 에폭 660 |  반복 1 / 2 | 시간 1[s] | 손실 0.81\n",
      "| 에폭 661 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 662 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
      "| 에폭 663 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 664 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 665 |  반복 1 / 2 | 시간 1[s] | 손실 0.54\n",
      "| 에폭 666 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
      "| 에폭 667 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 668 |  반복 1 / 2 | 시간 1[s] | 손실 0.81\n",
      "| 에폭 669 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 670 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 671 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 672 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
      "| 에폭 673 |  반복 1 / 2 | 시간 1[s] | 손실 0.50\n",
      "| 에폭 674 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 675 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
      "| 에폭 676 |  반복 1 / 2 | 시간 1[s] | 손실 0.43\n",
      "| 에폭 677 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 678 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
      "| 에폭 679 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 680 |  반복 1 / 2 | 시간 1[s] | 손실 0.51\n",
      "| 에폭 681 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 682 |  반복 1 / 2 | 시간 1[s] | 손실 0.58\n",
      "| 에폭 683 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 684 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 685 |  반복 1 / 2 | 시간 1[s] | 손실 0.50\n",
      "| 에폭 686 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 687 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 688 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 689 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 690 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 691 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 692 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 693 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 694 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 695 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 696 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
      "| 에폭 697 |  반복 1 / 2 | 시간 1[s] | 손실 0.42\n",
      "| 에폭 698 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 699 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 700 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 701 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 702 |  반복 1 / 2 | 시간 1[s] | 손실 0.42\n",
      "| 에폭 703 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 704 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
      "| 에폭 705 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 706 |  반복 1 / 2 | 시간 1[s] | 손실 0.42\n",
      "| 에폭 707 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
      "| 에폭 708 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 709 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 710 |  반복 1 / 2 | 시간 1[s] | 손실 0.52\n",
      "| 에폭 711 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
      "| 에폭 712 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 713 |  반복 1 / 2 | 시간 1[s] | 손실 0.52\n",
      "| 에폭 714 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 715 |  반복 1 / 2 | 시간 1[s] | 손실 0.50\n",
      "| 에폭 716 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 717 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
      "| 에폭 718 |  반복 1 / 2 | 시간 1[s] | 손실 0.41\n",
      "| 에폭 719 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
      "| 에폭 720 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 721 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 722 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 723 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 724 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 725 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 726 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
      "| 에폭 727 |  반복 1 / 2 | 시간 1[s] | 손실 0.58\n",
      "| 에폭 728 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 729 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 730 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 731 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 732 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 733 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
      "| 에폭 734 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
      "| 에폭 735 |  반복 1 / 2 | 시간 1[s] | 손실 0.58\n",
      "| 에폭 736 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 737 |  반복 1 / 2 | 시간 1[s] | 손실 0.48\n",
      "| 에폭 738 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
      "| 에폭 739 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 740 |  반복 1 / 2 | 시간 1[s] | 손실 0.43\n",
      "| 에폭 741 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
      "| 에폭 742 |  반복 1 / 2 | 시간 1[s] | 손실 0.54\n",
      "| 에폭 743 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 744 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
      "| 에폭 745 |  반복 1 / 2 | 시간 1[s] | 손실 0.50\n",
      "| 에폭 746 |  반복 1 / 2 | 시간 1[s] | 손실 0.81\n",
      "| 에폭 747 |  반복 1 / 2 | 시간 1[s] | 손실 0.58\n",
      "| 에폭 748 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 749 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 750 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 751 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
      "| 에폭 752 |  반복 1 / 2 | 시간 1[s] | 손실 0.58\n",
      "| 에폭 753 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 754 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 755 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
      "| 에폭 756 |  반복 1 / 2 | 시간 1[s] | 손실 0.49\n",
      "| 에폭 757 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
      "| 에폭 758 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 759 |  반복 1 / 2 | 시간 1[s] | 손실 0.47\n",
      "| 에폭 760 |  반복 1 / 2 | 시간 1[s] | 손실 0.81\n",
      "| 에폭 761 |  반복 1 / 2 | 시간 1[s] | 손실 0.47\n",
      "| 에폭 762 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
      "| 에폭 763 |  반복 1 / 2 | 시간 1[s] | 손실 0.50\n",
      "| 에폭 764 |  반복 1 / 2 | 시간 1[s] | 손실 0.81\n",
      "| 에폭 765 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 766 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 767 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 768 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 769 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 770 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
      "| 에폭 771 |  반복 1 / 2 | 시간 1[s] | 손실 0.39\n",
      "| 에폭 772 |  반복 1 / 2 | 시간 1[s] | 손실 0.81\n",
      "| 에폭 773 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 774 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 775 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 776 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 777 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 778 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 779 |  반복 1 / 2 | 시간 1[s] | 손실 0.54\n",
      "| 에폭 780 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
      "| 에폭 781 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 782 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 783 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 784 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 785 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
      "| 에폭 786 |  반복 1 / 2 | 시간 1[s] | 손실 0.39\n",
      "| 에폭 787 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 788 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
      "| 에폭 789 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 790 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 791 |  반복 1 / 2 | 시간 1[s] | 손실 0.46\n",
      "| 에폭 792 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 793 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 794 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
      "| 에폭 795 |  반복 1 / 2 | 시간 1[s] | 손실 0.52\n",
      "| 에폭 796 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 797 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 798 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 799 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 800 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 801 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 802 |  반복 1 / 2 | 시간 1[s] | 손실 0.45\n",
      "| 에폭 803 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 804 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 805 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 806 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
      "| 에폭 807 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
      "| 에폭 808 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
      "| 에폭 809 |  반복 1 / 2 | 시간 1[s] | 손실 0.38\n",
      "| 에폭 810 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
      "| 에폭 811 |  반복 1 / 2 | 시간 1[s] | 손실 0.31\n",
      "| 에폭 812 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 813 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
      "| 에폭 814 |  반복 1 / 2 | 시간 1[s] | 손실 0.48\n",
      "| 에폭 815 |  반복 1 / 2 | 시간 1[s] | 손실 0.44\n",
      "| 에폭 816 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
      "| 에폭 817 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 818 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
      "| 에폭 819 |  반복 1 / 2 | 시간 1[s] | 손실 0.45\n",
      "| 에폭 820 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 821 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
      "| 에폭 822 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 823 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 824 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 825 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 826 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 827 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 828 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 829 |  반복 1 / 2 | 시간 1[s] | 손실 0.58\n",
      "| 에폭 830 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 831 |  반복 1 / 2 | 시간 1[s] | 손실 0.58\n",
      "| 에폭 832 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 833 |  반복 1 / 2 | 시간 1[s] | 손실 0.40\n",
      "| 에폭 834 |  반복 1 / 2 | 시간 1[s] | 손실 0.58\n",
      "| 에폭 835 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 836 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 837 |  반복 1 / 2 | 시간 1[s] | 손실 0.37\n",
      "| 에폭 838 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 839 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
      "| 에폭 840 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 841 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 842 |  반복 1 / 2 | 시간 1[s] | 손실 0.54\n",
      "| 에폭 843 |  반복 1 / 2 | 시간 1[s] | 손실 0.47\n",
      "| 에폭 844 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
      "| 에폭 845 |  반복 1 / 2 | 시간 1[s] | 손실 0.51\n",
      "| 에폭 846 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 847 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 848 |  반복 1 / 2 | 시간 1[s] | 손실 0.44\n",
      "| 에폭 849 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 850 |  반복 1 / 2 | 시간 1[s] | 손실 0.54\n",
      "| 에폭 851 |  반복 1 / 2 | 시간 1[s] | 손실 0.86\n",
      "| 에폭 852 |  반복 1 / 2 | 시간 1[s] | 손실 0.47\n",
      "| 에폭 853 |  반복 1 / 2 | 시간 1[s] | 손실 0.58\n",
      "| 에폭 854 |  반복 1 / 2 | 시간 1[s] | 손실 0.54\n",
      "| 에폭 855 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 856 |  반복 1 / 2 | 시간 1[s] | 손실 0.54\n",
      "| 에폭 857 |  반복 1 / 2 | 시간 1[s] | 손실 0.58\n",
      "| 에폭 858 |  반복 1 / 2 | 시간 1[s] | 손실 0.50\n",
      "| 에폭 859 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 860 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 861 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 862 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 863 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 864 |  반복 1 / 2 | 시간 1[s] | 손실 0.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 865 |  반복 1 / 2 | 시간 1[s] | 손실 0.50\n",
      "| 에폭 866 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 867 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 868 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 869 |  반복 1 / 2 | 시간 1[s] | 손실 0.43\n",
      "| 에폭 870 |  반복 1 / 2 | 시간 1[s] | 손실 0.54\n",
      "| 에폭 871 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
      "| 에폭 872 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 873 |  반복 1 / 2 | 시간 1[s] | 손실 0.50\n",
      "| 에폭 874 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 875 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 876 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 877 |  반복 1 / 2 | 시간 1[s] | 손실 0.54\n",
      "| 에폭 878 |  반복 1 / 2 | 시간 1[s] | 손실 0.47\n",
      "| 에폭 879 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 880 |  반복 1 / 2 | 시간 1[s] | 손실 0.57\n",
      "| 에폭 881 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
      "| 에폭 882 |  반복 1 / 2 | 시간 1[s] | 손실 0.43\n",
      "| 에폭 883 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
      "| 에폭 884 |  반복 1 / 2 | 시간 1[s] | 손실 0.35\n",
      "| 에폭 885 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 886 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 887 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 888 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
      "| 에폭 889 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 890 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 891 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 892 |  반복 1 / 2 | 시간 1[s] | 손실 0.50\n",
      "| 에폭 893 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 894 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 895 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 896 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 897 |  반복 1 / 2 | 시간 1[s] | 손실 0.46\n",
      "| 에폭 898 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
      "| 에폭 899 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 900 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 901 |  반복 1 / 2 | 시간 1[s] | 손실 0.35\n",
      "| 에폭 902 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 903 |  반복 1 / 2 | 시간 1[s] | 손실 0.57\n",
      "| 에폭 904 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 905 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 906 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 907 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 908 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 909 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 910 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 911 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 912 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 913 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 914 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 915 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 916 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 917 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 918 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 919 |  반복 1 / 2 | 시간 1[s] | 손실 0.42\n",
      "| 에폭 920 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
      "| 에폭 921 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 922 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
      "| 에폭 923 |  반복 1 / 2 | 시간 1[s] | 손실 0.34\n",
      "| 에폭 924 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 925 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 926 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
      "| 에폭 927 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 928 |  반복 1 / 2 | 시간 1[s] | 손실 0.49\n",
      "| 에폭 929 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 930 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 931 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 932 |  반복 1 / 2 | 시간 1[s] | 손실 0.42\n",
      "| 에폭 933 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 934 |  반복 1 / 2 | 시간 1[s] | 손실 0.81\n",
      "| 에폭 935 |  반복 1 / 2 | 시간 1[s] | 손실 0.27\n",
      "| 에폭 936 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 937 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 938 |  반복 1 / 2 | 시간 1[s] | 손실 0.52\n",
      "| 에폭 939 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 940 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 941 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 942 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 943 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 944 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 945 |  반복 1 / 2 | 시간 1[s] | 손실 0.45\n",
      "| 에폭 946 |  반복 1 / 2 | 시간 1[s] | 손실 0.52\n",
      "| 에폭 947 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 948 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
      "| 에폭 949 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 950 |  반복 1 / 2 | 시간 1[s] | 손실 0.45\n",
      "| 에폭 951 |  반복 1 / 2 | 시간 1[s] | 손실 0.52\n",
      "| 에폭 952 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
      "| 에폭 953 |  반복 1 / 2 | 시간 1[s] | 손실 0.41\n",
      "| 에폭 954 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 955 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 956 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 957 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
      "| 에폭 958 |  반복 1 / 2 | 시간 1[s] | 손실 0.45\n",
      "| 에폭 959 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 960 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 961 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 962 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 963 |  반복 1 / 2 | 시간 1[s] | 손실 0.26\n",
      "| 에폭 964 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
      "| 에폭 965 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 966 |  반복 1 / 2 | 시간 1[s] | 손실 0.41\n",
      "| 에폭 967 |  반복 1 / 2 | 시간 1[s] | 손실 0.52\n",
      "| 에폭 968 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
      "| 에폭 969 |  반복 1 / 2 | 시간 1[s] | 손실 0.52\n",
      "| 에폭 970 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 971 |  반복 1 / 2 | 시간 1[s] | 손실 0.44\n",
      "| 에폭 972 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 973 |  반복 1 / 2 | 시간 1[s] | 손실 0.37\n",
      "| 에폭 974 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
      "| 에폭 975 |  반복 1 / 2 | 시간 1[s] | 손실 0.52\n",
      "| 에폭 976 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 977 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 978 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 979 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 980 |  반복 1 / 2 | 시간 1[s] | 손실 0.51\n",
      "| 에폭 981 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
      "| 에폭 982 |  반복 1 / 2 | 시간 1[s] | 손실 0.51\n",
      "| 에폭 983 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 984 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
      "| 에폭 985 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 986 |  반복 1 / 2 | 시간 1[s] | 손실 0.44\n",
      "| 에폭 987 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 988 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
      "| 에폭 989 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 990 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 991 |  반복 1 / 2 | 시간 1[s] | 손실 0.40\n",
      "| 에폭 992 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
      "| 에폭 993 |  반복 1 / 2 | 시간 1[s] | 손실 0.44\n",
      "| 에폭 994 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 995 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 996 |  반복 1 / 2 | 시간 1[s] | 손실 0.33\n",
      "| 에폭 997 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
      "| 에폭 998 |  반복 1 / 2 | 시간 1[s] | 손실 0.44\n",
      "| 에폭 999 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 1000 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCBOW(vocab_size, hidden_size) # vocab_size=7,hidden_size=5\n",
    "optimzer = Adam()\n",
    "trainer = Trainer(model,optimzer)\n",
    "\n",
    "trainer.fit(contexts, target, max_epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEGCAYAAABlxeIAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU5fXA8e/JRggEwhI22QVBQUGgKCqLiMqidWurda3VYm2trf5ccG/rUtRq1aq1WKvVVqut2qooKNYgoCKIgqAgLoDsAZGdkOX8/pg7k1nurJmbSSbn8zw8zLx3mfdOknvuu4uqYowxxuRkOgPGGGMaBgsIxhhjAAsIxhhjHBYQjDHGABYQjDHGOCwgGGOMASDPi5OKSAnwCNAJX9C5QFW/cra1BB4FDgC+Ac5X1R0icirwf0ABcK+qPhvvc9q3b689e/b04hKMMSYrffDBB1tUtdRtm3gxDkFEugCo6noRmQRMVNWfO9tuAr5Q1adF5OdAS+BBYCZwHL4gNRcYoar7Yn3OsGHDdOHChWnPvzHGZCsR+UBVh7lt86TKSFXXq+p65+02YHfQ5rHAv5zXzwMjgCOBN1W1QlV3A/OB/l7kzRhjjDtP2xBE5ADgKuC+oORmqlrpvN4KtAE6AOVB+/jT3c45WUQWisjC8vJyt12MMcakwLOAICInATcDPwkqLQDUiIj/c9vgCwTbCQ0A/vQIqjpNVYep6rDSUtdqMGOMMSnwJCCIyGHAyap6iapuDds8HzjFeX0GMAt4HxgvIvkiUgQMBJZ7kTdjjDHuPOllBIwHRopImfN+DbABuAn4HfCUiPwS+Bz4uapWiMgT+BqT9wK3qGqVR3kzxhjjwpNeRvXFehkZY0xy6r2XkTHGmMbHqyqjBu20h+exeUcFhfk5tCzMp12LAg7qWEyv9kUcf0gn2rYoyHQWjTGm3jXJgDCidzs27thHRWUNO/ZVsv7bvfxv+WYAbnhxKVU1yo+P7sVlY/tYcDDGNBnWhuDYV1nN4q+/5bmFa3l+0dpA+okDOjL19MNoY4HBGJMFYrUhWEBwsXnHPh4u+4In3lkVSLv9tIEc2bsdB5a2TPvnGWNMfbGAkKKq6hr63PBaSNqqqZM8+zxjjPGa9TJKUV5uDl/eMZFrx9dOq9RzynSWrd9ORVV1BnNmjDHpZwEhjpwc4eKRvejWtnkgbdIDczl66lsZzJUxxqSfBYQE5OfmMOeasdw46eBA2pZdFWzfUxnjKGOMaVwsICTh4pG9ee6SEYH3g377Oo25DcYYY4JZQEjS8F5tGX1Q7Syrva9/lY/Xbqe6xgKDMaZxs4CQgttOHciALq0AUIWTH5zLXTNtclZjTONmASEF3doWMf3ykZxzRPdA2tPz12QwR8YYU3cWEOrglpMHBF7v3FfFph0xl4A2xpgGzQJCHRTk5fDIuUMD74+4402mL9nAZgsMxphGyAJCHY0f2Cnk/c+fXsSP/7YgQ7kxxpjUWUBIg7nXHhvyfum6HdYd1RjT6FhASIOubYoigsLDZV9kKDfGGJMaCwhp0rVNEVcef1Dg/ePzvspgbowxJnkWENLo8uP6Bl5v2bWf/3tuMe98sSWDOTLGmMRZQEiz7/RsE3j9/KK1nP3o/AzmxhhjEmcBIc0ePmco10/sH39HY4xpYDwLCCJSKiK3i8itYel/EZEy598iEXnBSX9MRN5x0u/yKl9eKy1uxg+Hdw9Ju+SphTbXkTGmwfOyhHAPUAHkByeq6sWqOkZVxwBzgd85m0qACc62azzMl+eKC/N58OzDA+9nLtvEW8s3ZzBHxhgTn2cBQVXPB96Otl1EegAdVNU/iqsY2OFVfurbSYd1CXl/8ZO+pT637KqgxkoLxpgGKJNtCFcC9we9V6BMRF4XkZHRDhKRySKyUEQWlpeXe57JdCrfWcGw22Zx35srM50VY4yJkJGAICKFwGBVfdefpqonqupo4CLgoWjHquo0VR2mqsNKS0uj7dYg3H/WYAZ1bR14P3PZRgBed/43xpiGJFMlhAnArOAEEclzXm4DsmJtylMGH8DVJ9b2OLrxP0sBrIHZGNMg1VtAEJE7RaTAeTsGmBe2ywwRKQNeA66vr3xlQrXNc2SMaYDy4u+SOlUtA8qc19cGpf/SZd9xXuYlU2pcbv5flu9m2frtDOjS2uUIY4zJDBuY5rGubZoDcPWJ/ULSJz0wNxPZMcaYqCwgeKx3aUveu+44fjbmQEqLm2U6O8YYE5UFhHrQqXUhIkJBbujXvXH7PnpOmc4Li9ZmKGfGGFPLAkI9apYX+nWv3LwTgBc/XJeJ7BhjTAgLCPWoICwg3D79UwBEJBPZMcaYEBYQ6tGlYw4Meb98o6+EkGPxwBjTAHja7dSEOmXwAZwy+ABUlX43zWB/VQ0AOVZCMMY0AFZCyAARYdp5QwPvrYRgjGkILCBkSPe2RYHX1oZgjGkILCBkSPCYhDc+2UTPKdPZu786gzkyxjR1FhAypLgwn+E924akHXzzDF5evJ6/zv2KyuqaDOXMGNNUiTbiidaGDRumCxcuzHQ2UrZnfxWH3Dwz6vZVUyfVY26MMU2BiHygqsPctlkJIYOKCqyTlzGm4bCAkGGzrhzFUxcNz3Q2jDHGxiFkWp8OxfTpUEyLglx2W6OyMSaDrITQQBzcuVWms2CMaeIsIDQQ9501ONNZMMY0cRYQGoiubYoi1kvoOWU6uyqqMpQjY0xTYwGhAVlwQ+Qqolt2VmQgJ8aYpsgCQgNTdtWYkPf7bYCaMaaeWEBoYJoX5Ia8f3zeV7yyZD2NeQChMaZx8CwgiEipiNwuIreGpXcTkfUiUub8O8RJP1VE5ojIfBE506t8NXR5YVOfPvP+11z29Ie8tHh9hnJkjGkqvCwh3ANUAPlh6SXAs6o6xvn3iYi0AK4CxgFjgSkiUuhh3hqsvBz3H8kv//kR5U57wp/KvuDeNz6rz2wZY5oAzwKCqp4PvO2yqQTYFpZ2JPCmqlao6m5gPtDfq7w1ZHm50afCvveNFQDcOWM5D7y5sr6yZIxpIjLRhlAEnCEi80TkPhHJBzoA5UH7bAXauB0sIpNFZKGILCwvL3fbpVHLDaoy6t+pOGTbM+9/zacbdtR3lowxTUS9BwRVnamqg4CRwE7gJ8B2QgNAG0IDRPDx01R1mKoOKy0t9Ty/9S24DeHvFx8RsX3C/XPqMzvGmCak3gOCiOQBqGoNvpIAwPvAeBHJF5EiYCCwvL7z1hAElxDatSjIYE6MMU1NvQUEEblTRAqA74vIXBGZDRwOPKaqW4AngLnAq8Atqtokh+gGL6dpS2saY+qTp7OdqmoZUOa8vtZJfsb5F77vo8CjXuanMZp4aCde/XhjprNhjGkCbGBaA3TP9wcx68pRADx8ztCo+/3tnVX1lCNjTFNgAaEBOmNoV/p0KI673y0vLauH3BhjmgoLCI3cF+W7Mp0FY0yWsIDQyB13z2yb58gYkxYWEBqBaedFb0cA+MUzH3LEHbOosplRjTF1YAGhEThhQKeY219ZsoFNOyrYsS+0p+4Ff32f6Us2eJk1Y0wWsYDQSJx7ZHcAerQrirpPVU1oCWH2Z+X8/OlFnubLGJM9LCA0EiN6twegeX5u1H32V9UGBGtXMMYkywJCI3FAm+YADOvpOucfAMfc+VbgdXWNBQRjTHI8Hals0mdwtxJevXwk7VoW8Pf31kTdr6Kqmu17K/lwzbf1mDtjTDawgNCIHNKlFd/s3h9zn343zkAErMbIGJMsqzJqZEqahy9AFyk8GPScMp1l67d7lCNjTLawgNDI5OQId51xWNLHTX2tSc4mboxJggWERugH3+kWeF1a3CyhY+as3GID14wxMVlAaKSeumg43x3UhQU3jEv4mCdsdlRjTAwWEBqpkX1LeeCHhyd1zJZd7g3Sqsp1Lyxh4apv0pE1Y0wjZQEhCxzUsSWHdy+Ju5/i3vWoslp55v2vOWvae+nOmjGmEbGAkAVev2I0L/7s6Lj7/Xn2l67pNdZH1RiDBQSDBQRjjI8FBGPTXBhjAAsIWemYPu2T2r8mSm/U26d/Qs8p09OQI2NMY+BZQBCRUhG5XURuDUs/TEReF5E5IvKciBQ46Y+JyDsiUiYid3mVr6bgR0f1TGi/yuoarnthCV9v2+O6/dE5X6UxV8aYhs7LEsI9QAUQPteCAier6khgNXCKk14CTFDVMap6jYf5ynqHdWsdddsDb64MvJ67cgvPvP81J/1xbn1kyxjTwHk2uZ2qni8iY4DxYekfB73dBux2XhcDO7zKT1Mw68pRbNpRQYfiQiYd1tl1tbR73/iMLbsq2LanklMHd0novKqKiKQ7u8aYBiZjbQgicjQwAJjpJClQ5lQnjcxUvhqzPh2KOdppP8jPiX4Df/Ld1by8eH1EY3JVjbJ0XeQkeNbobEzTUO8BQXymAGOB81W1GkBVT1TV0cBFwEMxjp8sIgtFZGF5eXn9ZLoRysuN/6Od/NQHEWlu1UfV1i3VmCYhEyWEnwIbVPVWfzAAEBF/9dU2oDLawao6TVWHqeqw0tJSj7PaeOXnpq+Kx+KBMU1DvS2QIyJ3AjcBJwMlInKhs+klVb0XmOEEhVzg+vrKV7bKjVFllCyrMjKmafA0IKhqGVDmvL7WSZ4YZd/Ep+00cY3t3yHmUpuxbN65jz0VgcKbjWQ2pomwgWlZamz/jozt3yGlY4ff/iZjfl8WeP/ku6vTlCtjTENmASGL3fuDQRFpd51xGD8dfWBS57l75op0ZckY04BZQMhiJUUFPHLukJA0kejTYBtjmjYLCFlu/MDO9O3QMvA+nY3NxpjsYgGhCfj3T4/inu8PoqQon5F9rauuMcadBYQmoHVRPmcM7cpHN59AaXGzQPrVJ/ar03nXbtvDB6tt2U1jskXUbqcicizQOSz5I2AwgKo+LSK/UtX7PMyf8YLThJBTx/mJRt71FqqwauqkNGTKGJNpsUoIufhmKg3+dyrQG5ji7OM6psA0DqnGg537Kpn9WXlgBPOnG3Yw9bXlqI1XMKZRi1pCUNVZwe9FpBlwFfAaMMqf7F3WjFfqetu+4tnFzPp0U+D9j59YwIbt+7h4ZC/at2wW40j4fPNOxt37Nk/+eDijDrL2DGMakoTaEESkKzCVut9LTAOSTDR/a8XmwOsvt+wK2ebvubRjbyWrt+6msrqGqmr3ZdgWrtoGwPQlG/hs005WbtqZXKaNMZ6JGxBEpD3wAHCny2YLEI1QcNXObacOTOiYCx9fEHidnxP6a9Oyma+g+YdZKxl9dxl9b3iN8ffPiXvOE/7wNsf/4e2Y+zz13mquePajhPJojKmbmAFBRN4AVgGPqupGah8qRURGAW28zZ7xkgice2QPxg/olNRxeWEzqRbm5wIw65PaaqTPN4eWIoI/EyIHx32zez/lOysi9r/pP0t58cN1/Gvh1wy7bRY1NtGeMZ6JObmdqh4vIp2B+0Xkc+B/wFrgL8AI4N/eZ9GkW3jb71UnHsSMZRvjHtdzynR6l7bgy/LdIen+sW57K6sjjnnt4w3k5eZw/CEdAQIrr4XnYcitbwDReyxd98LHVNUo1arkWNOVMZ6IO9upqm4QkYuAB1TVP2X1s95my9QHcW6sfToU85vvDuCWl5bFPSY8GABUx3hov/QfiwBolpfDitsmBG7lyT7o+3e3jkzGeCehRmVV3QlcLiIneJwfUw9+Mqo3I3q343tDuwbSLjiqJzdOOpjOrQuTPl91jXsDcrCKqhrKd1Zw9b+XAMnPp+Rv94g1FffabXv4dIMty21MqhLtZXSNExSmhKWHD1wzjUDHVoU8M/lI2rQoCEm/eGRvZl052vWY847swZnDurluq4pVRAjy8uL1gdezV6S2/GmsgHDMnW8xIYHGbGOMu0R6GTUDevjfhm3+R9pzZDKqIM/9V2JwtxJuO829R1KiC+jcOWN54PXW3ftd9/kmSnrtZyX0UcaYFCRSQriQ2ht/+J+jte5lmbwos6EqkJ+bwz8uPiJi22eb3HsUhauoil+1NOTWN/jPh+uibrfV24zxTrxup/8HdAe2icgFQHj/RPvrzDL+XkCDurbmwNIWgXR/Hf7Rfdp7nod5n2+JSAs0KsePKcaYFMUrIdQAhc7/VVgAaBIW33wC//rpUZx9RI9AWn3+4N9eWU7PKdPZuityXIKVEIzxTsyAoKp/AL4C2qnqP4DNsfY32aF1UX5kW0IK9+Gvv9mT0udv2uELBEvX1/YY8scBt4Cwbfd+11KFMSY5ccch4BuEdhfwDs5tQUTuBQ6mtrHZZKFRfWurh1JZdnPkXW/V6fPdZk+tdkn70RMLWPz1t1HPs3rrblZu2sU4Z3CcMcZd3EZlVd0L+FdZFyftSlWdoKpRV2sXkVIRuV1Ebg1Lbykiz4jI2yLyHxFp5aSfKiJzRGS+iJyZ+iWZdOnbsZgnLvwOAEO61/8sJV9tiRwE51ZjtGJj9LEH736xldF3l3HxkwvTmTVjslKiA9MedF7ensS57wEq8K2jEOwK4GVVHQW8AVwqIi3wTa09DhgLTBGR5EdImbQb068Dq6ZOom/H4nr/7N+8/ElEmluVkYR1drvpP0sDry/624Lw3Y0xUSS1hGb4Gglx9j0fcJvKcizwL+f18/jmRDoSeFNVK1R1NzAf6J9M3kzDkRul62o6BI9DUFUmPTAnYg6lp95bHbS/NUIbk6hMrKncTFUrnddb8c2Y2gEIHrrqT48gIpNFZKGILCwvT220q6mb6Zcfw8uXHRN1e4uC3KTOd8ernya8b/Bsp1U1yrL1saeqSDUeXPy3BfzsHx+kdrAxjVQmAkKNiPg/tw2+QLCd0ADgT4+gqtNUdZiqDisttRW3MmFAl9Yc2rV11O3+m/DTLoPY3Ex7+8uEP1sVbvzPx1z/4scJTZmRavlg1qebefXj+DPAGpNNMhEQ5gOnOK/PAGYB7wPjRSRfRIqAgcDyKMebBqR5fmRpwN8TqHNJc8b275DWz6tW5e/vreHp+WuoTGBSveCeSr2vm859sz5La37iqaiq5roXPmaLy5gKYxqaegsIInKniBQAvwMmi0gZMBR4XFW3AE8Ac4FXgVtUtaq+8mZS8/4Nx/HBTeP4v+MPCkmvdqp18nMlZLRzOgS3CVQnUkII2qVG4b5ZK9m6q4LXl21kw/a9ac1bsLG/L+P+WSuZsXQjz7y/htteiWwgN6ah8TQgqGqZqk5xXl+rqvtVdYvTZXWMql6sqhXO9kdV9QgnvW4d2E296FBcSFFBHr84ri9tg2ZO9d+0C3JzyM1J769Y8BP//ijrNgdza1T+dm8lk5/6gNMeeieteQv25Zbd/GHWZ0ED6jz7KGPSJhNVRiYLvfbLkYHX/ptfXm4O6e5wFHxj/eGj70Xd7+tv9nDmn991vRH7G6Y37tgXSCvfWUFlAgEmWbVLhsb37hdbWbpuu29/VdeBecZ4yQKCSYuOrQqZ8auRPHXR8MBTeX6upP3J2H/DBPfV2/xu+u9S5n/1jeu2qrBMVVRV853bZ3H9Cx8D8I/5q90O89wPH32Pk/44l+17K+l13av0uu7VkDEVJraXFq+n55TpbIszhbqJzgKCSZv+nVoxsm9poJokPzcnodXUknHlc4sT2q8sxgI81WEBwd9b6ZUlGwC44cX03YTXbPXN55TM0/7moJJL8JiK4O09p0wPzN+0dN12vihPbArybPb4vK8AX3VdOqkqf39vNbsqsr9Z0wKC8Ux+bk6DrDv/xTMfhrz3ZzE8UEQzc9lGvt2T2FPoPW98FvIZ6bBozTYAnnx3FQAn/XEux90zO7D97EffS2psh4nt3S+3cuN/lnLLf+OvOd7YWUAwaXf9RN8g89wcIT+34f2KBc+RdMIfZjNt9heA+8R54Tbv3MclT33ApX9fBEBldU3an87j5cIft8Kn7PB754utrmM7tu6qoOeU6bz9WWjpaf23e9m7vzpif+Pj/26+2Z39XYcb3l+rafQmjzqQVVMnAdC5dfwpqcb0y9wAw8827eKB/30O+EoIu8OqBZ56dxVL1tbOpFpR6asCW+NM7T31teUcd89s1n0bpwtr2F3+9WUb2RRUNZQMf9xKtgPXEqf95bG5X4WkHzX1f1zw+Psp5aUh8aoNXprQupAWEIynRjpTaD909hCuGd/PdZ82RQWu6Zkw4JaZIe9v+u8yvvvgvKj7L1jla7gu35n402NNjTL5qQ/4wZ/fdd0e78bmb7SPVkJIxftRGuAbo3TfwJtSZ69E1kMwJmW9S1vy5R0TyXH6nx7Zux2nP1zb/793+/QOXPNa+NO5fw3q4MbzWA3I23bv58InfDOwrt2W2sC4wNkb+JPrLf9dys59Vdx75uBA2oJV39CmKJ8+Hep/9ty6kiZQVLASgvFcTtBgBLd1FRpTf/vwp/M8JzJUBo2admuc9i8w9PyitXzkLOaT6hgN//eVU083qFeWrKfP9a+yrzK5doa/vbuaFz5cF5L2/UfeZdy9bpMgm4bAAoLJKKVxLdQdPvI5N1BCqE3fvreScG4xL9oNPd7qdBpoVK4fd81YQVWNptzmYRoPCwjGJME/qM1/L8/LlZD01Vt3M/S2xJYNibZuxPj75oS83xx2I/YHDA+XnXD9vGz0wqK1MZdfbWosIJiMS7XG6MQB9btG8tJ127ni2Y+A2qdzfxtClTPtRbQuqG7XmJtglc/EB+aGvPc3V6SjTjuZ6rp0NmK7eWv5ZiqqUu/+msqv0ZXPLeaUh6J3GqiLVVt21+l6MsECgsko1cjnz7euGpPQsTdOOiTt+Ynmx08s4KQ/zg0syCMizPpkE285I6K/2rIbVSXadEhuT9mJ3s/Dp86OtgpcZXUN3/tTbYP9vspqPli9Lea5G8rAwUVrtnHhEwv43at1n/W+ITT97qqoYszvy7j230tct+/dX82pD80LTMWyctNO/vDGZ6gqO/dV8tbyza7H1dQoO/ZFVkmmiwUEk3G/GNuHPh1aBt53KYk9dqEgz/dr27JZ/XWS+1/YH+iuiioufnJh4P1t0z+l13Wv8pOgtHhyUqzz8ceDF8MabL/+Zg8LgwLAZU8v4ow/vcPXzpiJyPMory3dkFIe0s0//9DqrXWfduIf89fU+RzBUinB+gezzXWmFwn34ZptfPT1t9w23Tct+g8ffY/731zJjn1VXPHsR1z4xALXsS0P/G8lh/36dbZ6tL6GBQSTcQd1LGbWlaMD7+NVpSy55QRev2IUbVpkbvxCMuMOwHdTeWnxerYGTbz27Z5Knlv4ddKfHa1O/18frA15P+tTXxDbuc832G5LWJ5nf1bOZU+HTuOxdN12DrrxNd5asZm7ZiwPqVLycv2IQEN5GqrB/v3BWk9GXntR8vBXw/l7qdXUaGAuJrdrmO7Mt7VllzcT+FlAMA1G1zbNgfjdKQvzczmoY+Pqx76roorLn/mQP5V9EZJ+zb+XcPIf5ya1olq0ap5o1Qx+V4dVX3zjMivo395Zxf6qGi58fAEPl33BnqCb0pnTok83HmzHvko+35zcdB7+S2oI1T31IfxH6O9gEFodWP/1eTYwzWRU8K/8v346gg/XfJtyVUpDtjdGH/6P121nWII9kyBsFbig6JDsOAHXc4e9311RxbbdydVZn/Xn9/hkw46E9v18805KigoCJZHwZ4F/vr+GoT3a0DeRB4CgLyadPaPqeqa3Vmzm0w07+NmYPhHb/Nfr/5WvVs1oULQSgmkwOrduzsRDO6d07CWjeqc5N+n14Zq6dW28zlmrAUKfIoPXlY4VdMJd8tRC16nEw+vLx/y+LKlpn6987qOEgwHAuHvfZvRdtQskzvp0Mz2nTKfXddPZVVHFlBc+5vg/hA5km7tyC3v2V/HJ+trPqaquoaKq9rtY/PV2GooLH1/AXTNWhKSFf8/+UnFwulvbRe2CS96UHiwgmAbpT+cM4ZFzhyS8f7pKFZ1axZ+MLxOeeX8N87/cSs8p00O6tlYFjZDetCPxaqeZyza5poffaPaE1WOHd1P9ds9+ek6Zzhuf+M73wqLQhu5E7N5fHXF7U/V12wy3Zusezn1sPofcPJOJD8xhxtKNAJzzl/ks37gzsF+s1fQApr39Rcist7Gk8puV6A27toRQO8Axk1NkWEAw9S54BtRoPTgmHNqZ8QNrSwuLbjqeVVMnBWZRjefmk6J3SY01u2omG6rjeXaBrwF6UVBPouCAUB/Cf14rnJvwoy7Tbfu5rUC3ZO23STfMA+ysCK2++nKLLzhGWx3Pza6KKu54dTlnTXOfXBBg/H1v82Nnzim3b3j7nkq+jDHtebyeSeEBw23EeyZ6BFtAMPXutV+O5KXLjgbgzO90S+iYtnFu1D8ZGVplNOqg6Df9wrzcqNua5TXcP4kVm3w33xZB3W0r07wiXTzhYyACazPEeKh9buHaiLTvPjiP79xe227idgN1qwIL3y/WYLlog+786bsrolexLd+4M6KrcfA1nvzgXMYGLUoULtpYEYD9VTWBc2/fW8nqrbsD596zvzpwRa5VRkRWLaWTZ43KInIrMMr5jMmqusxJ/wvgb11pBaxS1dNF5DHgYGA/8L6qXuNV3kxmlRQVUFJUwOe3T4g6fUOy2rYo4ORBXXh58Xqg9omrU6tCNoZN/RBrHYGGHBD8g+KCe2H5u5TGomhIv/XNsZ7M49xoqlVDbhrBjcEvfhh543d2iptHtw8+M2x6cFXlR48vSOBcPtU1GphaJPYnJW9NlLEdfrEG/N05YzmPz1sFwNJ1Oxh9dxnd2xYBcOJ90Sf++8ucLwMPBV7xJCCIyEigo6qOFpGBwN3ARABVvThovweAp5y3JcAEVW04rUHGU3lpWE1t3MEdWfONry44+IkwR2DONceyc18VEx8InRsoVrfWggYcEPyCexMd+/uyuPvX1MCUoEbpT6M0+u51qcsP1+/GGbQpyueIXu04c3g3Cpyf4eebd3HFs+7rXScyGtotZoQft7+6JqJ7bqySyVnT3uPJi4ZTVJDHZ5t2squiiiHd2wQ+K9HG8lRm462JcdFubSNuD0bh1Uq3Tfd+WVSvSggnAM8AqOpSEWkbvoOI9AA6qKo/5BcDiXdPMAb4ywXDAq+D/3wEoVvbIo9QFMoAABe4SURBVNf+/bECQn1NKV0XyfQmAl+3Vn+jbywH3zwjofNt21PJjGUbmbFsI09dNByIPVDq43XbWbFxJ1tjLEGZyC13f1Vk9Visn9bC1duYvaKcCYd25gSnp9KqqZNcP+y8x+Zz4dE9mbl0E3d+77Co59xVUUXz/OhVjn6xYojbUq3J/to1tiqjDkDwwq1VIpKjqsE/0SuB+4PeK1AmIhXAraoa+ljnEJHJwGSA7t27pzfXpsGZMqG/6xoKboKf5Iqa+f5oWxXmR+wXq5qqEcSDQNVRoq5/8eP4O6Uo0RtTrKqQRLkGhDg/L7cHdbf6/TkrtzBnpW+aifCAIEE9gAbeMpMfDq9t93rqvdWcd2QP5n2+hZWbdvKjo3sBsPqbyFLA9r2VtG6e75ont9H5mVgmxKvy8XYg+K+4JjgYiEghMFhVA5WEqnqiqo4GLgIeinZiVZ2mqsNUdVhpaebW4jX146ejD2R4r4gCpit/++plx/ahfctmgHsVkL8U8KtxfaNuM4kJny4jVfFufqc9PI8layNrk+PNwOr2NB6rwRciq3v8Dxr+Kc7/FdRIftN/lgK+bq+/fvmTQPp5j0WuUT3oN6+HnC/YSpeR3dkUEOYA3wMQkUOA8N+aCUDI0EwR8ZdWtgHeTednspa/znVAl1Yx9/MXEIK7vwJ0a9u80S3pmWn+Rvy6itdv/8M13/LbVz6JSFeUh8s+j3pc+M19w/a9cds09keZstZ/g44XUOKp6/HQ+AamTQcKRGQO8HvgWhG5U0T8fQfHAOGTkM8QkTLgNeB6j/Jlsli0CdKe/PFwZvxqZOB9bZ/v0OOvm3Cw63kPLK0NEi9fdgy/PWUAh3SOHXRMclJdX3ru51sjRgEH+3TjDnpOmR54P+J3/4vbSBw84nl/VQ3//cgX9PxtN3WdMtxtiVU3mViYyJM2BKd66NKw5GuDtv/S5ZhxXuTFNB3R+sSHj0kodBoFw/dTdf9jn3hoZx6Z/QWV1UrblgWcP6In2/dUJjVFQzw50nDWJsiEqa/FXwfB7Ua+aXvsZT1fdxmRHbeEEBQQfvfap0z/2DfDaLy1JfzKVsSeZDDRn3OsuOVVdVLD72NnTMKcPvFx9rri+IO48OienD7kAJczRP6l9WjXIvBHnO/Srz0d0tEFN9u53QPj9ct3WzcgXpVNcJVR0rO2JjBWItFurOmoWkqW/RaarOGfGK9/p9jVOa2b53PLyQNolpfLjZMOZlDX1gB0al0Y8eT1yLlDOSMocOQ7o9pSaXv+9cnRp9PIz8IZXtMtlfvjDpeBe6u3xh5UVhHUrTfZTgaJVAclWkKoUV9p5bSH5yU03iQdbPprkzVOH9KVkwd1IT+Jp+2LR/bmwqN7sXTddgZ1K4lYU2BojzaISOCpzj/yNZEJyI7s3Zb3vqydYyc3Rr58JYTGtf5ufUvXE3O8ie+Cp9r4dk9yC9FEa5AOlmgbQo0qq7fudp0p16qMjElAMsHALzdHGNStBIDLxvYJqUoqzPedz//3l8j5zxjSlT+fNzTw/uoT+/H9oV057fDIKqrafFsJIZ76qkF5ZHbtIkaLXbq6hvvvR7UzvG5NYCWzRKuMVDVqgPGqOslKCKbJeOqi4XFnBy3Mz+WGiQfzwqJ1DOleQrEzsM3/95eX4y8hRD/HPT8YBMBf534FwOHdS/j5sZGLowRLJZA1NW5rDDcEv/znR4HXI4PWdnDz+Lyvkqoyqozy++pVQLDfQtNkjOxbyrH9O8Tdr13LZsy55lievWREIO35S4/iR0f1TGoyPv+fbLzBU4DrJGzpdNUJB3l6fhNN6M/1Ny9/wva9iQ2z+v4j77qOzgZ48t3VMedLSpUFBGNcdGtbFPLUPrRHG3793QGBtoN+CS3p6PsvkXbJ/FhTsDq+0zOxKTzctG3RLOVjTXol0y6xZ7/7BHwvfrjOk2lWrMrImBQcd3BH3rhiFP9etJZvd1fy7MKvI/bRBLvBQmIlhLrUEvjbQkzmufV8SmVfL1ZWs4BgTIr6diwOjG4+b0QPnn5/Dd8f2jViv0T+cPPilBB6tCtiyoT+fO+R6Kt8xVKYwAydJv3cZttNxo4Eq5fSxR4bjEmDgQe05o7TDuXwoJlZk3mij9fLaPbVxzKsZ1sW3JDagP6GvPCPie5GZ/K8+mK/JcZ4xB8PEmmHTnSkcmlxM1bcNj7pvFgJwSTCAoIxHgleXtKvYyv3xt28JHovNQtbEzqRqmRrQzCJsN8SYzziVmP0358fwxlDatsZpp03lOMP6chdMVbpivs5MaqmzjnCt4hUeBAxxo0FBGM8Unujrn2E79S6MDBwDeCEAZ149Pxh9GjXgveuO44fHdWTq0/sl7Y8/PaUgXzy2xMTGj/xu9MPTfr8Zx9hqxZmEwsIxngs0d6BnVoX8uvvDggZ1dymKJ9ubZun/Nm5OUJRQV5Ck7R9z6WHVDx3nJZ8EDENl3U7NcYjtSOVU/fhzSekIysk0madTDuGyU5WQjDGI7WNyt7daC8Y0YNHzh3KEXHWnU4kD17mM5YfDu/Oo+cP8+z8rQrzAm0pJjYrIRjjkQNLW7Jk7XaKC5P/M5t++TFxB6sB/OaUgQCMH9gpZKnIcMnO65+IUwd3Sct5SoryOf6Qjmk5l5s9+6ub9Gp0ybASgjEeueO0Q3nyx8M5sLRl0scO6NKafp0SmC/JxYNnHw7Asf1qlw71ojbo+onua1AnK9H1AVKVmyMJTznttYIGPqutlRCM8UjzgtyI9Zzrw0mHdWFs/w4hNx9/CeGAkubMvfZYPt2wkw9Wf8OiNd/y4ofrop0qppwEo8zvvz+I/Fzhobc+57NNkUtSehkQTh9yABcd04sn5q3y7DOS0bZFARt3xF4HOpMadrgyJktNOrRzYFGedBl3cEcOKPH1SCoqyIs6+llEOKRLK84b0ZPSYt9AuSkT+gPw4s+Oon3LAoC4vZtyE6yG6t+pmFMGH8DrV4xm1dRJEdsTDQjFzZJ/fr33B4MZ0KV1g6kyaud8t3Xl2drenpwVEJFbgVHOZ0xW1WVOejdgPvCZs+vPVPUTETkV+D+gALhXVZ/1Km/GZNpD5wxJ+zn/ckHyDbPnHtGDVxav5xSnPeDw7m3o2KqQLbv28+APh3Bw51a8smQ9Vz63OOLYREsI8eJGvMVeWhXm8dZVY8jPy+GwX7+e0GeG87rKqLgwj50JzGLqD8B1lcy6HMnwpIQgIiOBjqo6GrgEuDtocwnwrKqOcf59IiItgKuAccBYYIqIFHqRN2OaIv9NOfzG2L1dEe9cdxydW0eWBnJEKMjLoXeUNpB0tVNXRXl8v/iYXgD8Ymxf2rVsRitn9bpgL192TEKfUZ2mgOC2Dsbnt0/g41+fyKqpk5gaY3BfcWEeR/Zul5Z8JLJ+Riq8qjI6AXgGQFWXAsF94kqAbWH7Hwm8qaoVqrobXwmiv0d5M6bJSaZLaSB4OCMpqmviLxzvdnzgfZyRGKmu/DXp0M4c2rV1Qvumq8rI7WtMtAfXr8YdlNRYj2nnDaV9S/cSRa5HVUZeBYQOQHnQ+yoR8X9WEXCGiMwTkftEJN9l/61A6stDGWNSFn4DD17Xt0+Hltz7g0EM79WWlgXuNc4HdSjmhZ8dldBn9e3Qkp+M6p16ZhMUL+hcfEwvfjbmwJSmDQmuOosXG5IpqJwwoBMLb3Sf7jyRLsmp8KoNYTuhN/QaVa0BUNWZwEwnQPwG+AmwCghehbwNoQEiQEQmA5MBune3wSamafrvz4+mpCiyCiWeZB6U/Tevw7vXNn6P6N2O04d05fQh0ae5UJQh3dvQv1MxyzfujPkZb1w52jXdbaGhCEk8JMdrp7jxpEMCr9/7citzVm7hhokHc/urn4bsd834fvzi6Q/Zvb86SpaiZ0pIX9WVV6PKvSohzAG+ByAihwBr/RtEJA/ACRBbneT3gfEiki8iRcBAYLnbiVV1mqoOU9VhpaX136XPmIZgULcSerRrkfD+ydw+wp9ym+Xl8pvvDkj4+PB7XqK1Ve9eNzbwesSBtXXtGiWMJXNN8QJCMH+vp4M7t4rYNrZ/R5b9Nvn1KMD3PaSri22jalQGpgMFIjIH+D1wrYjcKSIFwPdFZK6IzAYOBx5T1S3AE8Bc4FXgFlVNfOFRY0xM7VoWUJifE+hemqpEbu7+W160e/D9Zw12TXdr2I6dl8Rvisnch/2N3CnddMMOuTmo5AGpt5eEa1TdTp2n/0vDkq91/n/G+Rd+zKPAo17kx5imrlleLstvnZDUManeusJ7MoXft08ZfAC//OdHrscWN8tjZ0UVR/dpzyfrd8T8nGRuicF5Ov6QjvzoqJ6c85f5rvvW1CEghB8R/h2mq3G7sZUQjDGNlP9Wk2rf/brc8z7+ja/7ZsdWhXFLIz3bFSV83uAbca4IR/dpH3gfPlguuIQw68pRrufzDwAMF6vUks42hHyPpsCwgGCMCeVyU0sqOKj/P+8Ggz1x4Xe4/Li+AEwY2IlLxxwYc/9k6u79++blCH06FNOuReTo4nlTxkakQWQJIfx9r/aJB7FY8hpZt1NjTCN16WhfN1C3AWmp3IbijUNIxZh+HQJTc/zp3KFcOz60bWTUQaU8ffERgfepNCr7q2WSGYAXvq+GbBNOHXwAz186gumX1w6ou2BEj8Q/wFEUpctvXVlAMMaEGD+wM6umTqJ189purSMO9FWxnDiwU9zjMz1tUPe2RTz54+EcFVQt5BYQHjp7CH+/6IiIdH/votrrT35QX/TtwtAebRnQpXZAnX8K82hmXz0mZB1ugAfOOjzhPCXDZjs1xsTVr1Ox68R0bvzVS7Eeyj+6+fiEq3GSrXZ3uym7DbaedFhn1+NvP20gZx/RjW5tfdU7k0f14o5XXXvBx5WOOZR6tGsRMdFgp9bezOxjJQRjTJ3MmzKWudcey7Xj+3Nw51aBdZa7OA2vhfmRt5mSogLaRZmWwS+dK7glU2VUmJ/L0B61s+1MHhW7fSLYiN7tQ94HjxWpy+V4Ue3mxkoIxpg68fe4uXTMgSGNuw+cdTizV5YnNYAuHdxundHmBEq3Tq0L+eKOiRx4/auAr4vrIZ1b8cmGHRH5Gt6zLb1LQ7+b5vm57K2MHAVdX6ubWgnBGOOJ1kX5fHdQepbZrKs7Tj+03hYrCh8iMKSH+7oXz/10BFPPOCwkLVrvpQkJtN2kgwUEY0yD5L8Jju5X9xt56+b5/PA73ep8nkSEV3Ul04zQ1qWLK0Dfjom34dSFVRkZYxqkw7u3ibgJPnzOEHbsrYx5XLS2h0z3fqq3ep86sBKCMabRmHhoZ84a7j7Lcfi8QeH8VTleTfsQTcYDURKshGCMyQqj+5XCK9FHDRx3cEcuGNGDy8b2rdd8+auMEg1Dr/ziGCqrk1uUKF0sIBhjskK8uvr83Jy4g8AagoEHJLYKnBcsIBhjsosHNULTLz8mYk3nq044iJWbd0U9xqtFbLxkAcEYkyW8q60PnmrCL1bV0/1nDebQwJO+L1+NoE3ZAoIxJjskW1fvpVMGHxCRVl+jjevCAoIxJqukc8qLhuaxC4axr9K7BmcLCMaYrNBQu3emaU0cwNdTyks2DsEYkxVKinyNvsf0aR9nz8xoDAUXKyEYY7JCh+JC3r76WDqXeDM1dKrSWULwmgUEY0zW6J7EOsv1xb+UaCMoIFiVkTHGGB/PAoKI3Cois0VknogMCEo/TEReF5E5IvKciBQ46Y+JyDsiUiYid3mVL2OMqU/+9SA6tKqfNRnqwpMqIxEZCXRU1dEiMhC4G5jobFbgZFWtEJG7gVOAfwElwARV3e5FnowxJhN+OvpABnRpxZh+HTKdlbi8akM4AXgGQFWXikhgPTpV/Thov23Abud1MbDDo/wYY0xG5OZI3GDwwY3jyGkA3ZC8qjLqAJQHva8SkZDPEpGjgQHATCdJgTKnOmlktBOLyGQRWSgiC8vLy6PtZowxjUa7ls1oE2VxnPrkVQlhO9Am6H2NqtYAiG8Y4bVAPnC+qlYDqOqJzvZuwHQgdG05h6pOA6YBDBs2rBF16DLGmIbNqxLCHOB7ACJyCLA2aNtPgQ2qeqs/GDj7+YPTNiD2kkjGGGPSzqsSwnRgoojMAXYCl4jIncBNwMlAiYhc6Oz7kqreC8xwgkIucL1H+TLGGBOFJwHBqR66NCz5Wuf/ibhQ1XFe5MUYY0xibGCaMcYYwAKCMcYYhwUEY4wxAIg2pqn4wohIObA6xcPbA1vSmJ3GwK65abBrbhpSveYeqlrqtqFRB4S6EJGFqjos0/moT3bNTYNdc9PgxTVblZExxhjAAoIxxhhHUw4I0zKdgQywa24a7JqbhrRfc5NtQzDGGBOqKZcQjDHGBLGAYIwxBmiiASHa8p6NnYiUiMg/nWVI3xaRXiLST0TedK717qB9s+47EJFFIjK+KVyziAx3fsbzROSaJnLNVwZdy+HZes0iUioit4vIrc77hK8z2r4JU9Um9Q8YCUxzXg8EXs10ntJ4bV2ALs7rScBDwGtATyftX8AR2fgd4Jtu/QtgfLZfM761RF4B2gSlZfs1lwBlgAB9gJez9ZqBJ4GbganJ/mzd9k3ms72a/rohi7q8Z2OnquuD3m4DKoBCVV3lpD0PjADakUXfgYgUA+cB/8A3g2+2X/MEfCP0nxGRfOA6sv+aq/HVaBTgG6FbDvTKxmtW1fNFZAww3lkSIKGfbYx95yf62U2xyiju8p6NnYgcAFwF3ANsDdq0Fd9Kdtn2HTwA3AbU4FubO9uvuS/QFjgJuAh4liy/ZlXdCbwNfAq8BDxOll+zo5QErxPoGGXfhDXFEkLU5T2zgYichG8Rop8Ae/AVtf3a4Pslak6WfAcicg6wRlUXiMgk4Fuy/Jrx/fG/rqpVwCoR+YbQa8u6a3Z+tvnAgfiu6Xl8DwB+WXfNjoR/n4FvouybsMYcOVMVa3nPRk1EDgNOVtVLVHWrqu4FmjklBoDTgTfJru/gbOAQEfknvmu6FhiQ5df8Lr5qI0SkI75VCQuy/Jp7AJvUVzm+A19JsG2WXzPJ/A3H2DdhTbGEELG8Z4bzk07jgZEiUua8XwNcCfxbRCrwLVf6qYisIEu+A1Wd5H8tIr8G3sNXVM7ma35fRFaIyDx8pYUr8T3cZe01A08AfxWR2UAz4M/AR2T3Nfsl8zccsW8yH2QjlY0xxgBNs8rIGGOMCwsIxhhjAAsIxhhjHBYQjDHGABYQjHElIs9kOg/G1DcLCKZJE5EZQa/HiMgU523EIuTOpGF9wv79r94ya4zHmuI4BGOC5YpIV+d1RBAIUwQc45IWlYjcCzysqp+HpRfgm3ywL1AIXKaqC0WkE/AXoDW+yfp+ApwBFKnqXxO4HmNSZgHBNHWt8c37BNAVWOi8FhG5DHhLVZc5aa2Ac8OOLyEKERkI7AgPBo4C4B5VXe5MXXwXvhlqbwfuUNV3nOmLT1fVf4rIf0XkeVXdnspFGpMIqzIyTd03qvorVf0V8GDYtuX45pIBQFUHqOo4fKNm/66q41S1f4xznwU8KSKtnbULmonIABH5p6ruUtXlzn7bgN3O636q+o7z2j9bJfgmdPtuyldpTAKshGCautYi8m/ndTt8U5sAqKrOAhCR44Ebgo5p60uWHwWlTVXVGYTqpqpfOue4G9+0AsOAS/07iEgJvllpf+skBT+kBc9WuQjfFN9PJXuBxiTKAoJp0lR1RAL7vAG8kcrpg87xstNg/ZKqbgYQkSOBnwFTVHW1s6sEHR88W+VuoEUKeTAmYRYQTJMnIjNV9cTgNKdqKHifjvgW4Al3kKp2j3LqahEpUNX9IjIBmAWMEZE/45u++CrgTFWtDjpmnYgMUdVF+BqTZznpXYDgBZCMSTsLCMZAbrwdVHUTMC48XURmuezuNw9fAFiM7+Y/Ht/yhw/gWwJzCPCmiADsV9UT8E3f/VcRqQEWADOdcx1PbXWWMZ6w2U5Nk+eMJXBbROVXqro0zrGzwksTQdua41v39rw65q8N8GdV/UFdzmNMPBYQjKkDEenolB6ibT8C38Iuq+rwGWOAFaq6IdVzGJMICwjGGGMAG4dgjDHGYQHBGGMMYAHBGGOMwwKCMcYYwAKCMcYYhwUEY4wxAPw/WNXxYZSxrjoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화\n",
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       you :  [-1.1576275 -1.1275733 -1.1181736  1.0868896 -1.3008032]\n",
      "       say :  [ 1.2234515   1.188574    1.2198206  -1.2201056   0.26780623]\n",
      "   goodbye :  [-0.65437067 -0.85305285 -0.70957863  0.7816981  -0.7345267 ]\n",
      "       and :  [ 0.96231675  1.003541    1.0038494  -0.9032868   1.8672729 ]\n",
      "         i :  [-0.65883726 -0.8543849  -0.69965684  0.8007502  -0.74782807]\n",
      "     hello :  [-1.2029454 -1.0971576 -1.107923   1.0922168 -1.294185 ]\n",
      "         . :  [ 1.0833081   0.99575454  1.1252542  -1.138593   -1.760465  ]\n"
     ]
    }
   ],
   "source": [
    "# W_in : 인스턴스 변수인 단어의 분산 표현\n",
    "word_vecs = model.word_vec # (7,5)\n",
    "\n",
    "for word_id, word in id_to_word.items():\n",
    "    print('%10s : '%word, word_vecs[word_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(0, 'you'), (1, 'say'), (2, 'goodbye'), (3, 'and'), (4, 'i'), (5, 'hello'), (6, '.')])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 및 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.16381383e-03 7.17599936e-01 3.48934794e-04 2.61877025e-01\n",
      "  3.50165498e-04 3.47986685e-03 8.18025806e-03]\n",
      " [1.22762903e-02 8.18450402e-05 4.65651505e-01 2.57061949e-04\n",
      "  4.64163787e-01 4.53145757e-02 1.22549349e-02]\n",
      " [1.99469721e-02 6.48607763e-01 1.66502890e-03 2.99664164e-01\n",
      "  1.66934340e-03 8.50944163e-03 1.99372868e-02]\n",
      " [1.22762903e-02 8.18450402e-05 4.65651505e-01 2.57061949e-04\n",
      "  4.64163787e-01 4.53145757e-02 1.22549349e-02]\n",
      " [8.08017516e-03 7.18839469e-01 3.40636370e-04 2.60886143e-01\n",
      "  3.42119262e-04 3.41508382e-03 8.09637373e-03]\n",
      " [2.10896670e-03 2.35578558e-04 4.49088662e-02 4.23772507e-04\n",
      "  4.49647540e-02 9.05180506e-01 2.17755640e-03]]\n",
      "(6, 7)\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "h = model.predict(contexts)\n",
    "print(h)\n",
    "print(h.shape) # (6,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: [1 2 3 4 1 5]\n",
      "predict: [1 2 1 2 1 5]\n"
     ]
    }
   ],
   "source": [
    "preds = np.argmax(h,1)\n",
    "t = np.argmax(target,1)\n",
    "print('target:',t)\n",
    "print('predict:',preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.6667\n"
     ]
    }
   ],
   "source": [
    "# 정확도\n",
    "accuracy = np.sum(np.equal(preds,t))/len(t)\n",
    "print('정확도 :', np.round(accuracy,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
