{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative Sampling  : 네거티브 샘플링\n",
    "\n",
    "### Embedding과 EmbeddingDot 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# nn_layers.py에 추가하여 놓는다\n",
    "\n",
    "# Embedding 계층\n",
    "class Embedding :\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.idx = None\n",
    "    \n",
    "    # 순전파\n",
    "    def forward(self,idx):\n",
    "        W, = self.params\n",
    "        self.idx = idx\n",
    "        out = W[idx]\n",
    "        return out\n",
    "    \n",
    "    # 역전파\n",
    "    def backward(self, dout):  # 중복 인덱스가 있어도 올바르게 처리, 속도가 빠름\n",
    "        dW, = self.grads\n",
    "        dW[...] = 0\n",
    "        np.add.at(dW, self.idx, dout)  \n",
    "        return None       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EmbeddingDot 계층\n",
    "# nn_layers.py에 추가하여 놓는다\n",
    "\n",
    "class EmbeddingDot:\n",
    "    def __init__(self,W):\n",
    "        self.embed = Embedding(W)\n",
    "        self.params = self.embed.params\n",
    "        self.grads = self.embed.grads\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self,h,idx):\n",
    "        target_W = self.embed.forward(idx)\n",
    "        out = np.sum(target_W*h,axis=1)   # 1차원 출력\n",
    "        self.cache = (h, target_W)\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        h, target_W = self.cache\n",
    "        dout = dout.reshape(dout.shape[0],1) # 2차원으로 변환\n",
    "        \n",
    "        dtarget_W = dout*h  # sum <--> repeat, 브로드캐스트\n",
    "        self.embed.backward(dtarget_W)\n",
    "        \n",
    "        dh = dout*target_W  # 브로드캐스트\n",
    "        return dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W:\n",
      " [[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]\n",
      " [12 13 14]\n",
      " [15 16 17]\n",
      " [18 19 20]]\n",
      "idx:\n",
      " [0 3 1]\n",
      "h:\n",
      " [[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "out:\n",
      " [  5 122  86]\n",
      "h:\n",
      " [[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "target_W:\n",
      " [[ 0  1  2]\n",
      " [ 9 10 11]\n",
      " [ 3  4  5]]\n"
     ]
    }
   ],
   "source": [
    "# EmbeddingDot 클래스 테스트 \n",
    "W = np.arange(21).reshape(7,3)\n",
    "print('W:\\n',W)\n",
    "\n",
    "idx = np.array([0,3,1])\n",
    "print('idx:\\n',idx)\n",
    "\n",
    "h = W[[0,1,2]]\n",
    "print('h:\\n',h)\n",
    "\n",
    "embed_dot = EmbeddingDot(W)\n",
    "out = embed_dot.forward(h,idx)\n",
    "print('out:\\n',out)\n",
    "\n",
    "print('h:\\n',embed_dot.cache[0])\n",
    "print('target_W:\\n',embed_dot.cache[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_W:\n",
      " [[ 0  1  2]\n",
      " [ 9 10 11]\n",
      " [ 3  4  5]]\n",
      "h:\n",
      " [[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "temp:\n",
      " [[ 0  1  4]\n",
      " [27 40 55]\n",
      " [18 28 40]]\n",
      "out:\n",
      " [  5 122  86]\n"
     ]
    }
   ],
   "source": [
    "# EmbeddingDot 계층의 forward 함수내에서 변수의 값 변화 정보\n",
    "idx = np.array([0,3,1])\n",
    "embed = Embedding(W)\n",
    "target_W = embed.forward(idx) # W에서 임베딩 처리\n",
    "print('target_W:\\n',target_W)\n",
    "\n",
    "h = W[[0,1,2]]\n",
    "print('h:\\n',h)\n",
    "\n",
    "temp = target_W * h\n",
    "print('temp:\\n',temp)\n",
    "\n",
    "out = np.sum(temp,axis=1)\n",
    "print('out:\\n',out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네거티브 샘플링 기법\n",
    " https://ddiri01.tistory.com/310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0에서 9까지의 숫자 중 하나를 무작위로 샘플링\n",
    "np.random.choice(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words에서만 하나만 무작위로 샘플링\n",
    "words = ['you','say','goodbye','i','hello','.']\n",
    "np.random.choice(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['you', '.', 'i', 'hello', '.'], dtype='<U7')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5개만 무작위로 샘플링 (중복 허용)\n",
    "np.random.choice(words,size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['goodbye', 'you', 'i', '.', 'hello'], dtype='<U7')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5개만 무작위로 샘플링 (중복 금지)\n",
    "np.random.choice(words,size=5,replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'say'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주어진 확률 분포에 따라 샘플링\n",
    "p = [0.5,0.1,0.05,0.2,0.05,0.1]  # 합이 1.0\n",
    "print(sum(p))\n",
    "\n",
    "np.random.choice(words,p = p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[0.76528558 0.39518322 0.03162278]\n",
      "[0.64196878 0.33150408 0.02652714]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 네거티브 샘플링에서는 기본 확률 분포에 0.75를 제곱해준다\n",
    "# 확률분포 값들에 모두 0.75제곱 처리 ==> 원래 확률이 낮은 단어를 버리지 않기 위해서\n",
    "p = [0.7,0.29,0.01]\n",
    "print(sum(p))\n",
    "new_p = np.power(p,0.75)\n",
    "print(new_p)\n",
    "new_p /= np.sum(new_p) # 다시 전체 요소의 합으로나누어 각 요소의 합이 1.0이 나오도록 새로운 확률 분포를 만든다\n",
    "print(new_p)\n",
    "print(sum(new_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 16\n"
     ]
    }
   ],
   "source": [
    "print(2**4, np.power(2,4) ) # 2^4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3개의 긍정 unigram 타겟을 주면  부정 맥락 2개씩 3개를 샘플링하여 생성해주는 클래스  \n",
    "# nn_layers.py에 추가하여 놓는다\n",
    "\n",
    "import collections\n",
    "class UnigramSampler:    \n",
    "    # 생성자 : corpus를 사용하여 단어의 0.75제곱 처리한 확률 분포를 구함\n",
    "    def __init__(self, corpus, power, sample_size): # power= 0.75, sample_size = 2\n",
    "        self.sample_size = sample_size\n",
    "        self.vocab_size = None\n",
    "        self.word_p = None\n",
    "\n",
    "        # corpus 내의 단어별 발생횟수를 구함    \n",
    "        counts = collections.Counter()  \n",
    "        for word_id in corpus:   # corpus: [0 1 2 3 4 1 5 6], \n",
    "            counts[word_id] += 1\n",
    "\n",
    "        vocab_size = len(counts)\n",
    "        self.vocab_size = vocab_size  # 7\n",
    "\n",
    "        self.word_p = np.zeros(vocab_size)  # (7,)\n",
    "        for i in range(vocab_size):  # 7 \n",
    "            self.word_p[i] = counts[i]  # [1, 2, 1, 1, 1, 1, 1] ,단어 발생 횟수\n",
    "\n",
    "        self.word_p = np.power(self.word_p, power) # 0.75제곱\n",
    "        self.word_p /= np.sum(self.word_p)  # 전체의 합으로 나누어 확률을 구함\n",
    "\n",
    "\n",
    "    def get_negative_sample(self, target):   # target = np.array([1, 3, 0]), (3,)\n",
    "        batch_size = target.shape[0]  # 3\n",
    "        \n",
    "        negative_sample = np.zeros((batch_size, self.sample_size), dtype=np.int32)  # (3,2)\n",
    "\n",
    "        for i in range(batch_size):  # 3회\n",
    "            p = self.word_p.copy()\n",
    "            target_idx = target[i]  # 1,3,0\n",
    "            p[target_idx] = 0  # p[1]=0,p[3]=0,p[0]=0 ,부정 단어로 target이 선택되지 않도록 확률 값을 0으로 설정 \n",
    "            p /= p.sum()\n",
    "            negative_sample[i, :] = np.random.choice(self.vocab_size, size=self.sample_size, replace=False, p=p)\n",
    "            \n",
    "        return negative_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'l': 3, 'o': 2, 'h': 1, 'e': 1, ' ': 1, 'w': 1, 'r': 1, 'd': 1})\n",
      "Counter({'a': 4, 'f': 4, 'b': 3, 'e': 3, 'g': 3, 'c': 2, 'd': 1})\n",
      "Counter({1: 2, 0: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1})\n",
      "corpus: [0 1 2 3 4 1 5 6]\n",
      "**before: 0 0\n",
      "   after: 0 1\n",
      "**before: 1 0\n",
      "   after: 1 1\n",
      "**before: 2 0\n",
      "   after: 2 1\n",
      "**before: 3 0\n",
      "   after: 3 1\n",
      "**before: 4 0\n",
      "   after: 4 1\n",
      "**before: 1 1\n",
      "   after: 1 2\n",
      "**before: 5 0\n",
      "   after: 5 1\n",
      "**before: 6 0\n",
      "   after: 6 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 1, 1: 2, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collections.Counter어떤 단어가 주어졌을 때 단어에 포함된 각 알파벳의 글자 수를 dict로 세어주는 클래스\n",
    "# https://www.daleseo.com/python-collections-counter/\n",
    "import collections\n",
    "print(collections.Counter('hello world'))\n",
    "print(collections.Counter('aaaabbbccdeeeffffggg'))\n",
    "\n",
    "corpus = np.array([0, 1, 2, 3, 4, 1, 5, 6])\n",
    "print(collections.Counter(corpus))\n",
    "\n",
    "# corpus 내의 단어별 발생횟수를 구함\n",
    "counts = collections.Counter()\n",
    "print('corpus:',corpus)\n",
    "corpus = np.array([0, 1, 2, 3, 4, 1, 5, 6])\n",
    "for word_id in corpus:\n",
    "    print('**before:',word_id,counts[word_id])\n",
    "    counts[word_id] += 1\n",
    "    print('   after:',word_id,counts[word_id])\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정(Yes) :  [2 4 3]\n",
      "부정(No)  : \n",
      " [[1 3]\n",
      " [3 1]\n",
      " [2 1]]\n"
     ]
    }
   ],
   "source": [
    "corpus= np.array([0, 1, 2, 3, 4, 1, 2, 3]) \n",
    "power = 0.75\n",
    "sample_size = 2 # 부정적 예 2개를 샘플링\n",
    "\n",
    "sampler = UnigramSampler(corpus,power,sample_size)\n",
    "\n",
    "target = np.array([2,4,3])\n",
    "negative_sample = sampler.get_negative_sample(target)\n",
    "\n",
    "print('긍정(Yes) : ', target)\n",
    "print('부정(No)  : \\n', negative_sample)  # 실행 시마다 다름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SigmoidWithLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SigmoidWithLoss 클래스 사용 \n",
    "# nn_layers.py 에 추가한다\n",
    "\n",
    "class SigmoidWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.loss = None\n",
    "        self.y = None  # sigmoid의 출력\n",
    "        self.t = None  # 정답 데이터\n",
    "\n",
    "    def cross_entropy_error(self,y, t):   # softmax 와 동일\n",
    "        if y.ndim == 1:\n",
    "            t = t.reshape(1, t.size)\n",
    "            y = y.reshape(1, y.size)\n",
    "\n",
    "        # 정답 데이터가 원핫 벡터일 경우 정답 레이블 인덱스로 변환\n",
    "        if t.size == y.size:\n",
    "            t = t.argmax(axis=1)\n",
    "\n",
    "        batch_size = y.shape[0]\n",
    "\n",
    "        return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = 1 / (1 + np.exp(-x))   # sigmoid , 예측값\n",
    "\n",
    "        self.loss = self.cross_entropy_error(np.c_[1 - self.y, self.y], self.t)\n",
    "\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "\n",
    "        dx = (self.y - self.t) * dout / batch_size\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "B:\n",
      " [[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 1.]]\n",
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]]\n",
      "[1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# np.c_()  # c_: column으로 합치기\n",
    "# https://rfriend.tistory.com/tag/np.c_%20%ED%95%A8%EC%88%98\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "N = 3\n",
    "A = np.eye(N)\n",
    "print('A:\\n', A)\n",
    "B = np.c_[A, A[2]]\n",
    "print('B:\\n', B)\n",
    "\n",
    "A = [1,2,3]\n",
    "B = [4,5,6]\n",
    "C = np.c_[A,B]\n",
    "print(C)\n",
    "\n",
    "R = np.r_[A,B]  # r_: row로 합치기\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네거티브 샘플링 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NegativeSamplingLoss 클래스\n",
    "# nn_layers.py 에 추가한다\n",
    "\n",
    "class NegativeSamplingLoss:\n",
    "    def __init__(self,W,corpus,power=0.75,sample_size=5): #  sample_size : 부정 단어 샘플링 수 (2개)\n",
    "        self.sample_size = sample_size\n",
    "        self.sampler = UnigramSampler(corpus,power,sample_size)\n",
    "        self.embed_dot_layers = [EmbeddingDot(W) for _ in range(sample_size + 1)] # 긍정 1개 + 부정 2개\n",
    "        self.loss_layers = [SigmoidWithLoss() for _ in range(sample_size + 1)]   # 긍정 1개 + 부정 2개\n",
    "        \n",
    "        self.params, self.grads = [],[]\n",
    "        for layer in self.embed_dot_layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "    def forward(self,h,target) : # target은 긍정단어의 index\n",
    "        batch_size = target.shape[0]\n",
    "        negative_sample = self.sampler.get_negative_sample(target) # 부정 단어 샘플\n",
    "        \n",
    "        # 긍정단어 순전파\n",
    "        score = self.embed_dot_layers[0].forward(h,target)  # target-->index\n",
    "        correct_label = np.ones(batch_size, dtype=np.int32) # 값이 모두 1: 긍정\n",
    "        loss = self.loss_layers[0].forward(score,correct_label)        \n",
    "        \n",
    "        # 부정단어 순전파\n",
    "        negative_label = np.zeros(batch_size,dtype-np.int32) # 값이 모두 0 : 부정 \n",
    "        \n",
    "        for i in range(self.sample_size):\n",
    "            negative_target = negative_sample[:,i]\n",
    "            score = self.embed_dot_layers[i + 1].forward(h,negative_target)\n",
    "            loss += self.loss_layers[i + 1].forward(score,negative_label) # loss의 누적 합\n",
    "            \n",
    "        return loss\n",
    "     \n",
    "    def backward(self,dout=1)  : # 입력값을 각 계층의 backward만 호출하여 전달\n",
    "        dh = 0\n",
    "        for l0,l1 in zip(self.loss_layers, self.embed_dot_layers):  # 역전파이므로  los_layer가 먼저 호출된다\n",
    "            dscore = l0.backward(dout)   # SigmoidWithLoss 계층\n",
    "            dh += l1.backward(dscore)   # EmbeddingDot 계층   \n",
    "        return dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<__main__.SigmoidWithLoss at 0x1f176c1a548>,\n",
       "  <__main__.SigmoidWithLoss at 0x1f176c1a648>,\n",
       "  <__main__.SigmoidWithLoss at 0x1f176c1a588>],\n",
       " [<__main__.EmbeddingDot at 0x1f176bc9448>,\n",
       "  <__main__.EmbeddingDot at 0x1f176c1a148>,\n",
       "  <__main__.EmbeddingDot at 0x1f176c1a188>])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.random.randn(7,3)\n",
    "neg = NegativeSamplingLoss(W,corpus,0.75,2)\n",
    "neg.loss_layers, neg.embed_dot_layers  # 각각 3개씩 생성 되었다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
