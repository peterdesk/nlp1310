{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n",
      "[0 1 0 0 0 0 0 0]\n",
      "[0 1 0 1 0 0 0 0]\n",
      "[0 1 0 1 0 0 0 0]\n",
      "[0 1 0 0 0 0 0]\n",
      "[0 1 0 1 0 0 0]\n",
      "0.7071067691154799\n",
      "[0 1 0 1 0 0 0]\n",
      "[0 1 0 0 0 0 1]\n",
      "0.49999999292893216\n",
      "\n",
      "[query] you\n",
      " goodbye: 0.7071067691154799\n",
      " i: 0.7071067691154799\n",
      " hello: 0.7071067691154799\n",
      " say: 0.0\n",
      " and: 0.0\n"
     ]
    }
   ],
   "source": [
    "from mynlp import preprocess, create_co_matrix, cos_similarity, most_similar\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ppmi 계산을 함수로 구현 \n",
    "def ppmi(C, verbose=False, eps = 1e-8):\n",
    "    M = np.zeros_like(C, dtype=np.float32)\n",
    "    N = np.sum(C)\n",
    "    S = np.sum(C, axis=0)\n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            pmi = np.log2(C[i, j] * N / (S[i]*S[j]) + eps)\n",
    "            M[i, j] = max(0, pmi)\n",
    "\n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % (total//100) == 0:\n",
    "                    print('%.1f%% 완료' % (100*cnt/total))\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataset import ptb\n",
    "\n",
    "# corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "\n",
    "# print('말뭉치 크기:', len(corpus), corpus.shape)  # (929589,)\n",
    "# print('corpus[:30]:', corpus[:30])\n",
    "# print()\n",
    "# print('id_to_word[0]:', id_to_word[0])\n",
    "# print('id_to_word[1]:', id_to_word[1])\n",
    "# print('id_to_word[2]:', id_to_word[2])\n",
    "# print()\n",
    "# print(\"word_to_id['car']:\", word_to_id['car'])\n",
    "# print(\"word_to_id['happy']:\", word_to_id['happy'])\n",
    "# print(\"word_to_id['lexus']:\", word_to_id['lexus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습과제 답안 구현 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [실습 과제]  : PPMI 단어의 유사도 측정\n",
    "\n",
    "# 1. 아래 문장에 사용된 단어를 PTB데이터셋을 PPMI 와 SVD 차원 축소 기법을 사용하여 만든 벡터에 넣어 각 단어들의 유사도를 측정하여 출력해보세요\n",
    "\n",
    "# text = \"The black cat ran so fast that the white mouse could not run away.\"\n",
    "\n",
    "# 주어진 text를 말뭉치로 변환한다\n",
    "# 마침표는 삭제한다\n",
    "# 유사도 출력 코드는 for 문을 사용하여 반복한다\n",
    "\n",
    "# 2. WordNet을 사용한 경로 거리 기반 유사도 (Path Distance Similarity)값과 비교하여 보세요\n",
    "# 'black'과 'white'의 유사도와 'cat'과 'mouse'의 유사도만 다음 3개의 방법으로 비교해 본다\n",
    "# - 경로 거리 기반 유사도 (Path Distance Similarity)\n",
    "# - 우 팔머 유사도 (Wu-Palmer Similarity)\n",
    "# - 리콕 초도로우 유사도(Leacock Chordorow Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동시발생 수 계산 ...\n",
      "PPMI 계산 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf20\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: overflow encountered in long_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf20\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in log2\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0% 완료\n",
      "2.0% 완료\n",
      "3.0% 완료\n",
      "4.0% 완료\n",
      "5.0% 완료\n",
      "6.0% 완료\n",
      "7.0% 완료\n",
      "8.0% 완료\n",
      "9.0% 완료\n",
      "10.0% 완료\n",
      "11.0% 완료\n",
      "12.0% 완료\n",
      "13.0% 완료\n",
      "14.0% 완료\n",
      "15.0% 완료\n",
      "16.0% 완료\n",
      "17.0% 완료\n",
      "18.0% 완료\n",
      "19.0% 완료\n",
      "20.0% 완료\n",
      "21.0% 완료\n",
      "22.0% 완료\n",
      "23.0% 완료\n",
      "24.0% 완료\n",
      "25.0% 완료\n",
      "26.0% 완료\n",
      "27.0% 완료\n",
      "28.0% 완료\n",
      "29.0% 완료\n",
      "30.0% 완료\n",
      "31.0% 완료\n",
      "32.0% 완료\n",
      "33.0% 완료\n",
      "34.0% 완료\n",
      "35.0% 완료\n",
      "36.0% 완료\n",
      "37.0% 완료\n",
      "38.0% 완료\n",
      "39.0% 완료\n",
      "40.0% 완료\n",
      "41.0% 완료\n",
      "42.0% 완료\n",
      "43.0% 완료\n",
      "44.0% 완료\n",
      "45.0% 완료\n",
      "46.0% 완료\n",
      "47.0% 완료\n",
      "48.0% 완료\n",
      "49.0% 완료\n",
      "50.0% 완료\n",
      "51.0% 완료\n",
      "52.0% 완료\n",
      "53.0% 완료\n",
      "54.0% 완료\n",
      "55.0% 완료\n",
      "56.0% 완료\n",
      "57.0% 완료\n",
      "58.0% 완료\n",
      "59.0% 완료\n",
      "60.0% 완료\n",
      "61.0% 완료\n",
      "62.0% 완료\n",
      "63.0% 완료\n",
      "64.0% 완료\n",
      "65.0% 완료\n",
      "66.0% 완료\n",
      "67.0% 완료\n",
      "68.0% 완료\n",
      "69.0% 완료\n",
      "70.0% 완료\n",
      "71.0% 완료\n",
      "72.0% 완료\n",
      "73.0% 완료\n",
      "74.0% 완료\n",
      "75.0% 완료\n",
      "76.0% 완료\n",
      "77.0% 완료\n",
      "78.0% 완료\n",
      "79.0% 완료\n",
      "80.0% 완료\n",
      "81.0% 완료\n",
      "82.0% 완료\n",
      "83.0% 완료\n",
      "84.0% 완료\n",
      "85.0% 완료\n",
      "86.0% 완료\n",
      "87.0% 완료\n",
      "88.0% 완료\n",
      "89.0% 완료\n",
      "90.0% 완료\n",
      "91.0% 완료\n",
      "92.0% 완료\n",
      "93.0% 완료\n",
      "94.0% 완료\n",
      "95.0% 완료\n",
      "96.0% 완료\n",
      "97.0% 완료\n",
      "98.0% 완료\n",
      "99.0% 완료\n",
      "100.0% 완료\n"
     ]
    }
   ],
   "source": [
    "# PTB 데이터셋으로 PPMI 얻기\n",
    "\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "window_size = 2\n",
    "wordvec_size = 100\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "print('동시발생 수 계산 ...')\n",
    "C = create_co_matrix(corpus, vocab_size, window_size)\n",
    "print('PPMI 계산 ...')\n",
    "W = ppmi(C, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating SVD ...\n",
      "(10000, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-7.1707566e-12,  5.1619224e-08, -4.1907410e-07, ...,\n",
       "        -3.8067374e-05,  1.2358902e-04, -7.4633238e-07],\n",
       "       [-1.4708361e-11,  1.2856992e-07, -1.1112376e-07, ...,\n",
       "        -6.0247141e-05,  1.7635472e-04, -2.3392754e-06],\n",
       "       [-5.5097797e-12, -2.0442064e-09,  1.1041527e-08, ...,\n",
       "        -8.3547144e-05,  2.3952904e-04, -4.1339858e-06],\n",
       "       ...,\n",
       "       [ 4.4260337e-03, -6.4803013e-03,  1.1453294e-02, ...,\n",
       "         1.4470930e-02, -3.2744058e-03,  4.6140300e-03],\n",
       "       [ 2.4589046e-03, -4.9205646e-03,  8.0249971e-03, ...,\n",
       "         1.0419410e-03,  4.4056461e-03,  4.0153073e-04],\n",
       "       [ 3.8884017e-03, -7.8423517e-03,  8.0783209e-03, ...,\n",
       "        -2.1364212e-03, -2.3151156e-03,  1.5917586e-02]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('calculating SVD ...')\n",
    "\n",
    "# truncated SVD : 속도가 빠르다, random 사용으로 매번 다른 결과 출력\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "U, S, V = randomized_svd(W, n_components=wordvec_size, n_iter=5,\n",
    "                         random_state=None)\n",
    "\n",
    "word_vecs = U[:, :wordvec_size]  # 100개로 차원 축소\n",
    "print(word_vecs.shape) # (1000,100)\n",
    "word_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most_similar('she', word_to_id, id_to_word, word_vecs, top=5)\n",
    "# most_similar('was', word_to_id, id_to_word, word_vecs, top=5)\n",
    "# most_similar('much', word_to_id, id_to_word, word_vecs, top=5)\n",
    "# most_similar('scared', word_to_id, id_to_word, word_vecs, top=5)\n",
    "# most_similar('because', word_to_id, id_to_word, word_vecs, top=5)\n",
    "# most_similar('the', word_to_id, id_to_word, word_vecs, top=5)\n",
    "# most_similar('lion', word_to_id, id_to_word, word_vecs, top=5)\n",
    "# most_similar('was', word_to_id, id_to_word, word_vecs, top=5)\n",
    "# most_similar('too', word_to_id, id_to_word, word_vecs, top=5)\n",
    "# most_similar('big', word_to_id, id_to_word, word_vecs, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'black',\n",
       " 'cat',\n",
       " 'ran',\n",
       " 'so',\n",
       " 'fast',\n",
       " 'that',\n",
       " 'the',\n",
       " 'white',\n",
       " 'mouse',\n",
       " 'could',\n",
       " 'not',\n",
       " 'run',\n",
       " 'away']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'The black cat ran so fast that the white mouse could not run away.'\n",
    "text = text.lower()\n",
    "text = text.replace('.', '')\n",
    "words = text.split(' ')\n",
    "\n",
    "# corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] the\n",
      " of: 0.6370799541473389\n",
      " a: 0.6024384498596191\n",
      " in: 0.5321652293205261\n",
      " this: 0.4323727488517761\n",
      " <unk>: 0.43163061141967773\n",
      "\n",
      "[query] black\n",
      " hispanic: 0.4898976981639862\n",
      " white: 0.4879007339477539\n",
      " young: 0.4864444136619568\n",
      " women: 0.48602789640426636\n",
      " activist: 0.4495448172092438\n",
      "\n",
      "[query] cat\n",
      " test: 0.5497627258300781\n",
      " lumpur: 0.5094209909439087\n",
      " bars: 0.48442214727401733\n",
      " kuala: 0.45799267292022705\n",
      " holidays: 0.4501901865005493\n",
      "\n",
      "[query] ran\n",
      " turned: 0.5427704453468323\n",
      " throws: 0.523361325263977\n",
      " carpeting: 0.5218486189842224\n",
      " interior: 0.5037709474563599\n",
      " pulls: 0.5019594430923462\n",
      "\n",
      "[query] so\n",
      " too: 0.5818270444869995\n",
      " far: 0.42303043603897095\n",
      " quite: 0.39934849739074707\n",
      " much: 0.3794543147087097\n",
      " more: 0.3670775890350342\n",
      "\n",
      "[query] fast\n",
      " hard: 0.5779397487640381\n",
      " attractive: 0.5157228112220764\n",
      " accessible: 0.4956439435482025\n",
      " quickly: 0.46727269887924194\n",
      " risky: 0.43322256207466125\n",
      "\n",
      "[query] that\n",
      " he: 0.5803117156028748\n",
      " it: 0.4878789186477661\n",
      " they: 0.44563642144203186\n",
      " there: 0.4423104524612427\n",
      " but: 0.43405288457870483\n",
      "\n",
      "[query] the\n",
      " of: 0.6370799541473389\n",
      " a: 0.6024384498596191\n",
      " in: 0.5321652293205261\n",
      " this: 0.4323727488517761\n",
      " <unk>: 0.43163061141967773\n",
      "\n",
      "[query] white\n",
      " house: 0.5695686340332031\n",
      " black: 0.4879007339477539\n",
      " men: 0.4749022126197815\n",
      " marlin: 0.46397513151168823\n",
      " senior: 0.4539763033390045\n",
      "\n",
      "[query] mouse\n",
      " fuels: 0.5055699944496155\n",
      " pertussis: 0.4844275414943695\n",
      " ninth: 0.48253133893013\n",
      " whooping: 0.478657066822052\n",
      " irrelevant: 0.46392595767974854\n",
      "\n",
      "[query] could\n",
      " would: 0.564531147480011\n",
      " wo: 0.5052471160888672\n",
      " will: 0.4875374436378479\n",
      " might: 0.48235511779785156\n",
      " able: 0.4633132517337799\n",
      "\n",
      "[query] not\n",
      " n't: 0.5302169322967529\n",
      " does: 0.4349810481071472\n",
      " be: 0.4075291156768799\n",
      " do: 0.40411925315856934\n",
      " did: 0.3723061680793762\n",
      "\n",
      "[query] run\n",
      " crews: 0.4147259294986725\n",
      " brought: 0.39116358757019043\n",
      " stay: 0.38805121183395386\n",
      " ride: 0.38712382316589355\n",
      " developed: 0.3795872926712036\n",
      "\n",
      "[query] away\n",
      " off: 0.6041542291641235\n",
      " out: 0.5288988947868347\n",
      " down: 0.4792684316635132\n",
      " back: 0.46202826499938965\n",
      " up: 0.42643338441848755\n"
     ]
    }
   ],
   "source": [
    "for query in words:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습 과제 2번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black: [path] 0.08333333333333333\n",
      "black: [wup] 0.15384615384615385\n",
      "black: [lch] 1.1526795099383855\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "# syn = wordnet.synsets('black')\n",
    "# print(syn)\n",
    "black = wordnet.synset('black.n.01')\n",
    "white = wordnet.synset('white.n.01')\n",
    "\n",
    "# 경로 유사도\n",
    "print('black: [path]', black.path_similarity(white))\n",
    "\n",
    "# Wu-Palmer Similarit\n",
    "print('black: [wup]', black.wup_similarity(white))\n",
    "\n",
    "# Leacock Chordorow Similarity\n",
    "print('black: [lch]', black.lch_similarity(white))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: [path] 0.05\n",
      "cat: [wup] 0.09523809523809523\n",
      "cat: [lch] 0.6418538861723948\n"
     ]
    }
   ],
   "source": [
    "# syn = wordnet.synsets('cat')\n",
    "# print(syn)\n",
    "cat = wordnet.synset('cat.n.01')\n",
    "mouse = wordnet.synset('mouse.n.01')\n",
    "\n",
    "# 경로 유사도\n",
    "print('cat: [path]', black.path_similarity(mouse))\n",
    "\n",
    "# Wu-Palmer Similarit\n",
    "print('cat: [wup]', black.wup_similarity(mouse))\n",
    "\n",
    "# Leacock Chordorow Similarity\n",
    "print('cat: [lch]', black.lch_similarity(mouse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "black - white [path] : 0.083333\n",
      "black - white [wup] : 0.15384615384615385\n",
      "black - white [lch] : 1.1526795099383855\n",
      "--------------------------------------------------\n",
      "cat - mouse [path] : 0.166667\n",
      "cat - mouse [wup] : 0.8148148148148148\n",
      "cat - mouse [lch] : 1.845826690498331\n",
      "--------------------------------------------------\n",
      "fast - run [path] : 0.083333\n",
      "fast - run [wup] : 0.47619047619047616\n",
      "fast - run [lch] : 1.1526795099383855\n"
     ]
    }
   ],
   "source": [
    "#  정규표현식 사용 자동화 구현\n",
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# 표제어를 정규표현식으로 검출\n",
    "def get_match(word) :\n",
    "    # r = r\"black.n.01\"\n",
    "    r = r\"^(%s)+(.)([a-z]+)(.)(01)$\"%word\n",
    "    p = re.compile(r, re.I)\n",
    "\n",
    "    syn = [ syn.name() for syn in wordnet.synsets(word) ]\n",
    "    # print(syn) \n",
    "\n",
    "    for s in syn:\n",
    "        # print(s)\n",
    "        match = p.match(s,0)\n",
    "        if match :\n",
    "            #print(match.group())\n",
    "            break\n",
    "    if match.group():\n",
    "        return match.group()\n",
    "\n",
    "# 검출된 두 단어의 표제어로 유사도 출력\n",
    "def get_wordnet_similarity(word1,word2):\n",
    "    \n",
    "    word1_match = get_match(word1)\n",
    "    word2_match = get_match(word2)\n",
    "\n",
    "    word1_syn = wordnet.synset(word1_match)\n",
    "    word2_syn = wordnet.synset(word2_match)\n",
    "    print('-'*50)\n",
    "\n",
    "    # 경로 유사도\n",
    "    print('%s - %s [path] : %f'%(word1,word2, word1_syn.path_similarity(word2_syn)))\n",
    "    \n",
    "    # Wu-Palmer Similarity\n",
    "    print('%s - %s [wup] :'%(word1,word2), word1_syn.wup_similarity(word2_syn))\n",
    "\n",
    "    # Leacock Chordorow Similarity\n",
    "    print('%s - %s [lch] :'%(word1,word2), word1_syn.lch_similarity(word2_syn))\n",
    "\n",
    "\n",
    "# 함수 호출   \n",
    "get_wordnet_similarity('black', 'white')\n",
    "get_wordnet_similarity('cat', 'mouse')\n",
    "get_wordnet_similarity('fast', 'run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
