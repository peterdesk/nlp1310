{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HtHF88M8SXZk"
   },
   "source": [
    "# 기계 번역(Neural Machine Translation)\n",
    "## [1] 영한 번역기 구현 :   Character-Level 번역기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2360,
     "status": "ok",
     "timestamp": 1600603819775,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "XWn6aM4tSXZm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib3\n",
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3062,
     "status": "ok",
     "timestamp": 1600603820481,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "VkxtFa8sSXZz"
   },
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "url ='http://www.manythings.org/anki/kor-eng.zip'\n",
    "filename = 'kor-eng.zip'\n",
    "path = os.getcwd()\n",
    "zipfilename = os.path.join(path, filename)\n",
    "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
    "    shutil.copyfileobj(r, out_file)\n",
    "\n",
    "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3052,
     "status": "ok",
     "timestamp": 1600603820482,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "Gk8Sy8bYSXZ7",
    "outputId": "dca161f2-94c0-4e36-a783-ed8fa3243c4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3638, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines= pd.read_csv('kor.txt', names=['src', 'tar'], sep='\\t', index_col =False)\n",
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 491
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3044,
     "status": "ok",
     "timestamp": 1600603820483,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "RidzraTvSXaj",
    "outputId": "f6945e1b-5d5e-4a76-f0d5-db5575cca405"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>가.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>안녕.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>뛰어!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run.</td>\n",
       "      <td>뛰어.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who?</td>\n",
       "      <td>누구?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>우와!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fire!</td>\n",
       "      <td>쏴!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Help!</td>\n",
       "      <td>도와줘!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jump!</td>\n",
       "      <td>점프!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>점프해.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Wait!</td>\n",
       "      <td>기다려!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wait!</td>\n",
       "      <td>잠깐!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wait.</td>\n",
       "      <td>기다려.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Begin.</td>\n",
       "      <td>시작해.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hello!</td>\n",
       "      <td>안녕!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       src   tar\n",
       "0      Go.    가.\n",
       "1      Hi.   안녕.\n",
       "2     Run!   뛰어!\n",
       "3     Run.   뛰어.\n",
       "4     Who?   누구?\n",
       "5     Wow!   우와!\n",
       "6    Fire!    쏴!\n",
       "7    Help!  도와줘!\n",
       "8    Jump!   점프!\n",
       "9    Jump.  점프해.\n",
       "10   Wait!  기다려!\n",
       "11   Wait!   잠깐!\n",
       "12   Wait.  기다려.\n",
       "13  Begin.  시작해.\n",
       "14  Hello!   안녕!"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3036,
     "status": "ok",
     "timestamp": 1600603820484,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "mYTJqAO8SXaw",
    "outputId": "b05fd2bc-8f59-4b86-ea68-620d3f8fb79d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>Somebody was talking to Tom.</td>\n",
       "      <td>\\t 누군가 톰한테 말을 걸고 있었어. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>Someone ate all my cupcakes.</td>\n",
       "      <td>\\t 누가 내 컵케익 다 먹었어 \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>That's why I can't help you.</td>\n",
       "      <td>\\t 이게 바로 내가 널 도와줄 수 없는 이유야. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>The cat is still very young.</td>\n",
       "      <td>\\t 그 고양이는 아직도 많이 어려. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>There's a full moon tonight.</td>\n",
       "      <td>\\t 오늘밤은 보름달이 떴어. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>I should've bought more food.</td>\n",
       "      <td>\\t 내가 먹을 것을 더 샀어야 했는데. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>I think that Tom is offended.</td>\n",
       "      <td>\\t 내 생각에 톰은 기분이 상해있어. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>I think that Tom is sensible.</td>\n",
       "      <td>\\t 톰은 예민한 것 같아. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>I tried to act appropriately.</td>\n",
       "      <td>\\t 난 적절하게 처신하려고 노력했어. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>I used to be a heroin addict.</td>\n",
       "      <td>\\t 나는 한때 헤로인 중독자였어. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                src                             tar\n",
       "2000   Somebody was talking to Tom.        \\t 누군가 톰한테 말을 걸고 있었어. \\n\n",
       "2001   Someone ate all my cupcakes.            \\t 누가 내 컵케익 다 먹었어 \\n\n",
       "2002   That's why I can't help you.  \\t 이게 바로 내가 널 도와줄 수 없는 이유야. \\n\n",
       "2003   The cat is still very young.         \\t 그 고양이는 아직도 많이 어려. \\n\n",
       "2004   There's a full moon tonight.             \\t 오늘밤은 보름달이 떴어. \\n\n",
       "...                             ...                             ...\n",
       "2095  I should've bought more food.       \\t 내가 먹을 것을 더 샀어야 했는데. \\n\n",
       "2096  I think that Tom is offended.        \\t 내 생각에 톰은 기분이 상해있어. \\n\n",
       "2097  I think that Tom is sensible.              \\t 톰은 예민한 것 같아. \\n\n",
       "2098  I tried to act appropriately.        \\t 난 적절하게 처신하려고 노력했어. \\n\n",
       "2099  I used to be a heroin addict.          \\t 나는 한때 헤로인 중독자였어. \\n\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target 컬럼 'tar'에 '\\t'와 '\\n'을 앞 뒤로 추가\n",
    "lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "lines[2000:2100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3035,
     "status": "ok",
     "timestamp": 1600603820485,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "LpVBxjtiSXbj"
   },
   "outputs": [],
   "source": [
    "# 'src'와 'tar'의 글자 집합 구축\n",
    "src_vocab=set()\n",
    "for line in lines.src:   # 1줄씩 읽음\n",
    "    for char in line:    # 1개의 글자씩 읽음\n",
    "        src_vocab.add(char)\n",
    "# print(src_vocab)  # 영어의 글자 수\n",
    "\n",
    "tar_vocab=set()\n",
    "for line in lines.tar:\n",
    "    for char in line:\n",
    "        tar_vocab.add(char)\n",
    "# print(tar_vocab)   # 한국어의 글자 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3027,
     "status": "ok",
     "timestamp": 1600603820486,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "B0heErOdSXb8",
    "outputId": "9488efe5-5789-44c2-aa1b-0564961f46b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "912\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(src_vocab)+1\n",
    "tar_vocab_size = len(tar_vocab)+1\n",
    "print(src_vocab_size)\n",
    "print(tar_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3018,
     "status": "ok",
     "timestamp": 1600603820486,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "1wurtoiWSXcA",
    "outputId": "3c17ddf0-facf-42cb-cfc4-ae7a0159b025"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '°', 'ï']\n",
      "['간', '갇', '갈', '감', '갑', '값', '갔', '강', '갖', '같', '개', '객', '갰', '걀', '걔', '거', '걱', '건', '걷', '걸', '검', '겁', '것', '게', '겐', '겠', '겨', '격', '겪', '견']\n"
     ]
    }
   ],
   "source": [
    "src_vocab = sorted(list(src_vocab))\n",
    "tar_vocab = sorted(list(tar_vocab))\n",
    "print(src_vocab[45:75])\n",
    "print(tar_vocab[45:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3010,
     "status": "ok",
     "timestamp": 1600603820487,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "Hm8XLW_WSXcD",
    "outputId": "bd96e901-6ac3-4486-8061-69a6f3df3a6a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, \"'\": 6, ',': 7, '-': 8, '.': 9, '0': 10, '1': 11, '2': 12, '3': 13, '4': 14, '5': 15, '6': 16, '7': 17, '8': 18, '9': 19, ':': 20, ';': 21, '?': 22, 'A': 23, 'B': 24, 'C': 25, 'D': 26, 'E': 27, 'F': 28, 'G': 29, 'H': 30, 'I': 31, 'J': 32, 'K': 33, 'L': 34, 'M': 35, 'N': 36, 'O': 37, 'P': 38, 'Q': 39, 'R': 40, 'S': 41, 'T': 42, 'U': 43, 'V': 44, 'W': 45, 'Y': 46, 'a': 47, 'b': 48, 'c': 49, 'd': 50, 'e': 51, 'f': 52, 'g': 53, 'h': 54, 'i': 55, 'j': 56, 'k': 57, 'l': 58, 'm': 59, 'n': 60, 'o': 61, 'p': 62, 'q': 63, 'r': 64, 's': 65, 't': 66, 'u': 67, 'v': 68, 'w': 69, 'x': 70, 'y': 71, 'z': 72, '°': 73, 'ï': 74}\n",
      "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '%': 6, '(': 7, ')': 8, ',': 9, '-': 10, '.': 11, '/': 12, '0': 13, '1': 14, '2': 15, '3': 16, '4': 17, '5': 18, '6': 19, '7': 20, '8': 21, '9': 22, ':': 23, '?': 24, 'A': 25, 'B': 26, 'C': 27, 'D': 28, 'H': 29, 'M': 30, 'N': 31, 'T': 32, 'a': 33, 'd': 34, 'h': 35, 'i': 36, 'm': 37, 'o': 38, 'p': 39, 'r': 40, 't': 41, 'y': 42, '°': 43, '가': 44, '각': 45, '간': 46, '갇': 47, '갈': 48, '감': 49, '갑': 50, '값': 51, '갔': 52, '강': 53, '갖': 54, '같': 55, '개': 56, '객': 57, '갰': 58, '걀': 59, '걔': 60, '거': 61, '걱': 62, '건': 63, '걷': 64, '걸': 65, '검': 66, '겁': 67, '것': 68, '게': 69, '겐': 70, '겠': 71, '겨': 72, '격': 73, '겪': 74, '견': 75, '결': 76, '겼': 77, '경': 78, '계': 79, '고': 80, '곡': 81, '곤': 82, '곧': 83, '골': 84, '곰': 85, '곱': 86, '곳': 87, '공': 88, '과': 89, '관': 90, '광': 91, '괜': 92, '괴': 93, '굉': 94, '교': 95, '구': 96, '국': 97, '군': 98, '굳': 99, '굴': 100, '굶': 101, '굼': 102, '굽': 103, '궁': 104, '권': 105, '귀': 106, '귄': 107, '규': 108, '그': 109, '극': 110, '근': 111, '글': 112, '금': 113, '급': 114, '긋': 115, '긍': 116, '기': 117, '긴': 118, '길': 119, '깊': 120, '까': 121, '깎': 122, '깐': 123, '깔': 124, '깜': 125, '깡': 126, '깨': 127, '꺼': 128, '꺾': 129, '껍': 130, '껏': 131, '껐': 132, '께': 133, '껴': 134, '꼈': 135, '꼬': 136, '꼴': 137, '꼼': 138, '꽃': 139, '꽉': 140, '꽤': 141, '꾸': 142, '꾼': 143, '꿇': 144, '꿈': 145, '꿔': 146, '꿨': 147, '뀌': 148, '끄': 149, '끈': 150, '끊': 151, '끌': 152, '끓': 153, '끔': 154, '끗': 155, '끙': 156, '끝': 157, '끼': 158, '낀': 159, '낄': 160, '낌': 161, '나': 162, '낙': 163, '낚': 164, '난': 165, '날': 166, '낡': 167, '남': 168, '납': 169, '났': 170, '낭': 171, '낮': 172, '낯': 173, '내': 174, '낸': 175, '낼': 176, '냄': 177, '냈': 178, '냉': 179, '냐': 180, '냥': 181, '너': 182, '넌': 183, '널': 184, '넓': 185, '넘': 186, '넛': 187, '넣': 188, '네': 189, '넷': 190, '녀': 191, '녁': 192, '년': 193, '념': 194, '녕': 195, '노': 196, '녹': 197, '논': 198, '놀': 199, '농': 200, '높': 201, '놓': 202, '놔': 203, '놨': 204, '뇌': 205, '누': 206, '눅': 207, '눈': 208, '눠': 209, '눴': 210, '뉴': 211, '늄': 212, '느': 213, '늑': 214, '는': 215, '늘': 216, '늙': 217, '능': 218, '늦': 219, '니': 220, '닌': 221, '님': 222, '다': 223, '닥': 224, '닦': 225, '단': 226, '닫': 227, '달': 228, '닮': 229, '담': 230, '답': 231, '당': 232, '대': 233, '댔': 234, '더': 235, '덕': 236, '던': 237, '덜': 238, '덤': 239, '덥': 240, '데': 241, '덴': 242, '도': 243, '독': 244, '돈': 245, '돌': 246, '돕': 247, '동': 248, '돼': 249, '됐': 250, '되': 251, '된': 252, '될': 253, '됩': 254, '두': 255, '둑': 256, '둔': 257, '둘': 258, '둠': 259, '둬': 260, '뒀': 261, '뒤': 262, '드': 263, '득': 264, '든': 265, '듣': 266, '들': 267, '듯': 268, '등': 269, '디': 270, '딘': 271, '딨': 272, '따': 273, '딱': 274, '딸': 275, '땅': 276, '땋': 277, '때': 278, '떠': 279, '떡': 280, '떤': 281, '떨': 282, '떴': 283, '떻': 284, '또': 285, '똑': 286, '뚱': 287, '뛰': 288, '뜨': 289, '뜰': 290, '뜻': 291, '라': 292, '락': 293, '란': 294, '랄': 295, '람': 296, '랍': 297, '랐': 298, '랑': 299, '래': 300, '랜': 301, '램': 302, '랩': 303, '랬': 304, '략': 305, '량': 306, '러': 307, '럭': 308, '런': 309, '럴': 310, '럼': 311, '럽': 312, '렀': 313, '렁': 314, '렇': 315, '레': 316, '렌': 317, '렛': 318, '려': 319, '력': 320, '련': 321, '렵': 322, '렸': 323, '령': 324, '례': 325, '로': 326, '록': 327, '론': 328, '롭': 329, '뢰': 330, '료': 331, '루': 332, '룹': 333, '류': 334, '륙': 335, '륜': 336, '륭': 337, '르': 338, '른': 339, '를': 340, '름': 341, '릅': 342, '릎': 343, '리': 344, '린': 345, '릴': 346, '림': 347, '립': 348, '마': 349, '막': 350, '만': 351, '많': 352, '말': 353, '맙': 354, '맛': 355, '망': 356, '맞': 357, '맡': 358, '매': 359, '맥': 360, '맨': 361, '맷': 362, '머': 363, '먹': 364, '먼': 365, '멀': 366, '멈': 367, '멋': 368, '멍': 369, '메': 370, '멕': 371, '멜': 372, '며': 373, '면': 374, '명': 375, '몇': 376, '모': 377, '목': 378, '몰': 379, '몸': 380, '못': 381, '묘': 382, '무': 383, '묵': 384, '묶': 385, '문': 386, '묻': 387, '물': 388, '뭇': 389, '뭐': 390, '뭔': 391, '뭘': 392, '므': 393, '미': 394, '민': 395, '믿': 396, '밀': 397, '밌': 398, '밍': 399, '밑': 400, '바': 401, '박': 402, '밖': 403, '반': 404, '받': 405, '발': 406, '밝': 407, '밟': 408, '밤': 409, '밥': 410, '방': 411, '배': 412, '백': 413, '뱀': 414, '버': 415, '벅': 416, '번': 417, '벌': 418, '범': 419, '법': 420, '벗': 421, '벙': 422, '베': 423, '벼': 424, '벽': 425, '변': 426, '별': 427, '병': 428, '보': 429, '복': 430, '본': 431, '볼': 432, '봄': 433, '봅': 434, '봇': 435, '봉': 436, '봐': 437, '봤': 438, '부': 439, '북': 440, '분': 441, '불': 442, '붉': 443, '붐': 444, '붕': 445, '붙': 446, '브': 447, '블': 448, '비': 449, '빈': 450, '빌': 451, '빙': 452, '빛': 453, '빠': 454, '빨': 455, '빴': 456, '빵': 457, '빼': 458, '뺄': 459, '뻔': 460, '뻤': 461, '뽀': 462, '뽑': 463, '뿌': 464, '뿐': 465, '쁘': 466, '쁜': 467, '쁠': 468, '삐': 469, '사': 470, '삭': 471, '산': 472, '살': 473, '삶': 474, '삼': 475, '샀': 476, '상': 477, '새': 478, '색': 479, '샌': 480, '생': 481, '샤': 482, '샴': 483, '서': 484, '석': 485, '선': 486, '설': 487, '섬': 488, '섭': 489, '섯': 490, '섰': 491, '성': 492, '세': 493, '센': 494, '셈': 495, '셔': 496, '셜': 497, '셨': 498, '소': 499, '속': 500, '손': 501, '솔': 502, '송': 503, '쇠': 504, '수': 505, '숙': 506, '순': 507, '숟': 508, '술': 509, '숨': 510, '쉬': 511, '쉽': 512, '슈': 513, '스': 514, '슨': 515, '슬': 516, '습': 517, '승': 518, '시': 519, '식': 520, '신': 521, '실': 522, '싫': 523, '심': 524, '십': 525, '싱': 526, '싶': 527, '싸': 528, '쌉': 529, '써': 530, '썩': 531, '썼': 532, '썽': 533, '쏘': 534, '쏠': 535, '쏴': 536, '쓰': 537, '쓱': 538, '쓴': 539, '쓸': 540, '씀': 541, '씨': 542, '씩': 543, '씬': 544, '씻': 545, '아': 546, '악': 547, '안': 548, '앉': 549, '않': 550, '알': 551, '앓': 552, '암': 553, '압': 554, '앗': 555, '았': 556, '앙': 557, '앞': 558, '애': 559, '액': 560, '앨': 561, '앵': 562, '야': 563, '약': 564, '얀': 565, '얇': 566, '양': 567, '얗': 568, '얘': 569, '어': 570, '억': 571, '언': 572, '얻': 573, '얼': 574, '엄': 575, '업': 576, '없': 577, '엇': 578, '었': 579, '엌': 580, '에': 581, '엔': 582, '엘': 583, '여': 584, '역': 585, '연': 586, '열': 587, '염': 588, '엽': 589, '였': 590, '영': 591, '옆': 592, '예': 593, '옛': 594, '오': 595, '옥': 596, '온': 597, '올': 598, '옮': 599, '옳': 600, '옷': 601, '옹': 602, '와': 603, '완': 604, '왔': 605, '왜': 606, '외': 607, '왼': 608, '요': 609, '욕': 610, '용': 611, '우': 612, '운': 613, '울': 614, '움': 615, '웃': 616, '워': 617, '원': 618, '월': 619, '웠': 620, '웨': 621, '위': 622, '윈': 623, '윗': 624, '윙': 625, '유': 626, '육': 627, '윤': 628, '으': 629, '은': 630, '을': 631, '음': 632, '읍': 633, '응': 634, '의': 635, '이': 636, '익': 637, '인': 638, '일': 639, '읽': 640, '잃': 641, '임': 642, '입': 643, '있': 644, '잊': 645, '자': 646, '작': 647, '잔': 648, '잖': 649, '잘': 650, '잠': 651, '잡': 652, '잤': 653, '장': 654, '재': 655, '잭': 656, '쟁': 657, '저': 658, '적': 659, '전': 660, '절': 661, '젊': 662, '점': 663, '접': 664, '정': 665, '제': 666, '젝': 667, '젠': 668, '젯': 669, '져': 670, '졌': 671, '조': 672, '족': 673, '존': 674, '졸': 675, '좀': 676, '종': 677, '좋': 678, '좌': 679, '죄': 680, '죠': 681, '주': 682, '죽': 683, '준': 684, '줄': 685, '중': 686, '줘': 687, '줬': 688, '쥐': 689, '즈': 690, '즉': 691, '즐': 692, '즘': 693, '증': 694, '지': 695, '직': 696, '진': 697, '질': 698, '집': 699, '짓': 700, '짖': 701, '짜': 702, '짝': 703, '짧': 704, '째': 705, '쨌': 706, '쩔': 707, '쩡': 708, '쪄': 709, '쪘': 710, '쪼': 711, '쪽': 712, '쫓': 713, '쯤': 714, '찌': 715, '찍': 716, '찔': 717, '찡': 718, '찢': 719, '차': 720, '착': 721, '찬': 722, '찮': 723, '찰': 724, '참': 725, '찼': 726, '창': 727, '찾': 728, '채': 729, '책': 730, '챌': 731, '챘': 732, '처': 733, '척': 734, '천': 735, '철': 736, '첫': 737, '청': 738, '체': 739, '쳐': 740, '쳤': 741, '초': 742, '촌': 743, '총': 744, '최': 745, '추': 746, '축': 747, '출': 748, '춤': 749, '충': 750, '춰': 751, '췄': 752, '취': 753, '츠': 754, '측': 755, '치': 756, '칙': 757, '친': 758, '칠': 759, '침': 760, '칩': 761, '카': 762, '캐': 763, '커': 764, '컨': 765, '컴': 766, '컵': 767, '케': 768, '켓': 769, '켜': 770, '켤': 771, '켰': 772, '코': 773, '콜': 774, '콥': 775, '콩': 776, '쾅': 777, '쿠': 778, '쿨': 779, '퀴': 780, '큐': 781, '크': 782, '큰': 783, '큼': 784, '키': 785, '킬': 786, '킹': 787, '타': 788, '탁': 789, '탄': 790, '탈': 791, '탐': 792, '탑': 793, '탓': 794, '탔': 795, '탕': 796, '태': 797, '택': 798, '터': 799, '턱': 800, '턴': 801, '테': 802, '텐': 803, '토': 804, '톰': 805, '톱': 806, '통': 807, '퇴': 808, '투': 809, '트': 810, '특': 811, '튼': 812, '틀': 813, '티': 814, '틱': 815, '틴': 816, '팀': 817, '팅': 818, '파': 819, '판': 820, '팔': 821, '팠': 822, '패': 823, '퍼': 824, '펐': 825, '페': 826, '펙': 827, '펜': 828, '펭': 829, '펴': 830, '편': 831, '평': 832, '폐': 833, '포': 834, '폭': 835, '폰': 836, '표': 837, '푸': 838, '푹': 839, '풀': 840, '품': 841, '풍': 842, '퓨': 843, '프': 844, '픈': 845, '플': 846, '픔': 847, '피': 848, '필': 849, '핑': 850, '하': 851, '학': 852, '한': 853, '할': 854, '함': 855, '합': 856, '항': 857, '해': 858, '핸': 859, '햄': 860, '했': 861, '행': 862, '향': 863, '햿': 864, '허': 865, '헉': 866, '헌': 867, '험': 868, '헤': 869, '헬': 870, '헷': 871, '혀': 872, '현': 873, '혈': 874, '혐': 875, '협': 876, '혔': 877, '형': 878, '혜': 879, '호': 880, '혹': 881, '혼': 882, '홉': 883, '홋': 884, '화': 885, '확': 886, '환': 887, '활': 888, '황': 889, '회': 890, '획': 891, '효': 892, '후': 893, '훈': 894, '훌': 895, '훔': 896, '훨': 897, '휘': 898, '휴': 899, '흐': 900, '흔': 901, '흘': 902, '흙': 903, '흠': 904, '흡': 905, '흥': 906, '희': 907, '흰': 908, '히': 909, '힌': 910, '힘': 911}\n"
     ]
    }
   ],
   "source": [
    "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
    "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
    "print(src_to_index)\n",
    "print(tar_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3002,
     "status": "ok",
     "timestamp": 1600603820488,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "Q6lgAf0DSXcf",
    "outputId": "9b7f9ebf-cf84-4721-bc27-4eff9f769db6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29, 61, 9], [30, 55, 9], [40, 67, 60, 2], [40, 67, 60, 9], [45, 54, 61, 22]]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = []\n",
    "for line in lines.src: # 입력 영어 데이터에서 1줄씩 문장을 읽음\n",
    "    temp_X = []\n",
    "    for w in line:     #각 줄에서 1개씩 글자를 읽음\n",
    "        temp_X.append(src_to_index[w]) # 글자를 해당되는 정수로 변환\n",
    "    encoder_input.append(temp_X)\n",
    "print(encoder_input[:5])  # 5개 샘플 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2993,
     "status": "ok",
     "timestamp": 1600603820488,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "nhKrM0eaSXc_",
    "outputId": "bebe7865-8a2e-4279-8819-7ef76ae35eb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 44, 11, 3, 2], [1, 3, 548, 195, 11, 3, 2], [1, 3, 288, 570, 4, 3, 2], [1, 3, 288, 570, 11, 3, 2], [1, 3, 206, 96, 24, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_input = []\n",
    "for line in lines.tar: # 출력 한국어 데이터에서 1줄씩 문장을 읽음\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "        temp_X.append(tar_to_index[w])\n",
    "    decoder_input.append(temp_X)\n",
    "print(decoder_input[:5])  # 5개 샘플 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2985,
     "status": "ok",
     "timestamp": 1600603820489,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "toKvk4Y9SXdR",
    "outputId": "3a096532-1f43-4c96-e342-8137f5f6bf0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 44, 11, 3, 2], [3, 548, 195, 11, 3, 2], [3, 288, 570, 4, 3, 2], [3, 288, 570, 11, 3, 2], [3, 206, 96, 24, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "# 'tar' 한국어 문장의 맨앞의 '\\t'(인코딩 값:1)를 모두 제거한다 \n",
    "decoder_target = []\n",
    "for line in lines.tar:\n",
    "    t=0\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "        if t>0:\n",
    "            temp_X.append(tar_to_index[w])\n",
    "        t=t+1\n",
    "    decoder_target.append(temp_X)\n",
    "print(decoder_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2975,
     "status": "ok",
     "timestamp": 1600603820490,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "qzItvuJWSXdY",
    "outputId": "66bbcd4e-3a2c-47e3-9e97-b57451324c66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "# 영어와 한국어 문장의 최대 길이를 구한다\n",
    "max_src_len = max([len(line) for line in lines.src])\n",
    "max_tar_len = max([len(line) for line in lines.tar])\n",
    "print(max_src_len)\n",
    "print(max_tar_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2966,
     "status": "ok",
     "timestamp": 1600603820490,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "cncNsU8PSXdc",
    "outputId": "d20a510a-bb24-4d21-dc7f-2e114c080a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# 최대 길이를 10으로 나누어 사용 (학습 시간 단축)\n",
    "max_src_len //= 10\n",
    "max_tar_len //= 10\n",
    "print(max_src_len)  # 53\n",
    "print(max_tar_len)  # 30  \n",
    "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3441,
     "status": "ok",
     "timestamp": 1600603820967,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "vBrEcyhuSXdp"
   },
   "outputs": [],
   "source": [
    "# 원핫 벡터\n",
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4xVsjwZiSXdu"
   },
   "source": [
    "### seq2seq 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3441,
     "status": "ok",
     "timestamp": 1600603820969,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "h_nYF-iMSXdv"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4402,
     "status": "ok",
     "timestamp": 1600603821931,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "lbXAvKhxSXd1"
   },
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
    "encoder_lstm = LSTM(units=256, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "# encoder_outputs도 같이 리턴받기는 했지만 여기서는 필요없으므로 이 값은 버림.\n",
    "encoder_states = [state_h, state_c]\n",
    "# LSTM은 바닐라 RNN과는 달리 상태가 두 개 : 은닉 상태와 셀 상태."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4394,
     "status": "ok",
     "timestamp": 1600603821932,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "pPO8-Ho2SXd7",
    "outputId": "65bdee79-1463-496d-dd3e-d43f12f76fc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 75)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 912)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 339968      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  1197056     input_2[0][0]                    \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 912)    234384      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,771,408\n",
      "Trainable params: 1,771,408\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
    "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "# 디코더의 첫 상태를 인코더의 은닉 상태, 셀 상태로 합니다.\n",
    "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n",
    "model.summary()\n",
    "\n",
    "# 글자  레벨이므로  Encoder 측에 워드임베딩을 위한 Embedding 계층을 사용하지 않았음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 66114,
     "status": "ok",
     "timestamp": 1600603883661,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "Plp5hX84SXd_",
    "outputId": "3f9e1bae-0269-46fb-d186-9571e01903b6",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46/46 [==============================] - 14s 299ms/step - loss: 2.7733 - val_loss: 4.0117\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 13s 291ms/step - loss: 2.3465 - val_loss: 4.4231\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 15s 325ms/step - loss: 2.2267 - val_loss: 4.0103\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 15s 316ms/step - loss: 2.0599 - val_loss: 3.6134\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 14s 312ms/step - loss: 1.8718 - val_loss: 3.3876\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 14s 313ms/step - loss: 1.8973 - val_loss: 3.3286\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 15s 316ms/step - loss: 1.6766 - val_loss: 3.4053\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 15s 322ms/step - loss: 1.6118 - val_loss: 3.2590\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 15s 324ms/step - loss: 1.5562 - val_loss: 3.2623\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 15s 329ms/step - loss: 1.5110 - val_loss: 3.2701\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 16s 338ms/step - loss: 1.4636 - val_loss: 3.2722\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 16s 342ms/step - loss: 1.4292 - val_loss: 3.1646\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 16s 349ms/step - loss: 1.3938 - val_loss: 3.0828\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 16s 350ms/step - loss: 1.3584 - val_loss: 3.0363\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 16s 343ms/step - loss: 1.3258 - val_loss: 3.0620\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 16s 339ms/step - loss: 1.2918 - val_loss: 3.0883\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 15s 328ms/step - loss: 1.2605 - val_loss: 3.0219\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 15s 329ms/step - loss: 1.2290 - val_loss: 3.0816\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 16s 357ms/step - loss: 1.2032 - val_loss: 3.0188\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 18s 385ms/step - loss: 1.1771 - val_loss: 3.0346\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 16s 357ms/step - loss: 1.1487 - val_loss: 2.9609\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 16s 347ms/step - loss: 1.1271 - val_loss: 2.9961\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 15s 317ms/step - loss: 1.1001 - val_loss: 2.9628\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 14s 313ms/step - loss: 1.0760 - val_loss: 2.9946\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 14s 306ms/step - loss: 1.0530 - val_loss: 2.9929\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 14s 310ms/step - loss: 1.0320 - val_loss: 2.9674\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 14s 313ms/step - loss: 1.0092 - val_loss: 2.9740\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 15s 318ms/step - loss: 0.9886 - val_loss: 2.9714\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 15s 326ms/step - loss: 0.9665 - val_loss: 3.0058\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 15s 327ms/step - loss: 0.9486 - val_loss: 2.9351\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 15s 320ms/step - loss: 0.9259 - val_loss: 3.1090\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 14s 314ms/step - loss: 0.9085 - val_loss: 3.0724\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 15s 317ms/step - loss: 0.8885 - val_loss: 3.0084\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 14s 309ms/step - loss: 0.8682 - val_loss: 3.0451\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 14s 311ms/step - loss: 0.8502 - val_loss: 3.0038\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 15s 317ms/step - loss: 0.8318 - val_loss: 3.1155\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 17s 367ms/step - loss: 0.8124 - val_loss: 2.9897\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 16s 345ms/step - loss: 0.7969 - val_loss: 3.0488\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 16s 350ms/step - loss: 0.7772 - val_loss: 2.9796\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 15s 332ms/step - loss: 0.7617 - val_loss: 3.1140\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 15s 327ms/step - loss: 0.7430 - val_loss: 2.9685\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 15s 326ms/step - loss: 0.7252 - val_loss: 3.1622\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 16s 338ms/step - loss: 0.7103 - val_loss: 3.0695\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 19s 403ms/step - loss: 0.6937 - val_loss: 3.1706\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 19s 411ms/step - loss: 0.6786 - val_loss: 3.1565\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 19s 406ms/step - loss: 0.6608 - val_loss: 3.1241\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 18s 383ms/step - loss: 0.6483 - val_loss: 3.3338\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 17s 361ms/step - loss: 0.6309 - val_loss: 3.2040\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 17s 369ms/step - loss: 0.6167 - val_loss: 3.2625\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 18s 391ms/step - loss: 0.6056 - val_loss: 3.1516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20ff62c6eb0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 66106,
     "status": "ok",
     "timestamp": 1600603883662,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "cnyz3JU_SXeE",
    "outputId": "af4786cc-9502-4354-c0f5-386182e5a8ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, 75)]        0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 256), (None, 256) 339968    \n",
      "=================================================================\n",
      "Total params: 339,968\n",
      "Trainable params: 339,968\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 66495,
     "status": "ok",
     "timestamp": 1600603884060,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "U_FlFWOYSXeJ",
    "outputId": "626a40c9-3b22-4cad-b777-9c6e4c264dae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None, 912)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  1197056     input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 912)    234384      lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,431,440\n",
      "Trainable params: 1,431,440\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "decoder_states = [state_h, state_c]\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 66496,
     "status": "ok",
     "timestamp": 1600603884063,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "lvQcWFG3SXeN"
   },
   "outputs": [],
   "source": [
    "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
    "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 66497,
     "status": "ok",
     "timestamp": 1600603884066,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "sGw6UlqzSXeQ"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "    target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_tar_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 71010,
     "status": "ok",
     "timestamp": 1600603888588,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "7hD5leU5SXeU",
    "outputId": "e621dfc7-5ff5-48eb-dd45-45213334c50a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: I won!\n",
      "정답 문장:  내가 이겼어! \n",
      "번역기가 번역한 문장:  난 톰이 자폐증이는 걸 알고 있어. \n",
      "-----------------------------------\n",
      "입력 문장: Hold still.\n",
      "정답 문장:  가만히 있어. \n",
      "번역기가 번역한 문장:  이렇게나 매력적이라니! \n",
      "-----------------------------------\n",
      "입력 문장: Cheer up!\n",
      "정답 문장:  힘내! \n",
      "번역기가 번역한 문장:  그만 나. \n",
      "-----------------------------------\n",
      "입력 문장: It stinks.\n",
      "정답 문장:  냄새나. \n",
      "번역기가 번역한 문장:  이건 너무 늙었어. \n",
      "-----------------------------------\n",
      "입력 문장: Don't talk!\n",
      "정답 문장:  말하지 마! \n",
      "번역기가 번역한 문장:  이렇게나 매력적이 수가! \n",
      "-----------------------------------\n",
      "입력 문장: It rained.\n",
      "정답 문장:  비가 왔어. \n",
      "번역기가 번역한 문장:  이건 너무 늙었어. \n",
      "-----------------------------------\n",
      "입력 문장: Tom yawned.\n",
      "정답 문장:  톰이 하품했어. \n",
      "번역기가 번역한 문장:  톰이 웃었어. \n",
      "-----------------------------------\n",
      "입력 문장: Don't lie.\n",
      "정답 문장:  거짓말 하지 마세요. \n",
      "번역기가 번역한 문장:  이렇게나 매력적이 수가! \n",
      "-----------------------------------\n",
      "입력 문장: I'm sad.\n",
      "정답 문장:  슬퍼. \n",
      "번역기가 번역한 문장:  난 톰이 자폐증이는 걸 알고 있어. \n",
      "-----------------------------------\n",
      "입력 문장: He came.\n",
      "정답 문장:  그 사람이 왔어. \n",
      "번역기가 번역한 문장:  그 사람은 아직 결혼했어. \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for i in range(10): # 입력 문장의 인덱스\n",
    "    seq_index = random.randint(10,300)\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.src[seq_index])\n",
    "    print('정답 문장:', lines.tar[seq_index][1:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QfxtCWA1SXeb"
   },
   "source": [
    "## [2]  영어-프랑스어 번역기 구현 : Word-Level 번역기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 71012,
     "status": "ok",
     "timestamp": 1600603888592,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "mVXArZmISXec"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import os\n",
    "import unicodedata\n",
    "import urllib3\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "duytxDKvSXen"
   },
   "source": [
    "### 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 76890,
     "status": "ok",
     "timestamp": 1600603894471,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "VlGszwDySXes"
   },
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "url ='http://www.manythings.org/anki/fra-eng.zip'\n",
    "filename = 'fra-eng.zip'\n",
    "path = os.getcwd()\n",
    "zipfilename = os.path.join(path, filename)\n",
    "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
    "    shutil.copyfileobj(r, out_file)\n",
    "\n",
    "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 76889,
     "status": "ok",
     "timestamp": 1600603894472,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "jClHm6__SXe9"
   },
   "outputs": [],
   "source": [
    "num_samples = 33000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9fnywYhLSXfC"
   },
   "source": [
    "### 전처리 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 76888,
     "status": "ok",
     "timestamp": 1600603894473,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "djhQLDurSXfD"
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) \n",
    "                   if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 76886,
     "status": "ok",
     "timestamp": 1600603894473,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "j9XqiT_cSXfH"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(sent):\n",
    "    # 위에서 구현한 함수를 내부적으로 호출\n",
    "    sent = unicode_to_ascii(sent.lower())\n",
    "\n",
    "    # 단어와 구두점 사이에 공백을 만듭니다.\n",
    "    # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
    "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "\n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n",
    "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
    "\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 76880,
     "status": "ok",
     "timestamp": 1600603894473,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "aAiEDvMuSXfL",
    "outputId": "86e10115-fde0-40cd-a518-793e18e6ed6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have you had dinner ?\n",
      "b'avez vous deja dine ?'\n"
     ]
    }
   ],
   "source": [
    "# 전처리 테스트\n",
    "en_sent = u\"Have you had dinner?\"\n",
    "fr_sent = u\"Avez-vous déjà diné?\"\n",
    "print(preprocess_sentence(en_sent))\n",
    "print(preprocess_sentence(fr_sent).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 76880,
     "status": "ok",
     "timestamp": 1600603894474,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "Dbl0tj8zSXfU"
   },
   "outputs": [],
   "source": [
    "def load_preprocessed_data():\n",
    "    encoder_input, decoder_input, decoder_target = [], [], []\n",
    "\n",
    "    with open(\"fra.txt\", \"r\", encoding='utf-8') as lines:\n",
    "        for i, line in enumerate(lines):\n",
    "\n",
    "            # source 데이터와 target 데이터 분리\n",
    "            src_line, tar_line, _ = line.strip().split('\\t')\n",
    "\n",
    "            # source 데이터 전처리\n",
    "            src_line_input = [w for w in preprocess_sentence(src_line).split()]\n",
    "\n",
    "            # target 데이터 전처리\n",
    "            tar_line = preprocess_sentence(tar_line)\n",
    "            tar_line_input = [w for w in (\"<sos> \" + tar_line).split()]\n",
    "            tar_line_target = [w for w in (tar_line + \" <eos>\").split()]\n",
    "\n",
    "            encoder_input.append(src_line_input)\n",
    "            decoder_input.append(tar_line_input)\n",
    "            decoder_target.append(tar_line_target)\n",
    "\n",
    "            if i == num_samples - 1:\n",
    "                break\n",
    "\n",
    "    return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 77883,
     "status": "ok",
     "timestamp": 1600603895484,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "Bd7jDPPkSXfY",
    "outputId": "3b43ff0b-b5c6-41b5-a8c5-e5587fc9b7a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go', '.'], ['hi', '.'], ['hi', '.'], ['run', '!'], ['run', '!']]\n",
      "[['<sos>', 'va', '!'], ['<sos>', 'salut', '!'], ['<sos>', 'salut', '.'], ['<sos>', 'cours', '!'], ['<sos>', 'courez', '!']]\n",
      "[['va', '!', '<eos>'], ['salut', '!', '<eos>'], ['salut', '.', '<eos>'], ['cours', '!', '<eos>'], ['courez', '!', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n",
    "print(sents_en_in[:5])\n",
    "print(sents_fra_in[:5])\n",
    "print(sents_fra_out[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J2Hxz5pUSXfi"
   },
   "source": [
    "#### 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78327,
     "status": "ok",
     "timestamp": 1600603895929,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "es3dTrL1SXfq"
   },
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_en.fit_on_texts(sents_en_in)\n",
    "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
    "\n",
    "tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
    "decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
    "decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fBhfzlH1SXfu"
   },
   "source": [
    "#### 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78738,
     "status": "ok",
     "timestamp": 1600603896342,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "jP0D9FZySXfv"
   },
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
    "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
    "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78733,
     "status": "ok",
     "timestamp": 1600603896343,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "Z3kyuPD-SXf1",
    "outputId": "4dcb0408-018a-4fbd-c4d5-b7d7be6b5886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어 집합의 크기 : 4663, 프랑스어 단어 집합의 크기 : 8038\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
    "tar_vocab_size = len(tokenizer_fra.word_index) + 1\n",
    "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78732,
     "status": "ok",
     "timestamp": 1600603896344,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "KWzfxQbYSXf8"
   },
   "outputs": [],
   "source": [
    "src_to_index = tokenizer_en.word_index\n",
    "index_to_src = tokenizer_en.index_word # 훈련 후 결과 비교할 때 사용\n",
    "\n",
    "tar_to_index = tokenizer_fra.word_index # 훈련 후 예측 과정에서 사용\n",
    "index_to_tar = tokenizer_fra.index_word # 훈련 후 결과 비교할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78727,
     "status": "ok",
     "timestamp": 1600603896345,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "Wl9N3ftKSXf_",
    "outputId": "4603879c-8e35-4d4a-ef12-1e2f63dc7767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14760  5876  4316 ...  9551 22051 13055]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78726,
     "status": "ok",
     "timestamp": 1600603896346,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "MscryFXZSXgC"
   },
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78721,
     "status": "ok",
     "timestamp": 1600603896348,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "iuoXjYvBSXgH",
    "outputId": "2c816118-198f-47dc-8dc8-ab57a4dc3b13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 10, 38, 41,  4,  0,  0,  0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input[30997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78715,
     "status": "ok",
     "timestamp": 1600603896349,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "ylXNo1iPSXgM",
    "outputId": "03b3f423-72fb-48e8-b549-a5397e8d7e1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,  39,  13, 100,  22,   6,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input[30997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78710,
     "status": "ok",
     "timestamp": 1600603896350,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "Zon8h9h9SXgQ",
    "outputId": "2b6a2a08-6d99-47ac-fc93-326402b1e6da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 39,  13, 100,  22,   6,   3,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target[30997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78705,
     "status": "ok",
     "timestamp": 1600603896351,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "tQGEva6bSXgU",
    "outputId": "3d39911d-7c9b-4686-ea48-e8d7f31575de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(33000*0.1)\n",
    "print(n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78704,
     "status": "ok",
     "timestamp": 1600603896352,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "-ARpbCn4SXgd"
   },
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78698,
     "status": "ok",
     "timestamp": 1600603896353,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "st2rgSm9SXgr",
    "outputId": "8a0a2379-cd21-4458-c6ba-41f07b3b4b22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29700, 8)\n",
      "(29700, 16)\n",
      "(29700, 16)\n",
      "(3300, 8)\n",
      "(3300, 16)\n",
      "(3300, 16)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_train.shape)\n",
    "print(decoder_input_train.shape)\n",
    "print(decoder_target_train.shape)\n",
    "print(encoder_input_test.shape)\n",
    "print(decoder_input_test.shape)\n",
    "print(decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j1BdjcAaSXg3"
   },
   "source": [
    "### 기계 번역기 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78696,
     "status": "ok",
     "timestamp": 1600603896353,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "o2WxuRICSXg4"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78696,
     "status": "ok",
     "timestamp": 1600603896354,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "FYOGyGqMSXg_"
   },
   "outputs": [],
   "source": [
    "latent_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 79614,
     "status": "ok",
     "timestamp": 1600603897274,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "YAEZxvTuSXhW"
   },
   "outputs": [],
   "source": [
    "# 인코더\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(src_vocab_size, latent_dim)(encoder_inputs) # 임베딩 층\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True) # 상태값 리턴을 위해 return_state는 True\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # 은닉 상태와 셀 상태를 리턴\n",
    "encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 80285,
     "status": "ok",
     "timestamp": 1600603897947,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "ihOOi1DYSXhm"
   },
   "outputs": [],
   "source": [
    "# 디코더\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(tar_vocab_size, latent_dim) # 임베딩 층\n",
    "dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "\n",
    "# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "\n",
    "# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n",
    "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 80285,
     "status": "ok",
     "timestamp": 1600603897949,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "PutYscpySXiF"
   },
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 80285,
     "status": "ok",
     "timestamp": 1600603897951,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "by8ylCE5SXiR"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 80281,
     "status": "ok",
     "timestamp": 1600603897953,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "UQ99SOjvSXiZ",
    "outputId": "3a135a28-42aa-4829-b4f7-3885e738840f"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 213762,
     "status": "ok",
     "timestamp": 1600604031440,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "V6ND8EyXSXic",
    "outputId": "410a6358-56a4-47fb-beae-855bf18d6c43"
   },
   "outputs": [],
   "source": [
    "model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 128, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 213755,
     "status": "ok",
     "timestamp": 1600604031441,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "BRFitd6SSXio",
    "outputId": "be7b5504-ba91-4aa3-f3a0-4f262b16400d"
   },
   "outputs": [],
   "source": [
    "# 인코더\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 213754,
     "status": "ok",
     "timestamp": 1600604031442,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "LrpZfgBLSXiq"
   },
   "outputs": [],
   "source": [
    "# 디코더\n",
    "# 이전 시점의 상태를 보관할 텐서\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# 훈련 때 사용했던 임베딩 층을 재사용\n",
    "dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "# 모든 시점에 대해서 단어 예측\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 213748,
     "status": "ok",
     "timestamp": 1600604031442,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "qjGeNSQXSXiy",
    "outputId": "b43eb8f2-7c3a-44a9-c687-cb0ef11fc7ce"
   },
   "outputs": [],
   "source": [
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 214123,
     "status": "ok",
     "timestamp": 1600604031819,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "97dC1yUXSXjM"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 정수 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_to_index['<sos>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 단어로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "         # 현재 시점의 예측 단어를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<eos>' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 214124,
     "status": "ok",
     "timestamp": 1600604031822,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "kGsOWsQqSXje"
   },
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2src(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + index_to_src[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2tar(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_to_index['<sos>']) and i!=tar_to_index['<eos>']):\n",
    "            temp = temp + index_to_tar[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 216160,
     "status": "ok",
     "timestamp": 1600604033864,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "rkIGwcv9SXjr",
    "outputId": "99bfbddf-d59c-4a01-9500-6dfe4de93c11"
   },
   "outputs": [],
   "source": [
    "for seq_index in [3,50,100,300,1001]:\n",
    "    input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "    print(\"원문 : \",seq2src(encoder_input_train[seq_index]))\n",
    "    print(\"번역문 :\",seq2tar(decoder_input_train[seq_index]))\n",
    "    print(\"예측문 :\",decoded_sentence[:-5])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 218063,
     "status": "ok",
     "timestamp": 1600604035773,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "lmVTBcoUSXjt",
    "outputId": "1224b5e7-5243-4691-a01a-459df1692ae3"
   },
   "outputs": [],
   "source": [
    "for seq_index in [3,50,100,300,1001]:\n",
    "    input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "    print(\"원문 : \",seq2src(encoder_input_test[seq_index]))\n",
    "    print(\"번역문 :\",seq2tar(decoder_input_test[seq_index]))\n",
    "    print(\"예측문 :\",decoded_sentence[:-5])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 218062,
     "status": "ok",
     "timestamp": 1600604035774,
     "user": {
      "displayName": "고병화",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgLZcAZyPt33HiIqtXjHiL8D4PIcVPdfLgODP1QBA=s64",
      "userId": "12645007744594631320"
     },
     "user_tz": -540
    },
    "id": "5ls7-3rySXjv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "07_기계번역.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
